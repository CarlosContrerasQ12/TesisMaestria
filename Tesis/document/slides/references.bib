@book{pham_continuous-time_2009,
	location = {Berlin, Heidelberg},
	title = {Continuous-time Stochastic Control and Optimization with Financial Applications},
	volume = {61},
	isbn = {978-3-540-89499-5 978-3-540-89500-8},
	url = {https://link.springer.com/10.1007/978-3-540-89500-8},
	series = {Stochastic Modelling and Applied Probability},
	publisher = {Springer Berlin Heidelberg},
	author = {Pham, Huyên},
	urldate = {2023-02-28},
	date = {2009},
	langid = {english},
	doi = {10.1007/978-3-540-89500-8},
	file = {Pham - 2009 - Continuous-time Stochastic Control and Optimizatio.pdf:/home/carlos/Zotero/storage/XKHCZZK5/Pham - 2009 - Continuous-time Stochastic Control and Optimizatio.pdf:application/pdf},
}

@article{han_solving_2018,
	title = {Solving high-dimensional partial differential equations using deep learning},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.1718942115},
	doi = {10.1073/pnas.1718942115},
	abstract = {Significance
	Partial differential equations ({PDEs}) are among the most ubiquitous tools used in modeling problems in nature. However, solving high-dimensional {PDEs} has been notoriously difficult due to the “curse of dimensionality.” This paper introduces a practical algorithm for solving nonlinear {PDEs} in very high (hundreds and potentially thousands of) dimensions. Numerical results suggest that the proposed algorithm is quite effective for a wide variety of problems, in terms of both accuracy and speed. We believe that this opens up a host of possibilities in economics, finance, operational research, and physics, by considering all participating agents, assets, resources, or particles together at the same time, instead of making ad hoc assumptions on their interrelationships.
	, 
	Developing algorithms for solving high-dimensional partial differential equations ({PDEs}) has been an exceedingly difficult task for a long time, due to the notoriously difficult problem known as the “curse of dimensionality.” This paper introduces a deep learning-based approach that can handle general high-dimensional parabolic {PDEs}. To this end, the {PDEs} are reformulated using backward stochastic differential equations and the gradient of the unknown solution is approximated by neural networks, very much in the spirit of deep reinforcement learning with the gradient acting as the policy function. Numerical results on examples including the nonlinear Black–Scholes equation, the Hamilton–Jacobi–Bellman equation, and the Allen–Cahn equation suggest that the proposed algorithm is quite effective in high dimensions, in terms of both accuracy and cost. This opens up possibilities in economics, finance, operational research, and physics, by considering all participating agents, assets, resources, or particles together at the same time, instead of making ad hoc assumptions on their interrelationships.},
	pages = {8505--8510},
	number = {34},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
	author = {Han, Jiequn and Jentzen, Arnulf and E, Weinan},
	urldate = {2022-09-26},
	date = {2018-08-21},
	langid = {english},
	file = {pnas.1718942115.pdf:/home/carlos/Descargas/pnas.1718942115.pdf:application/pdf},
}

@article{sirignano_dgm_2018,
	title = {{DGM}: A deep learning algorithm for solving partial differential equations},
	volume = {375},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999118305527},
	doi = {10.1016/j.jcp.2018.08.029},
	shorttitle = {{DGM}},
	abstract = {High-dimensional {PDEs} have been a longstanding computational challenge. We propose to solve highdimensional {PDEs} by approximating the solution with a deep neural network which is trained to satisfy the diﬀerential operator, initial condition, and boundary conditions. Our algorithm is meshfree, which is key since meshes become infeasible in higher dimensions. Instead of forming a mesh, the neural network is trained on batches of randomly sampled time and space points. The algorithm is tested on a class of high-dimensional free boundary {PDEs}, which we are able to accurately solve in up to 200 dimensions. The algorithm is also tested on a high-dimensional Hamilton-Jacobi-Bellman {PDE} and Burgers’ equation. The deep learning algorithm approximates the general solution to the Burgers’ equation for a continuum of diﬀerent boundary conditions and physical conditions (which can be viewed as a high-dimensional space). We call the algorithm a “Deep Galerkin Method ({DGM})” since it is similar in spirit to Galerkin methods, with the solution approximated by a neural network instead of a linear combination of basis functions. In addition, we prove a theorem regarding the approximation power of neural networks for a class of quasilinear parabolic {PDEs}.},
	pages = {1339--1364},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Sirignano, Justin and Spiliopoulos, Konstantinos},
	urldate = {2022-10-10},
	date = {2018-12},
	langid = {english},
	file = {Sirignano y Spiliopoulos - 2018 - DGM A deep learning algorithm for solving partial.pdf:/home/carlos/Zotero/storage/HSUX3UV9/Sirignano y Spiliopoulos - 2018 - DGM A deep learning algorithm for solving partial.pdf:application/pdf},
}

@article{hu_recent_nodate,
	title = {Recent Developments in Machine Learning Methods for Stochastic Control and Games},
	abstract = {In this paper, we give an overview of recently developed machine learning methods for stochastic control problems and games. The main focus is on deep learning methods that have unlocked the possibility to solve such problems even when the structure is very complex or when the dimension is very high, which is not feasible with traditional numerical methods. Many of these new approaches build on recent breakthrough machine learning methods for partial diﬀerential equations or backward stochastic diﬀerential equations, or on model-free reinforcement learning for Markov decision processes. This review summarizes state-of-the-art works at the crossroad of artiﬁcial intelligence and stochastic control and games. It also discusses connections with real applications and identiﬁes unsolved challenges.},
	author = {Hu, Ruimeng and Laurière, Mathieu},
	langid = {english},
	file = {Hu y Laurière - Recent Developments in Machine Learning Methods fo.pdf:/home/carlos/Zotero/storage/YF566UKJ/Hu y Laurière - Recent Developments in Machine Learning Methods fo.pdf:application/pdf},
}


@misc{raissi_forward-backward_2018,
	title = {Forward-Backward Stochastic Neural Networks: Deep Learning of High-dimensional Partial Differential Equations},
	url = {http://arxiv.org/abs/1804.07010},
	shorttitle = {Forward-Backward Stochastic Neural Networks},
	abstract = {Classical numerical methods for solving partial differential equations suffer from the curse dimensionality mainly due to their reliance on meticulously generated spatio-temporal grids. Inspired by modern deep learning based techniques for solving forward and inverse problems associated with partial differential equations, we circumvent the tyranny of numerical discretization by devising an algorithm that is scalable to high-dimensions. In particular, we approximate the unknown solution by a deep neural network which essentially enables us to benefit from the merits of automatic differentiation. To train the aforementioned neural network we leverage the well-known connection between high-dimensional partial differential equations and forward-backward stochastic differential equations. In fact, independent realizations of a standard Brownian motion will act as training data. We test the effectiveness of our approach for a couple of benchmark problems spanning a number of scientific domains including Black-Scholes-Barenblatt and Hamilton-Jacobi-Bellman equations, both in 100-dimensions.},
	number = {{arXiv}:1804.07010},
	publisher = {{arXiv}},
	author = {Raissi, Maziar},
	urldate = {2023-03-22},
	date = {2018-04-19},
	eprinttype = {arxiv},
	eprint = {1804.07010 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Mathematics - Analysis of {PDEs}, Electrical Engineering and Systems Science - Systems and Control},
	file = {arXiv Fulltext PDF:/home/carlos/Zotero/storage/XR8RPSHY/Raissi - 2018 - Forward-Backward Stochastic Neural Networks Deep .pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/KHWY7D98/1804.html:text/html},
}

@misc{chan-wai-nam_machine_2018,
	title = {Machine Learning for semi linear {PDEs}},
	url = {http://arxiv.org/abs/1809.07609},
	abstract = {Recent machine learning algorithms dedicated to solving semi-linear {PDEs} are improved by using different neural network architectures and different parameterizations. These algorithms are compared to a new one that solves a fixed point problem by using deep learning techniques. This new algorithm appears to be competitive in terms of accuracy with the best existing algorithms.},
	number = {{arXiv}:1809.07609},
	publisher = {{arXiv}},
	author = {Chan-Wai-Nam, Quentin and Mikael, Joseph and Warin, Xavier},
	urldate = {2023-03-26},
	date = {2018-12-10},
	eprinttype = {arxiv},
	eprint = {1809.07609 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, 65C05, 49L25, 65C99, Mathematics - Analysis of {PDEs}},
	file = {arXiv Fulltext PDF:/home/carlos/Zotero/storage/88IC72XX/Chan-Wai-Nam et al. - 2018 - Machine Learning for semi linear PDEs.pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/LXCE4JAV/1809.html:text/html},
}

@misc{nusken_interpolating_2023,
	title = {Interpolating between {BSDEs} and {PINNs}: deep learning for elliptic and parabolic boundary value problems},
	url = {http://arxiv.org/abs/2112.03749},
	shorttitle = {Interpolating between {BSDEs} and {PINNs}},
	abstract = {Solving high-dimensional partial differential equations is a recurrent challenge in economics, science and engineering. In recent years, a great number of computational approaches have been developed, most of them relying on a combination of Monte Carlo sampling and deep learning based approximation. For elliptic and parabolic problems, existing methods can broadly be classified into those resting on reformulations in terms of \${\textbackslash}textit\{backward stochastic differential equations\}\$ ({BSDEs}) and those aiming to minimize a regression-type \$L{\textasciicircum}2\$-error (\${\textbackslash}textit\{physics-informed neural networks\}\$, {PINNs}). In this paper, we review the literature and suggest a methodology based on the novel \${\textbackslash}textit\{diffusion loss\}\$ that interpolates between {BSDEs} and {PINNs}. Our contribution opens the door towards a unified understanding of numerical approaches for high-dimensional {PDEs}, as well as for implementations that combine the strengths of {BSDEs} and {PINNs}. The diffusion loss furthermore bears close similarities to \${\textbackslash}textit\{(least squares) temporal difference\}\$ objectives found in reinforcement learning. We also discuss eigenvalue problems and perform extensive numerical studies, including calculations of the ground state for nonlinear Schr{\textbackslash}"odinger operators and committor functions relevant in molecular dynamics.},
	number = {{arXiv}:2112.03749},
	publisher = {{arXiv}},
	author = {Nüsken, Nikolas and Richter, Lorenz},
	urldate = {2023-03-26},
	date = {2023-01-29},
	eprinttype = {arxiv},
	eprint = {2112.03749 [cs, math, stat]},
	keywords = {Mathematics - Numerical Analysis, Statistics - Machine Learning, Mathematics - Probability},
	file = {arXiv Fulltext PDF:/home/carlos/Zotero/storage/F6XGPLPR/Nüsken y Richter - 2023 - Interpolating between BSDEs and PINNs deep learni.pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/W2J945H2/2112.html:text/html},
}

@inproceedings{han_deep_2020,
	title = {Deep Fictitious Play for Finding Markovian Nash Equilibrium in Multi-Agent Games},
	url = {https://proceedings.mlr.press/v107/han20a.html},
	abstract = {We propose a deep neural network-based algorithm to identify the Markovian Nash equilibrium of general large \$N\$-player stochastic differential games. Following the idea of fictitious play, we recast the \$N\$-player game into \$N\$ decoupled decision problems (one for each player) and solve them iteratively. The individual decision problem is characterized by a semilinear Hamilton-Jacobi-Bellman equation, to solve which we employ the recently developed deep {BSDE} method. The resulted algorithm can solve large \$N\$-player games for which conventional numerical methods would suffer from the curse of dimensionality. Multiple numerical examples involving identical or heterogeneous agents, with risk-neutral or risk-sensitive objectives, are tested to validate the accuracy of the proposed algorithm in large group games. Even for a fifty-player game with the presence of common noise, the proposed algorithm still finds the approximate Nash equilibrium accurately, which, to our best knowledge, is difficult to achieve by other numerical algorithms.},
	eventtitle = {Mathematical and Scientific Machine Learning},
	pages = {221--245},
	booktitle = {Proceedings of The First Mathematical and Scientific Machine Learning Conference},
	publisher = {{PMLR}},
	author = {Han, Jiequn and Hu, Ruimeng},
	urldate = {2023-02-28},
	date = {2020-08-16},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:/home/carlos/Zotero/storage/ELYE2Q4K/Han y Hu - 2020 - Deep Fictitious Play for Finding Markovian Nash Eq.pdf:application/pdf},
}

@inbook{achdou_mean_2020,
	location = {Cham},
	title = {Mean Field Games and Applications: Numerical Aspects},
	volume = {2281},
	isbn = {978-3-030-59836-5 978-3-030-59837-2},
	url = {http://link.springer.com/10.1007/978-3-030-59837-2_4},
	shorttitle = {Mean Field Games and Applications},
	abstract = {The theory of mean ﬁeld games aims at studying deterministic or stochastic diﬀerential games (Nash equilibria) as the number of agents tends to inﬁnity. Since very few mean ﬁeld games have explicit or semi-explicit solutions, numerical simulations play a crucial role in obtaining quantitative information from this class of models. They may lead to systems of evolutive partial diﬀerential equations coupling a backward Bellman equation and a forward Fokker-Planck equation. In the present survey, we focus on such systems. The forward-backward structure is an important feature of this system, which makes it necessary to design unusual strategies for mathematical analysis and numerical approximation. In this survey, several aspects of a ﬁnite diﬀerence method used to approximate the previously mentioned system of {PDEs} are discussed, including convergence, variational aspects and algorithms for solving the resulting systems of nonlinear equations. Finally, we discuss in details two applications of mean ﬁeld games to the study of crowd motion and to macroeconomics, a comparison with mean ﬁeld type control, and present numerical simulations.},
	pages = {249--307},
	booktitle = {Mean Field Games},
	publisher = {Springer International Publishing},
	author = {Achdou, Yves and Laurière, Mathieu},
	bookauthor = {Achdou, Yves and Cardaliaguet, Pierre and Delarue, François and Porretta, Alessio and Santambrogio, Filippo},
	editor = {Cardaliaguet, Pierre and Porretta, Alessio},
	urldate = {2023-02-17},
	date = {2020},
	langid = {english},
	doi = {10.1007/978-3-030-59837-2_4},
	note = {Series Title: Lecture Notes in Mathematics},
	file = {Achdou y Laurière - 2020 - Mean Field Games and Applications Numerical Aspec.pdf:/home/carlos/Zotero/storage/HHG2RD4U/Achdou y Laurière - 2020 - Mean Field Games and Applications Numerical Aspec.pdf:application/pdf},
}

