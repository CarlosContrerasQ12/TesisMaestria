\newcommand{\Sspa}{\mathbb{S}^2(0,T)}
\newcommand{\Hspa}{\mathbb{H}^2(0,T)^d}

When addressing deterministic optimal control problems of dynamical systems, there are two approaches, one involving Bellman's dynamic programming principle, and the other relying on the Pontryagin's maximum principle. The former approach leads to a partial differential equation, the Hamilton-Jacobi-Bellman equation, to be solved for the value function and the optimal control of the process. The latter leads to a system of ordinary differential equations, one equation forward in time for the state and one backward in time for its adjoint.

The stochastic version of these problems is solved by methods analogous to those of the deterministic case. However, there are issues with desirable mathematical properties of solutions when we state them extending directly the ones proposed by deterministic methods. That is the case of the stochastic version of the Pontryagin's maximum principle, in which the backward differential equation cannot be stated directly as an SDE with terminal condition, as the solution is not guaranteed to be adapted to the filtration generated by the brownian motion.

The theory of backward stochastic differential equations (BSDEs) emerged in Bismut's \cite{bismut_conjugate_1973} early work, and later generalized by Pardoux and Peng \cite{pardoux_adapted_1990}, as an attempt to formalize the application of the stochastic maximum principle. Here we give an introduction and compilation of results about them based on \cite{zhang_backward_2017,pardoux_stochastic_2014,romero_maestro_nodate,touzi_optimal_2013}, including its relation with a certain class of nonlinear parabolic partial differential equations, which will be the main tool for the method explained in the following chapters. 
\section{Backward stochastic differential equations}
\subsection{Motivation}
Let's introduce the necessity for a different formulation of stochastic differential equations through an example \cite{romero_maestro_nodate}. In the usual setting for a stochastic differential equation (SDE), we specify the evolution of a $\mathbb{R}^n$-valued stochastic process $X_t$ through its dynamics and an initial value $x_0\in \mathbb{R}^n$(possibly random), in the form
\begin{equation}
	X_t=x_0 +\int_{0}^{t}\mu(t,X_t)dt+\int_{0}^{t} \sigma(t,X_t) dW_t,
\end{equation}
or equivalently,
\begin{equation}
	\label{eqn:SDE}
	\begin{split}
		dX_t&=\mu(t,X_t)dt+\sigma(t,X_t)dW_t\\
		X_0&=x_0,
	\end{split}
\end{equation}
where $W_t$ is a $d$-dimensional Brownian motion process and the stochastic integral is defined in the Ito sense.

We know that, under some Lipschitz and boundedness conditions for the drift $\mu$ and the volatility $\sigma$, the equation with initial condition $\eqref{eqn:SDE}$ has a unique solution which is adapted with respect to the filtration $\mathbb{F}=(\mathcal{F}_t)_t$ generated by $W_t$.

Now, what happens if we consider the problem \eqref{eqn:SDE} with a terminal condition at time $T>0$? Consider, for instance, the particular case with $\mu(t,X_t)=\sigma(t,X_t)=0$, and a square-integrable $\mathcal{F}_T$-measurable random variable $\xi\in L^2(0,T)$ for which we try to solve the problem of finding a process $Y_t$ such that
\begin{equation}
	\label{eqn:exampleBSDE}
	\begin{split}
		&dY_t=0\\
		&Y_t(T)=\xi.
	\end{split}
\end{equation}

This equation has a unique solution given by $Y(t)=\xi$, which is not necessarily $\mathcal{F}_t-$measurable for every $0\leq t \leq T$, and therefore \eqref{eqn:exampleBSDE} may not have solution in the usual SDE sense. 

Despite this, we can try to solve this problem reinterpreting the solution to \eqref{eqn:exampleBSDE} based on the following representation theorem.
\begin{theorem}[Martingale representation theorem \cite{mao_stochastic_2008}]
	\label{thm:MRT} Let $(M_t)_{0\leq t \leq T}$ be a continuous $\mathbb{R}^n$-valued square-integrable martingale with respect to $\mathcal{F}_t$, the augmented filtration generated by an $d$-dimensional Brownian motion $(W_t)_t$. Then, there is a unique $\mathbb{R}^{n\times d}$-valued $\mathcal{F}_t$-adapted stochastic process $f(s)$, with $\mathbb{E}[\int_{0}^{T}|f|^2dt]<\infty$ , such that 
	\begin{equation}
		M_t=M_0+\int_{0}^{t}f(s)dW_s \quad \text{ for } \quad t\in [0,T],
	\end{equation}
	where the uniqueness is interpreted in the mean squared norm.
\end{theorem}

We can intend to enforce the solution $Y_t$ to be $\mathcal{F}_t-$measurable for every $0 \leq t \leq T $ by taking its conditional expectation with respect to the evolving $\sigma$-algebra
\begin{equation}
	Y(t):=\mathbb{E}[\xi|\mathcal{F}_t],
\end{equation}
which satisfies the terminal condition $Y(T)=\xi$, since $\xi$ is $\mathbb{F}_T$-measurable. Thus, as a consequence of the Martingale representation theorem \ref{thm:MRT}, we conclude that there exist a square-integrable $\mathcal{F}_t$-measurable process $Z_t$ such that 
\begin{equation}
	\label{eqn:exampleBSDEintegral}
	Y(t)=Y(0)+\int_{0}^{t}Z_sdW_s\quad \text{ for } \quad t\in [0,T],
\end{equation}
which can be written as 
\begin{equation}
	\label{eqn:exampleBSDE2}
	\begin{split}
		&dY_t=Z_tdW_t\\
		&Y(T)=\xi
	\end{split}
\end{equation}
Therefore, problem \eqref{eqn:exampleBSDE} can be reinterpreted as in problem \eqref{eqn:exampleBSDE2}, that we will denote as a bacward stochastic differential equation (BSDE) , in which we seek a pair of processes $(Y_t,Z_t)$ that will provide an adapted solution to our original problem. Indeed, the process $Z_t$ will "steer" the system so that the process $Y_t$ remains adapted, and is thus called a control process. It is not possible to revert time as $t\to T-t$ as the filtration goes only in one direction \cite{chessari_numerical_2022}.

Finally, we can write this equation in another form. Note that \eqref{eqn:exampleBSDE2} is a forward SDE problem, hence we can solve for $Y(0)$ in the integral form , and so we have
\begin{equation}
	Y(0)=\xi-\int_{0}^{T}Z_sdW_s,
\end{equation}
that is inserted in \eqref{eqn:exampleBSDEintegral} to obtain
\begin{equation}
	Y(t)=\xi-\int_{0}^{T}Z_sdW_s+\int_{0}^{t}Z_sdW_s=\xi -\int_{t}^{T}Z_sdW_s \quad \forall t\in[0,T],
\end{equation}
which is the standard way to write the BSDE in integral form.
\subsection{Some useful theorems}
Now that we have motivated the use of BSDEs, we follow \cite{pham_continuous-time_2009} to provide a formal definition and prove that under certain regularity conditions, we can ensure the existence of a solution for that kind of equations.

Let be $(\Omega,\mathcal{F},\mathbb{P})$ a probability space and $T>0$ a fixed horizon time. We consider a $d$-dimensional Brownian motion $W=(W_t)_{t\in [0,T]}$ and let $\mathbb{F}=(\mathcal{F}_t)_{t\in[0,T]}$ be the corresponding natural augmented filtration (i.e with the completeness and right continuity conditions).

Denote by $\mathbb{S}^2(0,T)$ the set of $\bbR$-valued progressively measurable processes $Y_t$ such that 
\begin{equation}
	\mathbb{E}\left[\sup_{0\leq t \leq T}|Y_t|^2\right]<\infty,
\end{equation}  
and by $\mathbb{H}^2(0,T)^d$ the set of $\mathbb{R}^d$-valued progressively measurable processes $Z_t$ such that
\begin{equation}
	\mathbb{E}\left[\int_{0}^{T}|Z_t|^2 dt\right]<\infty.
\end{equation}

Here we consider the backward stochastic differential equation 
\begin{equation}
	\label{eqn:BSDE}
	\begin{split}
		&dY_t=-f(t,Y_t,Z_t)dt+Z_t\cdot dW_t\\
		&Y(T)=\xi
	\end{split}
\end{equation}
\begin{definition}
	A solution to the BSDE \eqref{eqn:BSDE} is a pair $(Y,Z)\in \Sspa \times \Hspa$ such that
	\begin{equation}
	Y_t=\xi+\int_t^T f\left(s, Y_s, Z_s\right) d s-\int_t^T Z_s \cdot d W_s, \quad 0 \leq t \leq T
	\end{equation}
\end{definition}
Now we establish an existence and uniqueness theorem for $\bbR$-valued process, which can be extended to $\bbR^m$-valued processes. 
\begin{assumptions}
	\label{ass:BSDEexistence}
	Let $(\xi,f)$ satisfy
	\begin{enumerate}[I.]
		\item $\xi \in L^2(\Omega,\mathcal{F}_T,\mathbb{P};\mathbb{R})$
		\item $f:\Omega\times [0,T]\times\mathbb{R}\times\mathbb{R}^d\to \bbR$ such that \begin{enumerate}[a)]
			\item $f(\cdot,t,y,z)$, written $f(t,y,z)$ for simplicity, is progressively measurable for all $y,z$
			\item $f(t,0,0)\in \mathbb{H}^2[0,T]$ 
			\item $f$ is uniformly Lipschitz in $(y,z)$, i.e ,there exist a constant $C_f$ such that for all $y_1,y_2\in \bbR\times \bbR $ and $z_1,z_2\in \bbR^d\times\bbR^d$ we have
			\begin{equation}
				\label{eqn:lipschitz}
				\left|f\left(t, y_1, z_1\right)-f\left(t, y_2, z_2\right)\right| \leq C_f\left(\left|y_1-y_2\right|+\left|z_1-z_2\right|\right) \quad a.s
			\end{equation}
		\end{enumerate}
	\end{enumerate}
\end{assumptions}
\begin{theorem}[Existence and uniqueness of solutions to BSDEs \cite{pham_continuous-time_2009}]
	\label{thm:existence}
Given a pair $(\xi,f)$, called the terminal condition and the driver of the BSDE, that satisfy the assumptions \ref{ass:BSDEexistence}
, there exist a unique solution $(Y,Z)$ to the backward stochastic differential equation \eqref{eqn:BSDE}.
\end{theorem}
To give a demonstration we will need the following inequalities about SDEs, whose proofs will be omitted.
\begin{theorem}[Doob's martingale inequality \cite{mao_stochastic_2008}]
	\label{thm:Doobs}
	Let $\{M_t\}_t\geq 0$ be a $\bbR^m$-valued martingale in $L^{p}(\Omega;\bbR^m)$. Let $[0,T]$ be a bounded interval with $T>0$ and let $p>1$. Then
	\begin{equation}
		\mathbb{E}\left[ \sup_{0\leq t\leq T}|M_t|^p\right]\leq \left(\frac{p}{p-1}\right)^p \mathbb{E}[|M_T|^p],
	\end{equation}
	in particular, if $p=2$,
	\begin{equation}
		\mathbb{E}\left[ \sup_{0\leq t\leq T}|M_t|^2\right]\leq4 \mathbb{E}[|M_T|^2].
	\end{equation}
\end{theorem}
\begin{theorem}[Burkholder-Davis-Gundy inequality
 \cite{mao_stochastic_2008}]
 \label{thm:BDGineq}
	Let $g\in L^2(\bbR^+;\bbR^{m\times d})$. Define for $t\geq 0$
	\begin{equation*}
		x(t)=\int_{0}^{t}g(s)dW_s\quad \text{ and }\quad  A(t)=\int_{0}^{t}|g(s)|^2 ds
	\end{equation*}
	then, for every $p>0$ there exist universal positive constants $c_p,C_p$, depending only on $p$, such that the following inequalities hold,
	\begin{equation}
		c_p\mathbb{E}[|A(t)|^{\frac{p}{2}}]\leq \mathbb{E}\left[\sup_{0\leq s\leq t}|x(s)|^p\right]\leq C_p\mathbb{E}[|A(t)|^{\frac{p}{2}}],
	\end{equation}
in particular, if $p=1$, we can take $c_p=\frac{1}{2}$ and $C_p=4\sqrt{2}$.
\end{theorem}
\begin{proof}[Proof of theorem \ref{thm:existence} ]
Here we give a fixed point argument. To do it, lets consider a pair of process $(U,V)\in\Sspa\times\Hspa$ and, as in the motivation example, consider the martingale
\begin{equation}
	M_t=\mathbb{E}\left[\xi +\int_{0}^{T}f(s,U_s,V_s)ds \Bigg| \mathcal{F}_t \right],
\end{equation}
which is square-integrable under the hypothesis on $(\xi,f)$. Using to the martingale representation theorem \ref{thm:MRT}, we deduce the existence and uniqueness of a process $Z_s\in \Hspa$ such that
\begin{equation}
	\label{eqn:Mdem}
	M_t=M_0+\int_{0}^{t}Z_s \cdot dW_s.
\end{equation}
Now, define the process $Y_t$ for $0\leq t\leq T$ as
\begin{equation}
	\begin{split}
	Y_t&=\mathbb{E}\left[\xi +\int_{t}^{T}f(s,U_s,V_s)ds \Bigg| \mathcal{F}_t \right]=\mathbb{E}\left[\xi +\int_{0}^{T}f(s,U_s,V_s)ds-\int_{0}^{t}f(s,U_s,V_s)ds  \Bigg| \mathcal{F}_t \right]\\
	&=M_t-\int_{0}^{t}f(s,U_s,V_s)ds\\
	\end{split}
\end{equation}
and note that from this and using \eqref{eqn:Mdem}, $Y_t$ satisfies 
\begin{equation}
	\label{eqn:SdeY}
	\begin{split}
		Y_t&=M_0+\int_{0}^{t}Z_s \cdot dW_s-\int_{0}^{t}f(s,U_s,V_s)ds\\
		&=\xi+\int_{t}^{T}f(s,U_s,V_s)ds-\int_{t}^{T} Z_s\cdot dW_s.
	\end{split}
\end{equation}


Thus, consider the function $\Phi:\Sspa\times\Hspa \to \Sspa\times\Hspa$ that maps the pair $(U,V)$ to the pair $(Y,Z)$ constructed as above, $\Phi(U,V)=(Y,Z)$. Note that it is well-defined as the $Z$ process is unique, and by Doob's martingale inequality \ref{thm:Doobs} we have

\begin{equation}
	\mathbb{E}\left[\sup_{0\leq t\leq T}\left|\int_{t}^{T}Z_s\cdot dW_s\right|^2\right]\leq 4\mathbb{E}\left[\int_{0}^{T}|Z_s|^2ds\right]<\infty,
\end{equation}
and therefore, by assumptions $I$, $II a)$ and $II b)$, $Y_t$ lies in $\Sspa$. Also note that a solution to the BSDE \eqref{eqn:BSDE} is a fixed point of $\Phi$. We will show that such fixed point exist by showing it is a contraction if we endow the $\Sspa\times\Hspa$ space with the metric 
\begin{equation}
	\lVert(Y,Z)\rVert_\beta=\left(\expect*{\int_{0}^{T}e^{\beta s}(  |Y_s|^2+|Z_s|^2)ds}\right)^{\frac{1}{2}},
\end{equation}
where $\beta>0$ is a parameter to be chosen later.

To show that $\Phi$ is a contraction, let $(U,V),(U',V')\in \Sspa\times \Hspa$ and $(Y,Z)=\Phi(U,V)$, $(Y',Z')=\Phi(U',V')$. We denote $(\bar{U},\bar{V})=(U-U',V-V')$,  $(\bar{Y},\bar{Z})=(Y-Y',Z-Z')$ and $\bar{f_t}=f(t,U_t,V_t)-f(t,U_t',V_t')$. 

Using equation \eqref{eqn:SdeY}, we know that $\bar{Y_s}$ satisfies 
\begin{equation}
	\bar{Y_s}=-\int_{0}^{t}\bar{f_s}ds+\int_{0}^{t}\bar{Z_s}\cdot dW_s
\end{equation} 

So let's apply Ito's formula to the process $e^{\beta s}|\bar{Y_s}|^2$ between $0$ and $T$ to obtain
\begin{equation}
	\label{eqn:itoProof}
	\begin{split}
	e^{\beta T}|\bar{Y_T}|^2=|\bar{Y_0}|^2&+\int_{0}^{T}(\beta e^{\beta s}|\bar{Y_s}|^2-2e^{\beta s}\bar{Y_s}\cdot \bar{f_s}+e^{\beta s}|\bar{Z_s}|^2)ds\\
	&+\int_{0}^{T}2e^{\beta s}\bar{Y_s} \bar{Z_s}\cdot dW_s.
	\end{split}
\end{equation}
Observe that we can apply the Burkholder-Davis-Gundy inequality \ref{thm:BDGineq} with $p=1$ to the following expectation of the supremum associated with the last term
\begin{equation}
	\begin{split}
	\expect*{\sup_{0\leq t \leq T}\left|\int_{0}^{t}2e^{\beta s}\bar{Y_s} \bar{Z_s}\cdot dW_s\right|}&\leq 4\sqrt{2} \expect*{\left(\int_{0}^{T}4e^{2\beta s}|\bar{Y_s}|^2 |\bar{Z_s}|^2 ds\right)^{\frac{1}{2}}} \\
	& \leq 4\sqrt{2}e^{\beta T} \expect*{\sup_{0\leq t\leq T}|Y_t|^2+\int_{0}^{T}|\bar{Z_s}|^2 ds}\\
	&<\infty,
	\end{split}
\end{equation}
which shows that the local martingale $\int_{0}^{t}2e^{\beta s}\bar{Y_s} \bar{Z_s}\cdot dW_s$ is actually a uniformly integrable martingale and therefore its expected value remains constant zero. Also, note that $\bar{Y}_T=Y_T-Y_T'=\xi-\xi=0$.

Using these facts, take the expected value to \eqref{eqn:itoProof} and reorder terms to obtain 
\begin{equation}
	\begin{aligned}
		& \mathbb{E}\left|\bar{Y}_0\right|^2+\mathbb{E}\left[\int_0^T e^{\beta s}\left(\beta\left|\bar{Y}_s\right|^2+\left|\bar{Z}_s\right|^2\right) d s\right]=2 \mathbb{E}\left[\int_0^T e^{\beta s} \bar{Y}_s \cdot \bar{f}_s d s\right] \\
		\leq & 2 C_f \mathbb{E}\left[\int_0^T e^{\beta s}\left|\bar{Y}_s\right|\left(\left|\bar{U}_s\right|+\left|\bar{V}_s\right|\right) d s\right] \quad \text{(by condition $IIc$))}  \\
		\leq & 4 C_f^2 \mathbb{E}\left[\int_0^T e^{\beta s}\left|\bar{Y}_s\right|^2 d s\right]+\frac{1}{2} \mathbb{E}\left[\int_0^T e^{\beta s}\left(\left|\bar{U}_s\right|^2+\left|\bar{V}_s\right|^2\right) d s\right],
	\end{aligned}
\end{equation}
so if we choose $\beta=1+4C_f^2$ and ignore the $ \mathbb{E}\left|\bar{Y}_0\right|^2$ term, we obtain

\begin{equation}
	 \mathbb{E}\left[\int_0^T e^{\beta s}\left(\left|\bar{Y}_s\right|^2+\left|\bar{Z}_s\right|^2\right) d s\right] \leq \frac{1}{2}  \mathbb{E}\left[\int_0^T e^{\beta s}\left(\left|\bar{U}_s\right|^2+\left|\bar{V}_s\right|^2\right) d s\right],
\end{equation}

which is $\lVert(\Phi(U,V))\rVert_\beta \leq \frac{1}{2}\lVert(U,V)\rVert_\beta$, that means $\Phi$ is a contraction in a Banach space, as $\Sspa \times \Hspa$ is the product of Banach spaces, and therefore has a unique fixed point.
\end{proof}

As in the every differential equation, there are cases where we can provide an explicit solution. The next theorem provides one for the BSDE with linear generator
\begin{theorem}[Linear BSDEs \cite{pham_continuous-time_2009}]
	\label{thm:linearBSDE}
	Let $A_t$,$B_t$ be bounded progressively measurable processes with values in $\bbR$ and $\bbR^d$, $C_t$ a process in $\mathbb{H}^2(0,T)$ and $\xi \in L^2(\Omega,\mathcal{F}_T,\mathbb{P},\bbR)$. Then, the linear backward stochastic differential equation
	\begin{equation}
		\begin{split}
			&dY_t=-(A_tY_t+Z_t\cdot B_t+C_t)dt+Z_t\cdot dW_t\\
			&Y_T=\xi
		\end{split}
	\end{equation}
	has a unique solution, and is given by the formula
	\begin{equation}
		\Gamma_t Y_t=E\left[\Gamma_T \xi+\int_t^T \Gamma_s C_s d s \mid \mathcal{F}_t\right],
	\end{equation}
	where $\Gamma_t$ is the solution to the adjoint process
	\begin{equation}
		\begin{split}
			&d\Gamma_t=\Gamma_t(A_tdt+B_t\cdot dW_t)\\
			&\Gamma_0=1
		\end{split}
	\end{equation}	
\end{theorem}
\begin{proof}
	First apply Ito's formula to $\Gamma_t Y_t$ to obtain
	\begin{equation}
		\begin{split}
			d(\Gamma_t Y_t)&=Y_t d\Gamma_t +\Gamma_t dY_t +d\Gamma_t dY_t\\
			&=Y_t(\Gamma_t A_t dt +\Gamma_t B_t\cdot dW_t)+\Gamma_t(-(A_tY_t+Z_t\cdot B_t+C_t)dt+Z_t\cdot dW_t)\\
			& \quad+\Gamma_t Z_t \cdot B_t dt\\
			&=-\Gamma_t C_t dt+\Gamma_t (Z_t+Y_t B_t)\cdot dW_t,
		\end{split}
	\end{equation}
that can be written in integral form as 
\begin{equation}
	\label{eqn:martAdj}
	\Gamma_t Y_t+\int_0^t \Gamma_s C_s d s=Y_0+\int_0^t \Gamma_s\left(Z_s+Y_s B_s\right) \cdot d W_s.
\end{equation}
We will show, as in the proof of theorem \ref{thm:existence}, that the stochastic integral  in the last expression, which is a local martingale, is in fact a uniformly integrable martingale. We have $\expect*{\sup_{0\leq t \leq T}|\Gamma_t|^2}<\infty$ ,since $A_t$ and $B_t$ are bounded. Also, let's denote $b_\infty$ the upper bound on $B_t$, then the following inequalities hold 
\begin{equation}
	\begin{split}
		\expect*{\sup_{0\leq t \leq T}\left|\int_0^t \Gamma_s\left(Z_s+Y_s B_s\right) \cdot d W_s\right|}&\leq 4\sqrt{2} \expect*{\left(\int_{0}^{T}|\Gamma_s|^2 |Z_s+Y_s B_s|^2 ds\right)^{\frac{1}{2}}} \\
		&\text{{\footnotesize (By BDG inequality \ref{thm:BDGineq})}}\\
		& \leq \frac{4\sqrt{2}}{2} E\left[\sup_{0\leq t \leq T}\left|\Gamma_t\right|^2+2 \int_0^T\left|Z_t\right|^2 d t+2 b_{\infty}^2 \int_0^T\left|Y_t\right|^2 d t\right]\\
		&<\infty.
	\end{split}
\end{equation}
Consequently, the right-hand side of is a uniformly integrable martingale, and so, if we take expected values to the equality \eqref{eqn:martAdj}, we have
\begin{equation}
	\begin{split}
		\Gamma_t Y_t+\int_0^t \Gamma_s C_s d s & =\expect*{\Gamma_T Y_T+\int_0^T \Gamma_s C_s d s \Bigg| \mathcal{F}_t} \\
		& =\expect*{\Gamma_T \xi+\int_0^T \Gamma_s C_s d s \Bigg| \mathcal{F}_t}
	\end{split}
\end{equation} 
and, as $\int_0^t \Gamma_s C_s d s$ is $\mathcal{F}_t$-measurable, we obtain
\begin{equation}
		\Gamma_t Y_t =\expect*{\Gamma_T \xi+\int_t^T \Gamma_s C_s d s \Bigg| \mathcal{F}_t},
\end{equation}
that is what we wanted to prove. The control solution $Z_t$ can be obtained by the martingale representation theorem \ref{thm:MRT} applied to this process.
\end{proof}


Finally, we state the next comparison principle for solution of BSDEs
\begin{theorem}[Comparison principle for BSDEs \cite{pham_continuous-time_2009}]
	Let $(\xi_1,f_1)$ and $(\xi_2,f_2)$ two pairs of terminal conditions and generators satisfying assumptions \ref{ass:BSDEexistence},and let $(Y_{1,t},Z_{1,t})$ and $(Y_{2,t},Z_{2,t})$ the solutions to their corresponding BSDE. Suppose that
	\begin{enumerate}
		\item $\xi_1 \leq \xi_2$ a.s
		\item $f_1(t,Y_{1,t},Z_{1,t})\leq f_2(t,Y_{1,t},Z_{1,t}) $ $dt\times d\mathbb{P}$-a.e 
		\item $f_2(t,Y_{1,t},Z_{1,t}) \in \mathbb{H}^2(0,T) $
	\end{enumerate} 
Then $Y_{1,t}\leq Y_{2,t}$ for all $0\leq t \leq T$, a.s.
Furthermore, if $Y_{2,0}\leq Y_{1,0}$, then $Y_{1,t}=Y_{2,t}$ for $t\in [0,T]$. In particular, if $\mathbb{P}(\xi_1<\xi_2)>0$ or $f_1(t,\cdot,\cdot)<f_2(t,\cdot,\cdot)$ on a set with strictly positive measure $dt\times d\mathbb{P}$ then $Y_{1,0}<Y_{2,0}$.
\end{theorem}
\begin{proof}
	To simplify notation, we give a proof with $d=1$.
	We denote $\bar{Y_t}=Y_{2,t}-Y_{1,t}$ and $\bar{Z_t}=Z_{2,t}-Z_{1,t}$. Then $(\bar{Y_t},\bar{Z_t})$ satisfy the BSDE
\begin{equation}
	\label{eqn:linearBSDE}
	\begin{split}
		&d \bar{Y_t}=-\left(\Delta_t^y \bar{Y_t}+\Delta_t^z \bar{Z_t}+\bar{f_t}\right) d t+\bar{Z}_t dW_t\\
		&\bar{Y_T}=\xi_2-\xi_1,
	\end{split}
\end{equation}
where 
\begin{equation}
	\begin{aligned}
		\Delta_t^y & =\frac{f_2\left(t, Y_{2,t}, Z_{2,t}\right)-f_2\left(t, Y_{1,t}, Z_{2,t}\right)}{Y_{2,t}-Y_{1,t}} 1_{Y_{2,t}-Y_{1,t} \neq 0} \\
		\Delta_t^z & =\frac{f_2\left(t, Y_{1,t}, Z_{2,t}\right)-f_2\left(t, Y_{1,t}, Z_{1,t}\right)}{Z_{2,t}-Z_{1,t}} 1_{Z_{2,t}-Z_{1,t} \neq 0} \\
		\bar{f}_t & =f_2\left(t, Y_{1,t}, Z_{1,t}\right)-f_1\left(t, Y_{1,t}, Z_{1,t}\right) .
	\end{aligned}
\end{equation}
By assumption, $f_2$ is Lipschitz in $y,z$, hence $\Delta_t^y$ and $\Delta_t^z$ are bounded. Moreover, $\bar{f_t}\in \mathbb{H}^2(0,T)$. Therefore, the solution to \eqref{eqn:linearBSDE} is given by theorem \ref{thm:linearBSDE} as
\begin{equation}
	\Gamma_t \bar{Y_t}=\expect*{\Gamma_T\left(\xi_2-\xi_1\right)+\int_t^T \Gamma_s \bar{f_s} d s \Bigg| \mathcal{F}_t},
\end{equation} 
where $\Gamma_t$ satisfies 
\begin{equation}
	\begin{split}
		&d\Gamma_t=\Gamma_{t}(\Delta_t^y dt + \Delta_t^z dW_t )\\
		&\Gamma_0=1.
	\end{split}
\end{equation}
Note that $\Gamma_t$ is strictly positive. We conclude the stated result using that $\xi_2-\xi_2\geq 0$ by assumption $1)$, and $\bar{f}_t\geq 0$ by assumption $2)$.

\end{proof}
\subsection{Forward-Backward stochastic differential equations}
Now we consider a special case of backward stochastic differential equations in which the randomness of the drift enters through a process satisfying a forward stochastic differential equation. In its more general form, the problem is stated as find three processes  $(X_t,Y_t,Z_t)\in\bbR^n\times\bbR^m\times\bbR^{m\times d}$ such that
\begin{equation}
	\begin{split}
		&dX_s=\mu(t,X_s,Y_s,Z_s)ds+\sigma(s,X_s,Y_s,Z_s)dW_s\\
		&X_t=x\\
		&dY_s=-f(s,X_s,Y_s,Z_s)ds+Z_s dW_s\\
		&Y_T=g(X_T),
	\end{split}
\end{equation}  
for all $t\leq s \leq T$, where $\mu,\sigma$ and $g$ are known functions, and $x$ is the initial condition at starting time $s$. This coupled system is called a forward-backward stochastic differential equation (FBSDE).

This problem is rather difficult, as the coupling between the processes may forbid a solution to exist. There are conditions on $\mu, \sigma,g$ where we can establish the existence and uniqueness of solutions to the former system, but their detailed proof is very technical and thus is not presented here, see \cite{zhang_backward_2017}.

However, we can say something simpler about the decoupled case   
\begin{equation}
	\label{eqn:Uncoupled}
	\begin{split}
		&dX_s=\mu(s,X_s)ds+\sigma(s,X_s)dW_s\\
		&X_t=x,\\
		&dY_s=-f(s,X_s,Y_s,Z_s)ds+Z_s dW_s\\
		&Y_T=g(X_T).
	\end{split}
\end{equation}
for all $t\leq s\leq T$.  

In this case, if $\mu$ and $\sigma$ satisfy enough regularity conditions to ensure that a solution to the forward SDE in \eqref{eqn:Uncoupled} exists, for example, if they are Lipschitz and bounded, then we can solve it for the process $X_t$ and insert the solution into the backward equation in \ref{eqn:Uncoupled} and solve for the backward process. However, the main property of FBSDEs is that the solution process $(Y,Z)$ of the BSDE can be written as a deterministic function of time and the state process, in this case the solution is said to be \textit{markovian}. 

Let's establish this assertions in the following theorem. 


\begin{assumptions}
	\label{ass:FBSDEexistence}
	Let $(\mu,\sigma,f,g)$. There exist a constant $C>0$ such that for all $x,y,t$
	\begin{enumerate}[I.]
		\item $|\mu(t,x)-\mu(t,y)|+|\sigma(t,x)-\sigma(t,y)|\leq C(1+|x-y|)$
		\item $|f(t,x,y_1,z_1)-f(t,x,y_2,z_2)|\leq C(|y_1-y_2|+|z_1-z_2|)$
		\item $|\sigma(t,x)|+|\mu(t,x)|\leq C(1+|x|)$
		\item $|f(t,x,y,z)|+|g(x)|\leq C(1+|x|^p)$ para $p\geq\frac{1}{2}$
	\end{enumerate}
\end{assumptions}
\begin{theorem}[Existence and markovianity of solutions of FBSDEs \cite{el_karoui_backward_1997}]
	Under assumptions \ref{ass:FBSDEexistence}, the uncoupled forward-backward stochastic differential equation \eqref{eqn:Uncoupled} has a unique solution $(X_{s}^{t,x},Y_{s}^{t,x},Z_{s}^{t,x})$ starting from $x$ at time $t$. Moreover, $(Y_{s}^{t,x},Z_{s}^{t,x})$ is adapted to the future $\sigma$-algebra of $W$ after $t$, i.e, it is $\mathcal{F}_{s}^{t}$-adapted where for each $s\in[t,T]$ we define $\mathcal{F}_{s}^{t}=\sigma(W_u-W_t,t\leq u\leq s)$. In particular, $Y_{t}^{t,x}$ is deterministic and for $0\leq s\leq t$ we have $Y_{s}^{t,x}=Y_{t}^{t,x}$ and $Z_{s}^{t,x}=0$.
\end{theorem}
\begin{proof}
	The first part about existence and uniqueness of solution to the FBSDE follows from the fact that in assumptions \ref{ass:FBSDEexistence}, $I$ and $III$ are the standard Lipschitz and linear growth conditions that guarantee the existence of a solution for the forward process \cite{mao_stochastic_2008}, and that $II$ and $IV$ are sufficient conditions to ensure the existence of the solution to the backward process from theorem \ref{thm:existence}.
	
	For the second part, consider the translated Brownian motion $W'$ and its associated filtration given by $W_s'=W_{t+s}-W_t$ for $0\leq s\leq T-t$ and $\mathcal{F}_s':=\mathcal{F}_{t+s}^t$ or $0\leq s\leq T-t$. Let $X_s'^{0,x}$ be the adapted solution to the SDE
	\begin{equation}
		\begin{split}
			&dX_s'=\mu(s,X_s')dt+\sigma(s,X_s')dW_s\\
			&X_0'=x.
		\end{split}
	\end{equation}
	By the the uniqueness provided by the former theorems, we have $X_s^{t,x}=X_{s-t}'^{0,x}$ a.s for $s\in[0,T-t]$, hence $X_s^{t,x}$ is $\mathcal{F}_{s}^{t}$-adapted.
	
	Now consider the associated $\mathcal{F}'$-adapted solution $(Y_s',Z_s')$ with $s\in[0,T-t]$ to the BSDE
	\begin{equation}
		\begin{split}
			&dY_s'=-f(s+t,X_s',Y_s',Z_s')ds+Z_s'\cdot dW_s \\
			&Y_{T-t}'=g(X_{T-t}').
		\end{split}
	\end{equation}

We have that $(Y_{s-t}',Z_{s-t}')$ with $s\in[t,T]$ is also a solution of the backward equation in \eqref{eqn:Uncoupled} in $[t,T]$. Hence, by the  uniqueness provided before we have that $(Y_{s-t}',Z_{s-t}')=(Y_{s}^{t,x},Z_{s}^{t,x})$ for $s\in[t,T]$, therefore $(Y_{s-t}',Z_{s-t}')$ is $\mathcal{F}_{s}^{t}$-adapted.

\end{proof}
From now on, we will denote by
\begin{equation}
	v(t,x):=Y_{t}^{t,x},
\end{equation}
the deterministic function of $t$ and $x$ provided by the last theorem. We also notice that $Y_t=v(t,X_t)$ for $t\in[0,T]$. 
\section{The Feynman-Kac formulas}
Now we shall establish the connection between stochastic differential equations with parabolic linear partial differential equations and its non-linear generalization based on backward stochastic differential equations. 
\subsection{The linear Feynman-Kac formula}
We will start by the linear case to introduce the necessity for a non-linear generalization. Consider the $\bbR^n$-valued process $X_s^{t,x}$ defined to be the solution in $s\in[t,\infty)$ of the SDE 
\begin{equation}
	\label{eqn:FKprocess}
	\begin{split}
		&dX_s=\mu(s,X_s)ds+\sigma(s,X_s)dW_s\\
		&X_t=x,
	\end{split}
\end{equation}
where, again,  $W_t$ is a $d$-dimensional Brownian motion, $\mu$ is $\bbR^n$-valued function, $\sigma$ is a $(n\times d)$-valued matrix of functions and $x\in\bbR^n$ is the initial condition. We have the following estimate 
\begin{theorem}[\cite{carmona_lectures_2016}]
	\label{thm:estimationSDE}
		Let $\mu$ and $\sigma$ satisfy conditions $I$ and $III$ of assumptions \ref{ass:FBSDEexistence}, then, there exist a constant $C>0$ such that the solution to \ref{eqn:FKprocess} satisfies
		\begin{equation}
			\expect*{\sup_{t\leq s\leq T}|X_s|^2}\leq C(1+\expect*{|x|^2})e^{C(T-t)}.
		\end{equation} 
\end{theorem}

Now, for a fixed $T>0$, consider the following parabolic PDE with terminal condition for the function $v(t,x):\bbR^+\times \bbR^n\to \bbR$,
\begin{equation}
	\label{eqn:FKequation}
	\begin{split}
		&\dpartial{v}{t}+\mathcal{L}_t v-k(t,x) v+f(t,x)=0\\
		&v(T,x)=g(x),
	\end{split}
\end{equation}
where $f(x,t)$ and $g(x)$ are some $\bbR$-valued continuous functions, $k(x,t)$ is a non-negative $\bbR$-valued function, and $\mathcal{L}_t$ is the \textit{generator} of the process $X_s$, defined as
\begin{equation}
	\label{eqn:ininitesimalGen}
	\begin{split}
		\mathcal{L}_tv&=\mu(t,x)\cdot D_x v(t,x)+\frac{1}{2}\Tr(\sigma(t,x)\sigma^{T}(t,x)D_{xx}^2v(t,x))\\
		&=\sum_{i=1}^{n}\mu_i(t,x)\dpartial{v}{x_i}(t,x)+\sum_{i,k=1}^{n}a_{i,k}(t,x)\frac{\partial^2 v}{\partial x_i\partial x_k}(t,x),
	\end{split}
\end{equation} 
where we denote by $a_{i,k}$ the coefficients of the \textit{diffusion matrix}, calculated as 
\begin{equation}
	a_{i,k}=\sum_{j=1}^{d}\sigma_{i,j}(t,x)\sigma_{k,j}(t,x).
\end{equation}

The linear Feynman-Kac formula establishes a connection between the process satisfying \eqref{eqn:FKprocess} and the classical solution to equation \eqref{eqn:FKequation} as follows
\begin{comment}
	\begin{assumptions}
		\label{ass:FK}
		Let $\mu$ and $\sigma$ satisfy conditions $I$ and $III$ of assumptions \ref{ass:FBSDEexistence}, and 
		\begin{enumerate}[I.]
			\item The function $g(t,x):\bbR^n\to \bbR$ is continuous and there exist constants $L_g>0$ and $\lambda_g\geq 1$ such that $|g(x)|\leq L_g(1+|x|^{2\lambda_g})$ or $g(x)\geq 0$ for all $x\in \bbR^n$.
			\item The function $f(t,x):\bbR\times\bbR^n\to \bbR$ is continuous and there exist constants $L_f>0$ and $\lambda_f\geq 1$ such that $|f(t,x)|\leq L_f(1+|x|^{2\lambda_f})$ or $f(t,x)\geq 0$ for all $x\in \bbR^n$ and $t\in [0,T]$. 
			\item The function $k(t,x):\bbR\times \bbR^{n}\to \bbR^{+}$ is a continuous function bounded above, i.e, there exist a constant $\bar{k}>0$ such that $k(t,x)\leq \bar{k}$ for all $x\in \bbR^n$ and $t\in[0,T]$
			\item The function $v(t,x):[0,T]\times \bbR^n\to \bbR$ is continuous, one time differentiable in $t$, and two times differentiable in $x$, and satisfies the PDE \eqref{eqn:FKequation}, as well as a polynomial growth condition, i.e, there exist $L_v>0$ and $\lambda_v\geq 1$ such that  $\max_{0\leq t\leq T}|v(t,x)|\leq L_v(1+|x|^{2\lambda_v})$ for all $x\in\bbR^n$.
		\end{enumerate}
	\end{assumptions}
\end{comment}
\begin{assumptions}
	\label{ass:FK}
	Let $\mu$ and $\sigma$ satisfy conditions $I$ and $III$ of assumptions \ref{ass:FBSDEexistence}, and assume that
	\begin{enumerate}[I.]
		\item The functions $g(x):\bbR^n\to \bbR$, $f(t,x):\bbR\times\bbR^n\to \bbR$ and $k(t,x):\bbR\times \bbR^{n}\to \bbR^{+}$ are continuous. 
		\item The function $v(t,x):[0,T]\times \bbR^n\to \bbR$ is continuous in $[0,T]\times \bbR^{n}$, one time differentiable in $t$, and two times differentiable in $x$, and satisfies the PDE \eqref{eqn:FKequation}. Moreover, its first derivative in $x$ is bounded, i.e , $|D_x v(t,x)|<M$ for some constant $M$ and all $t\in[0,T]$ and $x\in\bbR^n$.
	\end{enumerate}
\end{assumptions}
\begin{theorem}[Linear Feynman-Kac formula \cite{carmona_lectures_2016}]
	\label{thm:LinearFK}
	Under the assumptions \ref{ass:FK}, the solution $v(t,x)$ to the equation \eqref{eqn:FKequation} admits the stochastic representation 
	\begin{equation}
		v(t,x)=\expect*{g(X_{T}^{t,x})e^{-\int_{t}^{T}k(s,X_{s}^{t,x})ds}+\int_{t}^{T}f(s,X_{s}^{t,x})e^{-\int_{t}^{s}k(u,X_{u}^{t,x})du}ds},
	\end{equation}
	 for all $t\in[0,T]$ and $x\in\bbR^n$. In particular, this solution is unique.
\end{theorem}
\begin{proof}
	In order to simplify notation, we set $X_s=X_{s}^{x,t}$. Let's apply Ito's formula to the process  $v(s,X_s)e^{-\int_{t}^{s}k(u,X_{u})du}$ in $s\in[t,T]$ to obtain
	\begin{equation}
		\begin{split}
		e^{-\int_{t}^{T}k(u,X_{u})du}v(T,X_T)&=e^{-\int_{t}^{t}k(u,X_{u})du}v(t,X_t)\\
		&+\int_{t}^{T}e^{-\int_{t}^{s}k(u,X_{u})du}\left(\dpartial{v}{t}(s,X_s)-k(s,X_s)v(s,K_s)+\mathcal{L}_s v(s,X_s)\right)ds\\
		&+\int_{t}^{T}e^{-\int_{t}^{s}k(u,X_{u})du}D_x v(s,X_s)\cdot \sigma(s,X_s)dW_s\\
		&=v(t,X_t)-\int_{t}^{T}e^{-\int_{t}^{s}k(u,X_{u})du}f(s,X_s)ds\\
		&+\int_{t}^{T}e^{-\int_{t}^{s}k(u,X_{u})du}D_x v(s,X_s)\cdot \sigma(s,X_s)dW_s,
		\end{split},
	\end{equation}
and therefore, using that $X_t=x$, $v(T,X_t)=g(X_T)$ and solving for $v(x,t)$, we have
\begin{equation}
	\begin{split}
		v(t,x)&=g(X_T)e^{-\int_{t}^{T}k(u,X_{u})du}+\int_{t}^{T}f(s,X_s)e^{-\int_{t}^{s}k(u,X_{u})du}ds\\
		&-\int_{t}^{T}e^{-\int_{t}^{s}k(u,X_{u})du}D_x v(s,X_s)\cdot \sigma(s,X_s)dW_s.
	\end{split}
\end{equation}
To obtain the desired formula, we take expectation to this expression, and observe that the stochastic integral is a square integrable martingale by assumption \ref{ass:FK} $III$ on $D_x v$, the non-negativity of $k$, the linear growth condition on $\sigma$ and the estimation \ref{thm:estimationSDE}, therefore it's expected value is constant $0$.
\end{proof}
Note that we required that equation \eqref{eqn:FKequation} has a classical smooth solution, for which we need some regularity conditions on $\mu$, $\sigma$ and growth conditions on $f$ and $g$ to ensure the uniform ellipticity of $\mathcal{L}_t$. Also note, that assumptions \ref{ass:FK} are rather restrictive, especially the boundedness of $D_x$, but can be relaxed imposing some quadratic growth condition on $v$ and additional growth condition on $f$ and $g$. However, even if there is no smooth solution to this problem, the Feynman-Kac formula may provide a solution with other meaning, which will be named a viscosity solution and will be defined in what follows.

In addition, this formula is useful for approximating solutions $v(t,x)$ to PDEs of the form \eqref{eqn:FKequation}, even in high dimensions, where classical methods fails because of the \textit{curse of dimensionality}. This expected value can be approximated by Monte-Carlo simulation using sample paths, \hlc[Sure?]{whose rate of convergence is independent on the dimension $n$ of the underlying process}. However, its use is limited to linear equations that may not be useful for certain problems.

By the other hand, if we consider a bounded domain and add boundary conditions to \eqref{eqn:FKequation}, the we have a similar formula for the solution that can be obtained as before. We state it informally in the following theorem omitting long technical definitions and relying on the intuitive definition of reflected process. 
\begin{theorem}[Linear Feynman-Kac formula with boundary conditions \cite{yong_stochastic_1999},\cite{pardoux_stochastic_2014}]
	\label{thm:LinearFKBoundary}
	Consider equation \eqref{eqn:FKequation} in a bounded smooth domain $\Omega$, with boundary conditions
	\begin{equation}
		v(t,x)=h_d(t,x)\quad \forall x \in \Gamma_d
	\end{equation}
	
	\begin{equation}
		\dpartial{v}{\vec{n}}(t,x)=h_n(t,x)\quad \forall x \in \Gamma_n
	\end{equation}
	where $\Gamma_d \dot{\cup} \Gamma_n =\partial\Omega$ is a disjoint partition of the boundary with outer normal vector $\vec{n}$. Let
	\begin{equation}
		\tau=\inf\{s\in[t,T]|X_s^{t,x}\in \Gamma_d\}
	\end{equation}
the stopping time associated with the first exit of the domain, and define
\begin{equation}
	\Psi(t,x)=\begin{cases} 
		g(x) & (t,x)\in\{T\}\times \Omega \\
		h_d(t,x) & (t,x)\in (t,T)\times \Gamma_d
	\end{cases}
\end{equation} 
	Then, under the assumptions \ref{ass:FK}, the solution $v(t,x)$ to the equation \eqref{eqn:FKequation}	admits the stochastic representation 
	\begin{equation}
		v(t,x)=\expect*{\Psi(\tau,X_{\tau}^{t,x})e^{-\int_{t}^{T}k(s,X_{s}^{t,x})ds}+\int_{t}^{T}f(s,X_{s}^{t,x})e^{-\int_{t}^{s}k(u,X_{u}^{t,x})du}ds},
	\end{equation}
	for all $t\in[0,T]$ and $x\in\bbR^n$, where $X_{s}^{t,x}$ is the solution of a reflected stochastic differential equation starting at $t,x$ with reflection boundary $\Gamma_n$. In particular, this solution is unique.
\end{theorem}
Note that we have not defined precisely what means to be a solution to a reflected stochastic differential equation, see \cite{pardoux_stochastic_2014}.

\subsection{The non-linear Feynman-Kac formula}
Now we deal with a more general PDE than \eqref{eqn:FKequation}. We consider, for some fixed $T>0$, the problem 
\begin{equation}
	\label{eqn:FKNolineal}
		\begin{split}
			&\dpartial{v}{t}(t,x)+\mathcal{L}_t v(t,x)+f(t,x,v(t,x),\sigma(t,x)' D_x v(t,x))=0\\
			&v(T,x)=g(x),
		\end{split}
	\end{equation}
for all $t\in[0,T]$ and $x\in\bbR^{n}$, and where $f:\bbR\times \bbR^n\times \bbR \times \bbR^d\to \bbR$ is a non-linear function.

We will associate the solution to this problem with a forward-backward stochastic differential equation of the form \eqref{eqn:Uncoupled}. We have an easy association given by the following theorem

\begin{theorem}[Verification theorem \cite{pham_continuous-time_2009}]
	\label{thm:verficationThm}
	Let $v(t,x)$ be a classical solution to \ref{eqn:FKNolineal}, that is continuous on $[0,T]\times \bbR^n$, one time differentiable in $t$ and two times differentiable in $x$ and satisfy the linear growth condition $|v(t,x)|\leq L(1+|x|)$ for some $L>0$ and all $x\in\bbR^n$ $t\in[0,T]$. Also, let its first space derivative satisfy the growth condition $|D_x v(t,x)|\leq C(1+|x|^q)$ for some $C>0$, $q>0$ and all $x\in\bbR^n$ $t\in[0,T]$.Then, the pair $(Y,Z)$ defined by
	\begin{equation}
		Y_t=v(t,X_t) \quad Z_t=\sigma(t,X_t)' D_x v(t,X_t)
	\end{equation}
is the solution to the backward stochastic differential equation in \ref{eqn:Uncoupled}.
\end{theorem}
\begin{proof}
	Apply Ito's formula to $Y_t=v(t,X_t)$ to obtain
	\begin{equation}
		\begin{split}
		dY_t&=\left(\dpartial{v}{t}(t,X_t)+\mathcal{L}_t v(t,X_t)\right)dt+\sigma(t,X_t)' D_x v(t,X_t)\cdot dW_t\\
		&=-f(t,X_t,v(t,X_t,D_x v(t,X_t)))dt+\sigma(t,X_t)' D_x v(t,X_t) \cdot dW_t\\
		&=-f(t,X_t,Y_t,Z_t)dt+Z_t dW_t
		\end{split}
	\end{equation}
and observing that $Y_T=v(T,X_T)=g(X_T)$, we have the first part, as this process is in $\Sspa\times \Hspa$ due to the growth condition of $v$ and $D_x v$.
\end{proof}

Nevertheless, the reciprocal affirmation y somewhat more complicated. If we have a solution $(Y_t,Z_t)$ to the FBSDE \eqref{eqn:Uncoupled}, not necessarily $v(t,x)=Y_{t}^{t,x}$ will be a classical smooth solution to \eqref{eqn:FKNolineal} as it may not exist due to the non-linearity. Nevertheless, we can define a new weaker notion of solution as follows 
\begin{definition}
	Let $v(t,x):\bbR\times \bbR^n\to \bbR$ be a locally bounded continuous function. Then 
	\begin{itemize}
		\item $v(t,x)$ is called a viscosity sub-solution of \eqref{eqn:FKNolineal} if $v(T,x)\leq g(x)$ for $x\in\bbR^n$, and for all $\phi\in C^{1,2}([0,T]\times \bbR^n)$ such that the map $v(t,x)-\phi(t,x)$ attains a local maximum at $(t,x)\in [0,T]\times \bbR^n$ it holds
		\begin{equation}
			\dpartial{\phi}{t} +\mathcal{L}_t \phi +f(t,x,v(x,t),\sigma(t,x)'D_x v(t,x))\geq 0
		\end{equation}
		\item $v(t,x)$ is called a viscosity super-solution of \ref{eqn:FKNolineal} if $v(T,x)\geq g(x)$ for $x\in\bbR^n$, and for all $\phi\in C^{1,2}([0,T]\times \bbR^n)$ such that the map $v(t,x)-\phi(t,x)$ attains a local minimum at $(t,x)\in [0,T]\times \bbR^n$ it holds
	    \begin{equation}
		\dpartial{\phi}{t} +\mathcal{L}_t \phi +f(t,x,v(x,t),\sigma(t,x)'D_x v(t,x))\leq 0
	    \end{equation}
        \item If $v(t,x)$ is a sub-solution and a super-solution it is called a viscosity solution of \eqref{eqn:FKNolineal}.
	\end{itemize}
\end{definition}
In particular, note that this definition does not require the smoothness of $v(t,x)$.

With this new concept of solution, we can establish the reverse relation as follows
\begin{theorem}[Representation theorem \cite{pham_continuous-time_2009}]
	\label{thm:KFnonReps}
	\hlc[Poner explicitas las condiciones para la FBSDE]{} Let $(X,Y,Z)$ be the solution to the uncoupled FBSDE \eqref{eqn:Uncoupled} and set $v(t,x)=Y_{t}^{t,x}$. Then, $v$ is a continuous function and is a viscosity solution to \ref{eqn:FKNolineal}.
\end{theorem}
\begin{proof}
	\textit{Step 1: Continuity of $v(t,x)$}: \\
	Let $(t_1,x_1),(t_2,x_2)\in [0,T]\times \bbR^n$, with $t_1\leq t_2$. For lighten the notation we write $X_{s}^i=X_s^{t_i,x_i}$, $i=1,2$.
	
	\begin{equation}
		\begin{aligned}
			\left|Y_t^1-Y_t^2\right|^2= & \left|g\left(X_T^1\right)-g\left(X_T^2\right)\right|^2-\int_t^T\left|Z_s^1-Z_s^2\right|^2 d s \\
			& +2 \int_t^T\left(Y_s^1-Y_s^2\right) \cdot\left(f\left(s, X_s^1, Y_s^1, Z_s^1\right)-f\left(s, X_s^2, Y_s^2, Z_s^2\right)\right) d s \\
			& -2 \int_t^T\left(Y_s^1-Y_s^2\right)^{\prime}\left(Z_s^1-Z_s^2\right) d W_s
		\end{aligned}
	\end{equation}
Then,

\begin{equation}
	\begin{aligned}
		& E\left[\left|Y_t^1-Y_t^2\right|^2\right]+E\left[\int_t^T\left|Z_s^1-Z_s^2\right|^2 d s\right] \\
		= & E\left[\left|g\left(X_T^1\right)-g\left(X_T^2\right)\right|^2\right] \\
		& +2 E\left[\int_t^T\left(Y_s^1-Y_s^2\right) \cdot\left(f\left(s, X_s^1, Y_s^1, Z_s^1\right)-f\left(s, X_s^2, Y_s^2, Z_s^2\right)\right) d s\right] \\
		\leq & E\left[\left|g\left(X_T^1\right)-g\left(X_T^2\right)\right|^2\right] \\
		& +2 E\left[\int_t^T\left|Y_s^1-Y_s^2\right|\left|f\left(s, X_s^1, Y_s^1, Z_s^1\right)-f\left(s, X_s^2, Y_s^1, Z_s^1\right)\right| d s\right] \\
		& +2 C_f E\left[\int_t^T\left|Y_s^1-Y_s^2\right|\left(\left|Y_s^1-Y_s^2\right|+\left|Z_s^1-Z_s^2\right|\right) d s\right] \\
		\leq & E\left[\left|g\left(X_T^1\right)-g\left(X_T^2\right)\right|^2\right] \\
		& +E\left[\int_t^T\left|f\left(s, X_s^1, Y_s^1, Z_s^1\right)-f\left(s, X_s^2, Y_s^1, Z_s^1\right)\right|^2 d s\right] \\
		& +\left(1+4 C_f^2\right) E\left[\int_t^T\left|Y_s^1-Y_s^2\right|^2 d s+\frac{1}{2} E \int_t^T\left|Z_s^1-Z_s^2\right|^2 d s\right],
	\end{aligned}
\end{equation}

So, using the Gronwall's lemma we obtain

\begin{equation}
	\begin{aligned}
		E\left[\left|Y_t^1-Y_t^2\right|^2\right] \leq & E\left[\left|g\left(X_T^1\right)-g\left(X_T^2\right)\right|^2\right]+E\left[\int_t^T\left|f\left(s, X_s^1, Y_s^1, Z_s^1\right)-f\left(s, X_s^2, Y_s^1, Z_s^1\right)\right|^2 d s\right] \\
		& +\left(1+4 C_f^2\right) E\left[\int_t^T\left|Y_s^1-Y_s^2\right|^2 d s\right]
	\end{aligned}
\end{equation}
and, by Gronwall's lemma,
\begin{equation}
	\begin{aligned}
		E\left[\left|Y_t^1-Y_t^2\right|^2\right] \leq C & \left\{E\left[\left|g\left(X_T^1\right)-g\left(X_T^2\right)\right|^2\right]\right. \\
		& \left.+E\left[\int_t^T\left|f\left(s, X_s^1, Y_s^1, Z_s^1\right)-f\left(s, X_s^2, Y_s^1, Z_s^1\right)\right|^2 d s\right]\right\} .
	\end{aligned}
\end{equation}
This, combined with the continuity of $f$ and $g$ in $x$, and the continuity of $X^{t,x}$ in $(t,x)$, shows the mean-squared continuity of $Y_{s}^{t,x}$, and so the continuity of the map $(t,x)\to v(t,x)$.
\textit{Step 2: $v(t,x)$ is a viscosity solution.}\\
Let's prove it is a super-solution. Assume by contradiction that
\begin{equation}
	-\frac{\partial \varphi}{\partial t}(t, x)-\mathcal{L} \varphi(t, x)-f\left(t, x, v(t, x),\left(D_x \varphi\right)^{\prime}(t, x) \sigma(x)\right)>0.
\end{equation}
By continuity of $f, \varphi$ and its derivatives, there exists $h, \varepsilon>0$ such that for all $t \leq s \leq$ $t+h,|x-y| \leq \varepsilon$,
$$
\begin{aligned}
	\label{eqn:618}
	& v(s, y) \leq \varphi(s, y) \\
	&-\frac{\partial \varphi}{\partial t}(s, y)-\mathcal{L} \varphi(s, y)-f\left(s, y, v(s, y),\left(D_x \varphi\right)^{\prime}(s, y) \sigma(y)\right)>0 .
\end{aligned}
$$
Let $\tau=\inf \left\{s \geq t:\left|X_s^{t, x}-x\right| \geq \varepsilon\right\} \wedge(t+h)$, and consider the pair
$$
\left(Y_s^1, Z_s^1\right)=\left(Y_{s \wedge \tau}^{t, x}, 1_{[0, \tau]}(s) Z_s^{t, x}\right), \quad t \leq s \leq t+h
$$
By construction, $\left(Y_s^1, Z_s^1\right)$ solves the BSDE
$$
\begin{aligned}
	-d Y_s^1 & =1_{[0, \tau]}(s) f\left(s, X_s^{t, x}, u\left(s, X_s^{t, x}\right), Z_s^1\right) d s-Z_s^1 d W_s, \quad t \leq s \leq t+h, \\
	Y_{t+h}^1 & =u\left(\tau, X_\tau^{t, x}\right)
\end{aligned}
$$
On the other hand, the pair
$$
\left(Y_s^2, Z_s^2\right)=\left(\varphi\left(s, X_{s \wedge \tau}^{t, x}\right), 1_{[0, \tau]}(s) D_x \varphi\left(s, X_s^{t, x}\right)^{\prime} \sigma\left(X_s^{t, x}\right)\right), \quad t \leq s \leq t+h
$$
satisfies, by It√¥'s formula, the BSDE
$$
\begin{aligned}
	-d Y_s^2 & =-1_{[0, \tau]}(s)\left(\frac{\partial \varphi}{\partial t}+\mathcal{L} \varphi\right)\left(s, X_s^{t, x}\right)-Z_s^2 d W_s, \quad t \leq s \leq t+h, \\
	Y_{t+h}^1 & =\varphi\left(\tau, X_\tau^{t, x}\right) .
\end{aligned}
$$
From the inequalities \eqref{eqn:618}, and the strict comparison principle, we deduce $Y_0^1<Y_0^2$, i.e. $u(t, x)<\varphi(t, x)$, then we have a contradiction.
\end{proof}
Note that this representation can be restated in a more similar form to the linear Feynman-Kac formula as
\begin{theorem}[]
	\label{thm:NonlinealFK}
	Under assumptions the same assumptions as \ref{thm:KFnonReps}, the function defined by 
	\begin{equation}
		v(t, x):=Y_t^{t, x}=\mathbb{E}\left[g\left(X_T^{t, x}\right)+\int_t^T f\left(s, X_s^{t, x}, Y_s^{t, x}, Z_s^{t, x}\right) d s\right],
	\end{equation}
where $(X_t,Y_T,Z_T)$ is the solution to the FBSE \ref{eqn:Uncoupled} restricted to $[t,T]$, is a viscosity solution to the parabolic PDE \eqref{eqn:FKNolineal}.
\end{theorem}

Finally, we can state a similar informal result for nonlinear equations in a bounded domain with boundary conditions in analogy with \autoref{thm:LinearFKBoundary}. 

\begin{theorem}[ \cite{pardoux_stochastic_2014}]
	\label{thm:FKRelfected}
Under the same hypothesis of \autoref{thm:verficationThm} and assuming $v$ is a classical solution that also satisfies the Dirichlet and Neumann conditions as in \autoref{thm:LinearFKBoundary} with $h_n(t,x)=0$, then the pair $(Y_t=v(t,X_t))$, $Z_t=\sigma(t,X_t)'D_x v(t,X_t)$ is the solution to a backward stochastic differential equation similar to \eqref{eqn:Uncoupled} with the forward process reflected at the Neumann boundary and stopped at the first time it hits the Dirichlet boundary. And conversely, if $(X,Y,Z)$ is a solution to the BSDE with the forward process reflecting at the Neumann boundary and stopped at the Dirichlet boundary, then $v(t,x):=Y_{t}^{t,x}$ is continuous and is a viscosity solution to the nonlinear PDE that also satisfies boundary conditions. 
	
\end{theorem}

