Partial differential equations (PDE's) are ubiquitous among the tools for modeling complex phenomena in all sciences. However, we almost never have explicit solutions for them, making it difficult to describe those phenomenons and make accurate predictions about them. Hence, we need numerical methods to provide approximate solutions to those equations, for example, classical methods are finite differences, finite elements and spectral methods. Those rely on different discretizations of the particular problem that  we can use for calculating approximations in different forms and with varying levels of accuracy. Since the advent of fast computers and efficient tools for programming them, this process is effective for many kinds of problems.   

Now, when we attempt to solve numerically some particular problem, we need to play with the trade-off between accuracy of the approximate solution and the computational cost needed to obtain it. Indeed, with those classical methods, a small approximation error requires a finer grid, which implies more computational resources to store and process the information required by the method. In consequence, for some problems, we may not be able to calculate an accurate enough solution in a feasible computational time.

This is the case for high dimensional PDE's, for which the size of discretization usually scales exponentially with the number of points used for each dimension. For example, if we try to use a finite difference scheme in a $100$-dimensional unit square $[0,1]^{100}$ with $N$ points in each dimension, we would need $N^{100}$ points in total, making it impossible to even store them in a computer. In practice, high dimension can be considered as low as $d>4$, for which traditional methods cannot be used as regularly. This problem is known as the \textit{curse of dimensionality}, a term established by Bellman when considering problems in dynamic programming.

High dimensional PDE's appear in many contexts, such as asset pricing, image denoising, statistical physics, many-body quantum mechanics, optimal control and game theory. Therefore, there is a necessity for numerical methods that are able to overcome this difficulty. Early attempts to solve this kind of problems used the connection between stochastic diffusions and parabolic PDE's, as we seemed in the preceding chapter. In fact, if the PDE is linear, the linear Feynman-Kac \ref{thm:LinearFK} formula can be used to provide an approximate solution by computing the expectation using simulated paths of the process through the  Monte-Carlo approach. The convergence of this formulation is \hlc[Sure?]{independent} of the dimension of the underlying process, and therefore does not suffer from the curse dimensionality.

Nevertheless, if we try a similar approach using the non-linear Feynman-Kac formula \ref{thm:NonlinealFK} for more general non-linear equations, we would have to deal with solving numerically the associated BSDE. There are numerical methods to approximate the set of solution processes $(X,Y,Z)$, but they are not as simple as an Euler-Maruyama discretization for a forward process. Generally, they require the computation of conditional expectations that almost never are computationally cheap and hence is not a straightforward generalization of the former linear approach. Despite this, some progress has been made under this formulation, see for example \cite{chessari_numerical_nodate}. Other solutions methods are based in fixed point iterations and branching methods \cite{bibid}.

Representing functions in a high dimensional space is a problem encountered in many other areas of applied mathematics. Particularly, in recent times, the analysis and inference on big amounts of data has emerged as the fascinating research area of \textit{machine learning}. Many methods have been proposed for this goal, for example, regression methods, support vector machines and tree methods. Nonetheless, the approach that has encountered more success when trying to approximate high dimensional functions using big amounts of data is deep learning.  In this setting, we parametrize functions using structures that use composition of simpler function for approximate complex ones, these structures are called neural networks. We refer the reader to \autoref{chp:ApendixNN} for a brief introduction and to \cite{higham_deep_2019} for a deeper exposition of the topic.

The idea of using this neural network parametrization of functions to solve PDE's can be tracked to the 80's, when in \cite{} a perceptron layer approximation was proposed to \hlc[Completar]{}. However, due to the high computational cost of training a neural network, a successful attempt was not achieved until recently, with the works of \cite{bibid}\hlc[Blablabla]{}. 

This is a very new area of research, for which many open questions remain. Particularly, it is not well understood yet if the curse of dimensionality is solved, even if there is work for certain equations that ensures it \cite{bibid}. Also, there is not yet a good understanding of why different classes of neural networks are useful to approximate certain classes of functions and how to tune adequately its parameters to do it efficiently. In consequence, even if it is possible to give a convergence proof for certain cases, most algorithms rely on empirical experimentation and heuristic arguments to provide reasonable approximate solutions.    

In this chapter we review some of these methods, implement them for toy examples and perform a comparison of speed, accuracy and practical usefulness for solving PDE's.   

\section{Unbounded problems}
Let's start with problems in free space. In the same setup as \autoref{thm:verficationThm}, we deal with the following equation with terminal condition
\begin{equation}
	\label{eqn:FKNolinealCh2}
	\begin{split}
		&\dpartial{v}{t}(t,x)+\mu(t,x)\cdot D_x v(t,x)+\frac{1}{2}\Tr(\sigma(t,x)\sigma^{T}(t,x)D_{xx}^2v(t,x))\\
		&+f(t,x,v(t,x),\sigma(t,x)' D_x v(t,x))=0\\
		&v(T,x)=g(x),
	\end{split}
\end{equation}
that can also be written as 
\begin{equation}
	\label{eqn:FKNolinealLCh2}
	\begin{split}
	&\dpartial{v}{t}(t,x)+\mathcal{L}_t v(t,x)+f(t,x,v(t,x),\sigma(t,x)' D_x v(t,x))=0\\
	&v(T,x)=g(x),
   \end{split}
\end{equation}
using the infinitesimal generator $\mathcal{L}_t$ of the forward process $X$ as in \eqref{eqn:ininitesimalGen}.

We have proven that we can construct a viscosity solution to this equation by setting $v(t,x)=Y_{t}^{t,x}$, where $Y$ is the solution process to the FBSDE
\begin{equation}
	\label{eqn:UncoupledCh2}
	\begin{split}
		&dX_s=\mu(s,X_s)ds+\sigma(s,X_s)dW_s\\
		&X_t=x,\\
		&dY_s=-f(s,X_s,Y_s,Z_s)ds+Z_s dW_s\\
		&Y_T=g(X_T).
	\end{split}
\end{equation}
Moreover, we have that $Y_t=v(t,X_t)$ and $Z_t=\sigma(t,X_t)'D_x v(t,X_t)$.
\subsection{Deep BSDE method}
The first deep learning algorithm that was successfully applied to solve equation \eqref{eqn:FKNolinealCh2} was proposed by Han, E and Jentzen \cite{han_solving_2018,e_deep_2017}. This algorithm aims to approximate $Y_0=v(0,x)$ for some point $x\in \bbR^n$, and is similar in spirit to the stochastic shooting method for ODE's.

Here we discretize the time domain $0=t_0<t_1<\cdots <t_{N-1}<t_N=T$ and the FBSDE system a  forward equation using the Euler-Maruyama scheme for $n=0,\ldots,N-1$,
\begin{equation}
	\label{eqn:EMForward}
	X_{t_{n+1}} \approx X_{t_n} +\mu\left(t_n, X_{t_n}\right) \Delta t_n+\sigma\left(t_n, X_{t_n}\right) \Delta W_n
\end{equation}
and 
\begin{equation}
	\label{eqn:EMBackward}
	\begin{aligned}
		 v\left(t_{n+1}, X_{t_{n+1}}\right)
		&\approx  v\left(t_n, X_{t_n}\right) -f\left(t_n, X_{t_n}, v\left(t_n, X_{t_n}\right), \sigma'\left(t_n, X_{t_n}\right) D_x v\left(t_n, X_{t_n}\right)\right) \Delta t_n \\
		& +\sigma\left(t_n, X_{t_n}\right)'D_x u\left(t_n, X_{t_n}\right)  \Delta W_n,
	\end{aligned}
\end{equation}
where $\Delta t_n=t_{n+1}-t_{n}$ and $\Delta W_n\sim \mathcal{N}(0,\Delta t_n)$.

The main idea of this algorithm is to transform the problem in a learning one approximating the unknown product $\sigma\left(t_n, X_{t_n}\right)'D_x u\left(t_n, X_{t_n}\right)$ with a fully coupled neural network for each time step, i.e
\begin{equation}
	\sigma\left(t_n, X_{t_n}\right)'D_x u\left(t_n, X_{t_n}\right) \approx \mathcal{Z}_n(X_{t_n}|\theta_n),
\end{equation}
where $\theta_n$ denotes the parameters of the neural network at time $t_n$. Each one of these networks receives as inputs the simulated paths \eqref{eqn:EMForward} and therefore its input layers have $d$ neurons.   Furthermore, the desired solution $v(0,x)$ and its derivative $D_x v(0,x)$ also will be parameters to be learned in the model, it means $v(0,x)\approx \theta_{v_0}$ and $D_x v(0,x)\approx \theta_{D_x v_0}$. Thus, the total set of parameters to be optimized is 
\begin{equation}
	\theta=\{\theta_{v_0}, \theta_{D_x v_0},\theta_1,\theta_2,\cdots,\theta_n \}.
\end{equation}
If we need the solution $v(0,x)$ for all $x$ in some region $\Omega$, we can choose to parametrize $v(0,x)\approx \theta_{v_0}$ with a neural network and simulate the process $X_t$ with random initial conditions in $\Omega$.

The set of parameters will be optimized such that the stacked solution $\hat{u}(\{X_{t_n}\}_{0}^{N},\{W_{t_n}\}_{0}^{N})$, constructed with \eqref{eqn:EMBackward}, resembles the terminal condition $g(X_{t_N})$. This is achieved defining the loss function 
\begin{equation}
	\label{eqn:lossDeepBSDE}
	\ell(\theta)=\expect*{|g(X_{t_N})-\hat{u}(\{X_{t_n}\}_{0}^N,\{W_{t_n}\}_{0}^N)|^2},
\end{equation}
which will be minimized using deep learning standard methods for training, for example, the ADAM optimizer.

The overall method can be thought as a constrained minimization problem of the form
\begin{equation}
	\label{eqn:constrainedDeepBSDE}
	\begin{split}
		&\inf_{\theta}\hat{u}(\{X_{t_n}\}_{0}^{N},\{W_{t_n}\}_{0}^{N})\\
		s.t \quad & X_0=\xi ,\quad Y_0=\theta_{v_0}\\
		& 		X_{t_{n+1}} = X_{t_n} +\mu\left(t_n, X_{t_n}\right) \Delta t_n+\sigma\left(t_n, X_{t_n}\right) \Delta W_n\\
		&Z_{t_n}=\mathcal{Z}_n(X_{t_n})\\
		&Y_{t_{n+1}}=Y_{t_n}-f(t_n,X_{t_n},Y_{t_n},Z_{t_n})\Delta t +Z_{t_n}'\Delta W_{n}
	\end{split}
\end{equation}
where $\xi$ is random variable uniformly distributed on $\Omega$. And it can be summarized in the diagram shown in figure \ref{fig:deepbsdemap}.
\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{images/DeepBSDEMap}
	\caption{Deep BSDE diagram \cite{chan-wai-nam_machine_2018}. In red are the parameters to be optimized in the algorithm \hlc[Hay que cambiar $\kappa_i$]{}}
	\label{fig:deepbsdemap}
\end{figure}

The convergence of this algorithm has been proved in \cite{han_convergence_2020} for fully coupled FBSDEs. The assumptions needed are very general, and the proof is rather technical, so for the sake of brevity, we only state some imprecise results.

Denote by $X_t,Y_t,Z_t$ the exact solution to the FBSDE \eqref{eqn:UncoupledCh2}, and by $X_{t_i}^\pi,Y_{t_i}^\pi,Y_{t_i}^\pi$ the discrete solution to the constrained optimization problem \eqref{eqn:constrainedDeepBSDE}. Also, let's denote $h=\max_{i}\Delta t_i$. The first result states that the simulation error can be bounded through the value of the loss function \eqref{eqn:lossDeepBSDE}.
\begin{theorem}[Error of discretization is bounded by loss function \cite{han_convergence_2020}]
	Under some assumptions, there exist a constant $C$, independent of $h$, $d$ and $n$, such that for sufficiently small $h$
	$$
	\sup _{t \in[0, T]}\left(E\left|X_t-\hat{X}_t^\pi\right|^2+E\left|Y_t-\hat{Y}_t^\pi\right|^2\right)+\int_0^T E\left|Z_t-\hat{Z}_t^\pi\right|^2 \mathrm{~d} t \leq C\left[h+E\left|g\left(X_T^\pi\right)-Y_T^\pi\right|^2\right]
	$$
	where $\hat{X}_t^\pi=X_{t_i}^\pi, \hat{Y}_t^\pi=Y_{t_i}^\pi, \hat{Z}_t^\pi=Z_{t_i}^\pi$ for $t \in\left[t_i, t_{i+1}\right)$
\end{theorem}   

The second result establishes that the optimal value of the loss function can be small if the approximation capability of the family of parametric functions (neural networks) is good enough. Denote by $\mathcal{N}_0'$ and $\{\mathcal{N}_i\}_{0}^{N-1}$ the parametric function spaces generated by neural networks, then we have
\begin{theorem}[Optimal loss function is bounded by approximation error \cite{han_convergence_2020}]
Under some assumptions, there exists a constant $C$, independent of $\Delta t, d$ and $n$, such that for sufficiently small $\Delta t$,
	$$
	\begin{aligned}
		& \inf _{\mu_0^\pi \in \mathcal{N}_0^{\prime}, \phi_i^\pi \in \mathcal{N}_i} E\left|g\left(X_T^\pi\right)-Y_T^\pi\right|^2 \\
		& \leq C\left\{h+\inf _{\mu_0^\pi \in \mathcal{N}_0^{\prime}, \phi_i^\pi \in \mathcal{N}_i}\left[E\left|Y_0-\mu_0^\pi(\xi)\right|^2\right.\right. \\
		&\left.\left.+\sum_{i=0}^{N-1} E\left|E\left[\tilde{Z}_{t_i} \mid X_{t_i}^\pi, Y_{t_i}^\pi\right]-\phi_i^\pi\left(X_{t_i}^\pi, Y_{t_i}^\pi\right)\right|^2 h\right]\right\},
	\end{aligned}
	$$
	where $\tilde{Z}_{t_i}=h^{-1} E\left[\int_{t_i}^{t_{i+1}} Z_t \mathrm{~d} t \mid \mathcal{F}_{t_i}\right]$. If $\mu$ and $\sigma$ are independent of $Y$, the term $E\left[\tilde{Z}_{t_i} \mid X_{t_i}^\pi, Y_{t_i}^\pi\right]$ can be replaced with $E\left[\tilde{Z}_{t_i} \mid X_{t_i}^\pi\right]$.
\end{theorem}

Neural networks are a promising candidate for such approximation space of functions, as there are results in regard
to the universal approximation and complexity of neural networks\hlc[Completar referencias]{}.

Note that, in practice, we cannot minimize exactly the loss function in the space of parametric functions, as the methods we use are generally iterative. Also, it is not known how better is the approximation depending on the width, deep and connections of the neural network, so the capability of approximation is not well understood yet. Therefore, this results only establish the convergence of the method in a general setting and are not useful for estimate the real velocity of convergence, the achievable loss in the training stage, nor the real accuracy of the approximate solution.  

Now, we highlight the major drawbacks of this method 
\begin{enumerate}
	\item The number of neural networks to train grows linearly with the number of time steps in the discretization, making it very computationally costly to use small time steps.
	\item We only have a full solution at time $t=0$. At intermediate times we only have approximate solutions evaluated on sample paths $v(t,X_t)$. Therefore, we would need many of them to represent accurately the solution in the desired region.
	\item Moreover, nothing guarantees that this intermediate steps resembles accurately the real solutions in between steps. This requirement is not well encoded in the loss function.
	\item The time structure of the problem is not reflected in the separate approximations for each step, at least not directly.
	\item It may be unstable or converge to saddle points, see \cite{hure_deep_2020}.
\end{enumerate}     

Moreover, the structure of the neural networks is crucial for the practical convergence of the algorithm. The original work by \cite{han_solving_2018} used fully coupled neural networks with 3 layers, the $relu$ activation function and batch normalization, this structure is represented in figure \ref{fig:FCStructure}. However, many changes can be made to accelerate the process of training or to achieve lower optimal losses. All of them are inspired by practical evidence and currently there is not enough understanding of how to choose theoretically the hyperparameters to reach the best convergence we can. Some of these modifications are explained below.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\linewidth,height=5cm]{images/FCStructure}
	\caption{Neural network structure \cite{chan-wai-nam_machine_2018}.\hlc[Hay que cambiar $\kappa_i$ Mejor hago la mia :(]{}}
	\label{fig:FCStructure}
\end{figure}

\subsubsection*{Merged Deep BSDE}
The first such modification was proposed in \cite{chan-wai-nam_machine_2018}. In this work, the authors propose to use a single neural network to approximate the $Z$ process for all time steps. Thus, this reduced model has less parameters to optimize, making this process faster, and also adds regularity to the computed gradients, which means that close in time parametrizations should be close for a given $x$.

Moreover, it was noted that using all information available at time $t$, like $Y_t$ and $g(X_t)$, increases the performance and optimal loss. Thus, in order to merge all neural networks in a single one, we have to add new dimensions to the neural network to include the additional variables, hence we use a neural network $\mathcal{N}^{\theta}:(t,x)\in \bbR^{n+3}\to\bbR^n$ that uses $(t_n,Y_{t_n},g(X_{t_n}),X_{t_n})$ as inputs to approximate $Z_{t_{n}}$ for each $t_n$ in the discretization. Note that $Z_0$ is also obtained through such network and therefore is not longer a parameter to be optimized. This process is summarized in the figure \ref{fig:mergeddeepbsdemap}.
\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{images/MergedBSDE}
	\caption{Merged Deep BSDE diagram \cite{chan-wai-nam_machine_2018}. In red are the parameters to be optimized in the algorithm \hlc[Hay que cambiar $\kappa_i$]{}}
	\label{fig:mergeddeepbsdemap}
\end{figure}

The structure of the neural network needs to be adapted to this new setup. In this case, the activation functions may be changed for the ELU function and batch normalization was not performed after each layer as the process in no longer stationary. This structure is represented in figure \ref{fig:MergedStructure}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\linewidth,height=5cm]{images/MergedStructure}
	\caption{Neural network structure for merged BSDE \cite{chan-wai-nam_machine_2018}.\hlc[Hay que cambiar $\kappa_i$ Mejor hago la mia :(]{}}
	\label{fig:MergedStructure}
\end{figure}
\subsubsection*{Residual Merged Deep BSDE}
Finally, another useful modification to the merged deep BSDE scheme was to modify the network structure adding shortcut connections between layers. This new configuration is represented in figure \ref{fig:ResidualMergedStructure}.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\linewidth,height=5cm]{images/ResidualMergedStructure}
	\caption{Neural network structure for merged residual BSDE \cite{chan-wai-nam_machine_2018}.\hlc[Hay que cambiar $\kappa_i$ Mejor hago la mia :(]{}}
	\label{fig:ResidualMergedStructure}
\end{figure}
\subsection{Raissi's method}
To circumvent some of the problems encountered with the deep BSDE method and its variants, Raissi \cite{raissi_forward-backward_2018} proposed a new scheme based on the same stochastic formulation. In this approach, the solution $v(t,x)$ is directly approximated with a neural network $\mathcal{N}(x,t)$ that takes as inputs $x$ and $t$ instead of its gradient as before. 

Now, the constraints on problem \eqref{eqn:constrainedDeepBSDE} are relaxed and they are enforced weakly through the neural network loss function given by

\begin{equation}
	\begin{gathered}
		\ell(\theta):=\mathbb{E}\left[\sum_{i=0}^{N-1} \Phi\left(t_i, X_{t_i}, Y_{t_i}, Y_{t_{i+1}}, \Delta W_{t_{i}}\right)+\left(g\left(X_{t_N}\right)-Y_{t_N}\right)^2\right] \\
	\end{gathered}
\end{equation}
where 
\begin{equation}
	\begin{split}
		\Phi\left(t_i, X_{t_i}, Y_{t_i}, Y_{t_{i+1}}, \Delta W_{t_i}\right)&=\left(Y_{t_{i+1}}-Y_{t_i}+f\left(t_i, X_{t_i}, Y_{t_i}, \sigma'\left(t_i, X_{t_i}\right) \widehat{Z}_{t_i}\right)\left(\Delta t_i\right)\right. \\
		&\left.-\widehat{Z}_{t_i}' \sigma\left(t_i, X_{t_i}\right)\left(\Delta W_{t_i}\right)\right)^2,
	\end{split}
\end{equation}
and $\widehat{Z}_{t_i}$ is calculated with automatic differentiation in the neural network $\widehat{Z}_{t_i}=\hat{D}\mathcal{N}(t_i,X_{t_i})$. With this approach we can compute the solution at all times $t$ and point in space $x$.
\subsection{An example}
Let's test those algorithms with a toy problem from control theory using the Hamilton-Jacobi-Bellman equation. For completeness, we briefly review the standard formulation of such problems in \autoref{chp:ApendixStochasticControl}.


We will perform a non-exhaustive comparison between the preceding algorithms by solving, just for fun, the Hamilton-Jacobi-Bellman equation associated to a linear-quadratic regulator in dimension 6.

Suppose that we have three stochastic particles in the plane, whose common state is described by the stochastic process $X_t=(\vec{x}_1,\vec{x}_2,\vec{x}_3)=(x_1,y_1,x_2,y_2,x_3,y_3)\in\bbR^6$, that satisfies the linear dynamics given by 
\begin{equation}
	\begin{split}
		&dX_t=2\sqrt{\lambda}\alpha_t dt+\sqrt{2\nu}dW_t\\
		&X_0=x_0,
	\end{split} 
\end{equation} 
where $\alpha_t$ is a joint control you can select for all particles individually and $\lambda$, $\nu$ are constants representing the strength of the control we exert and the magnitude of noise the particles feel from its environment.  

We wish to bring the three particles to the origin of the plane at time $T=1.0$, i.e the desired terminal state is $X_t=(0,0,0,0,0,0)$, while trying to avoid that the particles are close to each other during their trajectories. Thus, we will try to choose $\alpha_t$ to minimize the cost
\begin{equation}
	J(\alpha_t)=\mathbb{E}\left[\int_{0}^{T}(|\alpha_t|^2+F(t,X_t)) dt +g(X_T)\right],
\end{equation}   
where we model the avoiding condition with the $F(t,X_t)$ term given by
\begin{equation}
	F(t,X_t)=F(t,(\vec{x}_1,\vec{x}_2,\vec{x}_3))=C\left(e^{-\frac{|\vec{x}_1-\vec{x}_2|^2}{\sigma}}+e^{-\frac{|\vec{x}_1-\vec{x}_3|^2}{\sigma}}+e^{-\frac{|\vec{x}_2-\vec{x}_3|^2}{\sigma}}\right),
\end{equation}
with $C,\sigma$ given constants, and we also model the desired terminal condition through the terminal cost $g(X_T)$ given by 
\begin{equation}
	g(x)=|x-(0,0,0,0,0,0)|^2=|x|^2.
\end{equation}

Therefore, as described in \autoref{chp:ApendixStochasticControl}, to solve this problem we may try to solve the Hamilton-Jacobi-Bellman equation for the value function $V(t,x)$
\begin{equation}
	\label{eqn:HJB_example}
	\dpartial{V}{t}+\nu \Delta V -\lambda |\nabla V|^2+F(t,x)=0
\end{equation}
subject to the terminal condition 
\begin{equation}
	V(T,x)=g(x).
\end{equation}

Note that we have access to a probabilistic representation of such value function given by \eqref{eqn:probabilisticExact}. We may simulate sample paths to calculate the expected value at a given space-time point using the Monte-Carlo approach. However, this is not very useful for our purposes as we require the optimal controls $\hat{\alpha}(t,x)=-\sqrt{\lambda}D_x V(t,x)$, and with this representation we do not have access to such gradient of the solution.\footnote{Please ignore the fact that we can obtain analytically the expected value with the known density of Brownian motion, i.e. the heat kernel, and then take its derivative to obtain the desired controls, as nobody would want to perform such long and tedious calculation.} Despite this, it will be useful to test the convergence of our numerical methods comparing the obtained solutions in a single point.

Note also that it is not very practical to apply traditional discretization methods as finite differences or finite elements. The first problem we face is that the domain is not bounded, and even if we focus on some small region of interest with artificial boundary condition, the discretization of a 6-dimensional space is not computationally feasible.

Thus, we may interpret this problem in the framework previously developed. To do that, note that \eqref{eqn:HJB_example} is the same as \eqref{eqn:FKNolinealCh2} if we choose
\begin{equation}
	\mu(t,x)=0\quad \quad \sigma(t,x)=\sqrt{2\nu} \mathbb{I}_{6\times 6}
\end{equation}
and 
\begin{equation}
	f(t,x,V(t,x),\sigma(t,x)'D_x V(t,x))=-\lambda |D_x V|^2+F(t,x).
\end{equation}

Therefore, we can apply the deep BSDE solver and all its variants to solve this PDE. We implemented these in the Python language using the Pytorch framework with its automatic differentiation and neural networks capabilities.

In this example we use $\lambda=1.0$ and $\nu=0.05$. 
For all methods, we discretized time using a step of $\Delta t=0.05$. The sample paths were simulated using the Euler-Maruyama scheme and they look like \autoref{fig:sample_path_example}.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{example-image}
	\caption{Sample path for the 6-dimensional diffusion}
	\label{fig:sample_path_example}
\end{figure}



We trained all neural networks using the ADAM optimizer with a learning rate of $\eta=0.01$ and using batches of 64 sample paths to calculate the expectations in loss functions. 

In the deep BSDE method, for every subnet approximating $Z_{t_n}$  we used a fully coupled neural network with 2 layers with 16 neurons each, using a batch normalization layer in between to prevent gradients exploding and the ReLu as activation function. We also parametrize the initial solution and its gradient with fully coupled neural networks with the same structure as before.

\begin{figure}[htb!]		
	\begin{subfigure}{.475\linewidth}
		\includegraphics[width=\linewidth]{example-image}
		\caption{Deep BSDE training loss}
		\label{fig:BSDE_loss}
	\end{subfigure}\hfill % <-- "\hfill"
	\begin{subfigure}{.475\linewidth}
		\includegraphics[width=\linewidth]{example-image}
		\caption{Deep BSDE training error}
		\label{fig:BSDE_error}
	\end{subfigure}
	\caption{Losses and error in training Deep BSDE method }
	\label{fig:deep_BSDE_training}
\end{figure}

In the merged deep BSDE method, we use a 3 layer fully coupled neural network with 20 neurons in each layer, with the ELU activation function to parametrize the mapping $(t,x)\to Z(t,x)$. 

\begin{figure}[htb!]
	\begin{subfigure}{.475\linewidth}
		\includegraphics[width=\linewidth]{example-image}
		\caption{Merged Deep BSDE training loss}
		\label{fig:Merged_loss}
	\end{subfigure}\hfill % <-- "\hfill"
	\begin{subfigure}{.475\linewidth}
		\includegraphics[width=\linewidth]{example-image}
		\caption{Merged Deep BSDE training error}
		\label{fig:Merged_error}
	\end{subfigure}
	\caption{Losses and error in training Merged Deep BSDE method }
	\label{fig:deep_Merged_BSDE_training}
\end{figure}

In the residual merged deep BSDE method, we use a 3 layer fully coupled neural network with 20 neurons in each layer, with the ELU activation function, and with a shortcut connection as depicted in \autoref{fig:ResidualMergedStructure} to parametrize the mapping $(t,x)\to Z(t,x)$. 

\begin{figure}[htb!]
	\begin{subfigure}{.475\linewidth}
		\includegraphics[width=\linewidth]{example-image}
		\caption{Merged residual Deep BSDE training loss}
		\label{fig:Merged_residual_loss}
	\end{subfigure}\hfill % <-- "\hfill"
	\begin{subfigure}{.475\linewidth}
		\includegraphics[width=\linewidth]{example-image}
		\caption{Merged residual Deep BSDE training error}
		\label{fig:Merged_residual_error}
	\end{subfigure}
	\caption{Losses and error in training Merged Residual Deep BSDE method }
	\label{fig:deep_Merged_Residual_BSDE_training}
\end{figure}

In \autoref{fig:deep_BSDE_training}, \autoref{fig:deep_Merged_BSDE_training} and \autoref{fig:deep_Merged_Residual_BSDE_training}, we depict the training losses with respect to a fixed sample path and the error at the point $x=(0.5,0,0,0.5,0.5,0.5)$ at $t=0$, compared with the exact solution calculated using \eqref{eqn:probabilisticExact} with 20000 sample paths, for those three methods.

For the Raissi's method we used a 4 layer fully coupled neural network with 15 neurons in each layers to parametrize the approximated solution $\varphi(t,x)$. We note that this method is not well suited for computing gradients and therefore controls, as the automatic differentiation of the parametrized solution is slow and not very precise. In \autoref{fig:Raissi_training} we depict training and error losses with the same criteria as before.
 \begin{figure}[htb!]		
 	\begin{subfigure}{.475\linewidth}
 		\includegraphics[width=\linewidth]{example-image}
 		\caption{Raissi's training loss}
 		\label{fig:Raissi_loss}
 	\end{subfigure}\hfill % <-- "\hfill"
 	\begin{subfigure}{.475\linewidth}
 		\includegraphics[width=\linewidth]{example-image}
 		\caption{Raissi's training error}
 		\label{fig:Raissi_error}
 	\end{subfigure}
 	\caption{Losses and error in training Raissi's method }
 	\label{fig:Raissi_training}
 \end{figure}
 
 In \autoref{fig:surface_solution} we depict the surface solution in a region of interest at $t=0$ using the deep BSDE algorithm. In  \autoref{fig:Optimal_trajectory_path} an optimal controlled path is shown.
  \begin{figure}[htb!]		
 	\begin{subfigure}{.475\linewidth}
 		\includegraphics[width=\linewidth]{example-image}
 		\caption{Surface solution}
 		\label{fig:surface_solution}
 	\end{subfigure}\hfill % <-- "\hfill"
 	\begin{subfigure}{.475\linewidth}
 		\includegraphics[width=\linewidth]{example-image}
 		\caption{Optimal controlled sampled path}
 		\label{fig:Optimal_trajectory_path}
 	\end{subfigure}
 	\caption{}
 	\label{fig:solution_path}
 \end{figure}
Finally, in \autoref{tab:ComparisonBSDE} we resume all this information for a vague comparison.
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		Method & \# Parameters & reached error & reached loss & time \\
		\hline
		Deep BSDE & 0 & 10 & 10 & 33 \\
		\hline
		Merged  & 0 & 10 & 10 & 33 \\
		\hline
		Merged Residual & 0 & 10 & 10 & 33 \\
		\hline
		Raissi & 0 & 10 & 10 & 33 \\
		\hline
	\end{tabular}
\caption{}
\label{tab:ComparisonBSDE}
\end{table}

We note that when we optimize the parameters of the neural networks, there is maximum achievable error depending on the network structure and time discretization size. In this toy example we reached an estimated error with order of magnitude $10^{-2}$. Fewer error would require more epochs in the training stage and smaller time step.

\section{Bounded problems}
In this section, we consider PDE's with boundary conditions of the form 
\begin{subequations}
	\label{eqn:PDEBoundaryCh2}
	\begin{equation}
		\begin{split}
			&\dpartial{v}{t}(t,x)+\mathcal{L}v(t,x)+f(t,x,v(t,x),\sigma(t,x)' D_x v(t,x))=0
		\end{split}
	%\tag{\ref{eqn:PDEBoundaryCh2}}
	\end{equation}
with terminal condition 
\begin{equation}
	\label{eqn:terminalBoundary}
	v(T,x)=g(x) \quad \forall x\in \Omega ,
\end{equation}
and Dirichlet and Neumman conditions
\begin{align}
	&v(t,x)=h_d(x) \quad \forall x\in \Gamma_D \text{ and } \forall t\in[0,T] \label{eqn:DirichletBoundary}\\
	&\dpartial{v}{n}(t,x)=h_n(x) \quad \forall x\in \Gamma_N \text{ and } \forall t\in[0,T] \label{eqn:NeumanBoundary},
\end{align}
\end{subequations}
where $\Omega$ is a bounded domain, regular enough for a solution to exist, and $\Gamma_D \dot{\cup} \Gamma_N=\partial \Omega$. Here again $\mathcal{L}$ represents the infinitesimal generator of the process $X$ that is solution to \eqref{eqn:UncoupledCh2}. 

We will assume the following
\begin{assumptions}
	\label{ass:BoundaryExistence}
	The following holds
	\begin{enumerate}[I.] 
		\item The domain $\Omega$ is bounded with piecewise smooth boundary
		\item The boundary problem \eqref{eqn:PDEBoundaryCh2} admits a unique classical solution $v\in C^{1,2}([0,t]\times \Omega) \cap C(\bar{\Omega} \times [0,T])$. Moreover, the gradient of $v$ satisfies a polynomial growth condition in $x$, i.e , $|D_x v(t,x)|\leq C (1+|x|^p)$ for $(t,x)\in [0,T]\times \Omega$ and some $C,q\geq 0$
		\item The forward process in \eqref{eqn:UncoupledCh2} admits a unique strong solution globally in time.
		\end{enumerate}
\end{assumptions}

If, in addition to the PDE, we impose Neumman/Dirichlet boundary conditions, the previous approaches must be modified because the Feynman-Kac formula does not account for them explicitly. We will try two different approaches.
\subsection{Deep Galerkin method}
The first approach is named the deep Galerkin method (DGM) and was proposed in \cite{sirignano_dgm_2018}. This method is also called Physics Informed Neural Networks (PINN's). It does not rely on a probabilistic representation of the solution, but on the explicit form \eqref{eqn:PDEBoundaryCh2}.

The DGM algorithm approximates the solution $v(t,x)$ with a deep neural network $\varphi(t,x|\theta)$, where $\theta$ are the network's parameters. We will choose this function aiming to minimize the loss function given by
\begin{equation}
	\label{eqn:DGMLoss}
	\begin{split}
			\mathcal{L}(\varphi):=&\alpha_{int}\mathcal{L}_{\text{DGM,int}}(\varphi)+\alpha_{T}\mathcal{L}_{\text{DGM,T}}(\varphi)+\alpha_{d}\mathcal{L}_{\text{DGM,d}}(\varphi)+\alpha_{n}\mathcal{L}_{\text{DGM,n}}(\varphi) \\
			:=&\alpha_{int}\norm{\dpartial{\varphi}{t}+\mathcal{L}\varphi+f(t,x,\varphi(t,x),\sigma(t,x)'D_x \varphi(t,x))}_{[0,T]\times \Omega,\nu_1}^2\\
			+&\alpha_{T}\norm{\varphi(T,x|\theta)-g(x)}_{\Omega,\nu_2}^2\\
			+&\alpha_{d}\norm{\varphi(t,x)-h_d(x)}_{[0,T]\times \partial \Gamma_D,\nu_3 }^2\\
			+&\alpha_{n}\norm{\hat{n}\cdot D_x \varphi(t,x)-h_n(x)}_{[0,T]\times \partial \Gamma_N,\nu_4 }^2
	\end{split},
\end{equation}
where we use the notation for the norms $\norm{f(y)}_{\mathcal{Y},\nu}^2=\int_{\mathcal{Y}}|f(y)|^2d\nu$, given a positive probability density $\nu$ on $\mathcal{Y}$. Here, $J(\varphi)$ measure how well $\phi$ satisfies the PDE with its initial and boundary conditions weighted by the $\alpha$ coefficients. If $J(\varphi)=0$, then $\varphi$ is a solution to \eqref{eqn:PDEBoundaryCh2}.

To obtain the minimizing parameters $\theta$, we will perform a training procedure of the neural network with a stochastic gradient descent algorithm. We will sample points according to $\nu_1,\nu_2,\nu_3,\nu_4$ and calculate a Monte-Carlo approximation of the functional loss \eqref{eqn:DGMLoss} using automatic differentiation to calculate the derivatives appearing in the PDE operator and boundary conditions. With this approximation, we will take a descent step in the gradient direction calculated again using automatic differentiation. 

Using the universal approximation theorem for single layer neural networks and some standard assumptions on the behavior of the problem, we can establish the strong convergence in $L^2(\Omega\times [0,T])$ of this algorithm as the number of neurons in the layer tends to infinity, assuming we are able to find exactly the optimal parameters of the network in each size. The reader may consult  \cite{sirignano_dgm_2018} for such proof.

However, the practical convergence presents difficulties as it depends strongly on a set of well-chosen hyper-parameters, such as the learning rate of the descent method, the batch sizes, the weights in the loss function, the network architecture, as well as the sampling densities. There is not a straightforward way to choose such parameters, thus the convergence is 

Note also that there is a big operational cost involved in the computation of derivatives appearing in the loss function through automatic differentiation. For operators using fully coupled second order derivatives, this cost becomes prohibitive in high dimensions. Therefore, we need alternatives for problems with these restrictions.
\subsection{Interpolating BSDEs with PINNs}
To circumvent these issues, we may combine the powerful ideas of stochastic representation of solutions of PDEs with the forcing technique used in the PINNs approach. This method was proposed by \cite{nusken_interpolating_2023}, and its main idea is to define a parameter to interpolate between the losses used by each scheme to combine the strengths of both. In the same spirit of the last methods, we parameterize the PDE's solution by a neural network $\phi$ and try to adjust its parameters to give a good enough approximation of the desired solution.

In this method, we use the Ito's formula applied to $v(X_t,t)$ to obtain
\begin{equation}
	\label{eqn:itoV}
	v(T,X_T)-v(0,X_0)=\int_{0}^{T}\left(\dpartial{}{s}+\mathcal{L}\right)v(s,X_s)ds+\int_{0}^{T}\sigma'D_x v(s,X_s)\cdot dW_s,
\end{equation}
and, inspired in this relation for the interior process and the forcing of boundary conditions used in the DGM method, we aim to minimize the \textit{diffusion loss} with interpolation parameter $\mathrm{t}\in(0,\infty)$ defined as
\begin{equation}
	\mathcal{L}_{\text {diff }}^{\mathrm{t}}(\varphi)=\alpha_{\text {int }} \mathcal{L}_{\text {diff,int }}^{\mathrm{t}}(\varphi)+\alpha_{\mathrm{T}} \mathcal{L}_{\text {diff, } \mathrm{T}}^{\mathrm{t}}(\varphi)+\alpha_{\mathrm{d}} \mathcal{L}_{\text {diff, } \mathrm{d}}^{\mathrm{t}}(\varphi)+\alpha_{\mathrm{n}} \mathcal{L}_{\text {diff, } \mathrm{n}}^{\mathrm{t}}(\varphi)
\end{equation}
where
\begin{equation}
	\begin{aligned}
		& \mathcal{L}_{\text {diff,int }}^{\mathrm{t}}(\varphi)=\mathbb{E}\left[\left(\varphi\left(\mathcal{T},X_{\mathcal{T}} \right)-\varphi\left(t_0,X_{t_0}\right)-\int_{t_0}^{\mathcal{T}} \sigma^{\top} \nabla \varphi\left(s,X_s\right) \cdot \mathrm{d} W_s\right.\right. \\
		& \left.\left.+\int_{t_0}^{\mathcal{T}} f\left(s,X_s, \varphi\left(s,X_s\right), \sigma^{\top} \nabla \varphi\left(s,X_s\right)\right) \mathrm{d} s\right)^2\right] \text {, } \\
		& \mathcal{L}_{\text {diff,T }}^{\mathrm{t}}(\varphi)=\mathbb{E}\left[\left(\varphi\left(T,X^{(T)}\right)-g\left(X^{(T)}\right)\right)^2\right] \\
		& \mathcal{L}_{\text {diff, } \mathrm{d}}^{\mathrm{t}}(\varphi)=\mathbb{E}\left[\left(\varphi\left(t^{\mathrm{d}},X^{\mathrm{d}}\right)-h_d\left(t^{\mathrm{d}},X^{\mathrm{d}}\right)\right)^2\right], \\
		&
		\mathcal{L}_{\text {diff, } \mathrm{n}}^{\mathrm{t}}(\varphi)=\mathbb{E}\left[\left(D_x\varphi\left(t^{\mathrm{n}},X^{\mathrm{n}} \right)-h_n\left(t^{\mathrm{n}},X^{\mathrm{n}}\right)\right)^2\right]. \\
	\end{aligned}
\end{equation}

Here, the process $(X_t)_{0\leq t\leq \mathcal{T}}$ is the solution to \eqref{eqn:UncoupledCh2} with initial condition $(X_0,t_0)\sim \nu_{\Omega\times [0,T]}$, where $\nu_{\Omega\times [0,T]}$ is a measure with full support on $\Omega\times[0,T]$,  and maximal trajectory length $\mathrm{t}>0$. In addition, the stopping time $\mathcal{T}:=(t_0+\mathrm{t})\wedge \tau \wedge T$ refers to the random final time associated with the realization of the path $X_t$ when it either hit the boundary at time $\tau=\inf\{t>0: X_t\notin\Omega\}$ or runs for $t_0+\mathrm{t}$ or reaches time $T$. Furthermore, using the same notation as in the case of DGM, $X^{(T)} \sim \nu_{2}$, $(t^{\mathrm{n}},X^{\mathrm{d}})\sim \nu_{3}$ and $(t^\mathrm{n},X^{\mathrm{n}})\sim \nu_{4}$.

In this case, the data inside the domain is not sampled as points with distribution $\nu_1$ as in DGM, but along trajectories of the diffusion. Hence, we do not need to calculate second derivatives of $\varphi$ explicitly trough automatic differentiation, but are approximated using the underlying process $X_t$. Note also that using a maximal trajectory length we avoid computing large first exit times that may arise depending on $\Omega$ or long simulation times if $T$ is large. 

Now, let's prove that this loss function is indeed suitable for the problem \eqref{eqn:PDEBoundaryCh2}.
\begin{theorem}[\cite{nusken_interpolating_2023}]
	Let $\mathcal{F}\subset C^{1,2}([0,t]\times \Omega) \cap C(\bar{\Omega} \times [0,T])$ be the function space of neural networks. Then, under assumptions \ref{ass:FBSDEexistence} and \ref{ass:BoundaryExistence}, for $\varphi\in \mathcal{F}$, the following are equivalent
	\begin{enumerate}[I.]
		\item $\varphi$ fulfills the boundary value problem
		\item The difussion loss vanishes on $\varphi$ 
		\begin{equation}
			\mathcal{L}_{\text{diff}}^{\mathrm{t}}(\varphi)=0
		\end{equation}
	 \eqref{eqn:PDEBoundaryCh2}.
	\end{enumerate}
\end{theorem}
\begin{proof}
	
	$I \implies II)$ Assume that $\varphi$ satisfies \eqref{eqn:PDEBoundaryCh2} and $X_s$ is the strong solution to the forward process \eqref{eqn:UncoupledCh2}, then, by Ito's formula, we have
\begin{equation}
	\varphi(\mathcal{T},X_\mathcal{T})=v(0,X_0)+\int_{t_0}^{\mathcal{T}}\left(\dpartial{}{s}+\mathcal{L}\right)\varphi(s,X_s)ds+\int_{t_0}^{\mathcal{T}}\sigma'D_x \varphi(s,X_s)\cdot dW_s,
\end{equation}
almost surely. It follows that $\mathcal{L}_{\text{diff,int}}^{\mathrm{t}}(\varphi)=0$, and similarly, as $\varphi$ satisfies terminal and boundary conditions, we have $\mathcal{L}_{\text{diff,T}}^{\mathrm{t}}(\varphi)=\mathcal{L}_{\text{diff,d}}^{\mathrm{t}}(\varphi)=\mathcal{L}_{\text{diff,n}}^{\mathrm{t}}(\phi)=0$, so $\mathcal{L}_{\text{diff}}^{\mathrm{t}}(\varphi)=0$

$II \implies I)$ Observe that $\mathcal{L}_{\text{diff,int}}^{\mathrm{t}}(\varphi)=0$ implies that 
\begin{equation}
	\label{eqn:itoPhi}
	\varphi(\mathcal{T},X_\mathcal{T})=\varphi(0,X_0)+\int_{t_0}^{\mathcal{T}}\sigma'D_x\varphi(s,X_s)\cdot dW_s-\int_{t_0}^{\mathcal{T}}f(s,X_s \varphi(s,X_s),\sigma' D_x \varphi(s,X_s))ds,
\end{equation}
almost surely, and note that the same holds for $\phi$ replaced by $v$ \eqref{eqn:itoV}. Now, define the processes $\tilde{Y}_s=\phi(s,X_s)$,$\tilde{Z}_s=\sigma'D_x \phi(s,X_s)$ and $Y_s=v(s,X_s)$,$Z_s=\sigma'D_x v(s,X_s)$. Observe that those are $W_{t}-$progressively measurable and square integrable. Moreover, \eqref{eqn:itoPhi} and \eqref{eqn:itoV} means that they satisfy a BSDE with terminal condition $\xi=\varphi(\mathcal{T},X_\mathcal{T})$ on $[t_0,\mathcal{T}]$. Thus, by the uniqueness of solution in \autoref{thm:linearBSDE}, we have that $Y=\tilde{Y}$ and $Z=\tilde{Z}$. Observe also that $v(t_{0},X_{t_0})=Y^{t_0,X_{t_0}}=\tilde{Y}^{t_0,X_{t_0}}=\varphi(t_0,X_{t_0})$. Hence, we conclude that $v=\varphi$ $\nu_{\Omega}\times [0,T]-$ almost surely, and thus $\varphi$ is the solution to \eqref{eqn:PDEBoundaryCh2} using that $\nu_{\Omega\times[0,T]}$ has full support.
\end{proof}

By the other hand, observe that this diffusion loss, in the case of an unbounded problem, where $\alpha_d=\alpha_n=0$, is an interpolation between the weak BSDE loss defined as
\begin{equation}
	\begin{aligned}
			\mathcal{L}_{BSDE}=\mathbb{E}\Big[\Big(g(X_T)&-\varphi(t_0,X_{t_0})-\int_{t_0}^{T}\sigma'D_x \varphi (s,X_s)\cdot dW_s\\ &+\int_{t_0}^{T}f(s,X_s,\varphi(s,X_s),\sigma'D_x \varphi(s,X_s)ds)\Big)^2\Big]
	\end{aligned}
\end{equation}
and the DGM loss as the following theorem shows.
\begin{theorem}[\cite{nusken_interpolating_2023}]
	Let $\phi\in \mathcal{F}$. Assuming that the sampling distributions $\nu_1$ for interior points in the DGM loss and $\nu_{\Omega\times [0,t]}$ for starting points in the BSDE and diffusion losses coincide, then we have 
	\begin{enumerate}[I.]
		\item \begin{equation}
			\frac{\mathcal{L}_{\text{diff, int}}(\varphi)}{\mathrm{t}^2}\to \mathcal{L}_{DGM,int}(\varphi)
		\end{equation} as $\mathrm{t}\to 0$
		\item \begin{equation}
			\mathcal{L}_{\text{diff, int}}(\varphi)\to \mathcal{L}_{BSDE}(\varphi)
		\end{equation} as $\mathrm{t}\to \infty$
	\end{enumerate} 
\end{theorem}
\begin{proof}
	For $I)$ note that the interior part of the diffusion loss can be written as 
	\begin{equation}
		\mathcal{L}_{\text {diff,int }}^{\mathrm{t}}(\varphi)=\mathbb{E}\left[\left(\int_{t_0}^{\mathcal{T}}\left(\dpartial{}{s}+\mathcal{L}\right)\varphi(s,X_s)ds
		+\int_{t_0}^{\mathcal{T}} f\left(s,X_s, \varphi\left(s,X_s\right), \sigma^{\top} \nabla \varphi\left(s,X_s\right)\right) \mathrm{d} s\right)^2\right] \text {, }
	\end{equation} and that $\mathcal{T}\to t_0$ as $\mathrm{t}\to 0$ almost surely, then by the dominated convergence theorem $I$ follow. Moreover, note that $\mathcal{T}\to T$ as $\mathrm{t}\to\infty$ almost surely, thus $II)$  holds.
\end{proof}

In practice, we use the same strategy as in the DGM algorithm. We simulate paths  of the $X_t$ process to estimate the interior diffusion loss using Monte-Carlo method. We approximate the integral by using, for example, the Euler-Maruyama scheme. Furthermore, we sample points according to $\nu_2,\nu_3,\nu_4$ to estimate the losses associated to boundary and terminal conditions, using automatic differentiation when necessary. 

With this estimation of the loss, we take gradient descent steps to reduce sequentially the total error and obtain a good approximation of the solution. However, there is almost no theory about what are the optimal hyperparameters, as the weights in the loss, the learning rate, length of the sample paths or network architecture to be chosen in the algorithm to converge optimally, so empirical experience is needed to obtain approximations efficiently.


\subsection{An example}
In our implementation of these methods for boundary problems we saw that they were significantly harder than unbounded problems. The convergence of those algorithms was very dependent on hyperparameters such as learning rate, sample points distribution, weigths in the losses and network structure. Even for simple domains it was difficult to find parameters that worked. What is worse, as these methods parametrize directly the solution and not its gradient, they cannot be used to calculate accurately controls dependent on the space derivative, because it is generally not well approximated.   

Thus, just for illustration of the methods for a very simple case, consider a modification of the preceding example. We wish to find the control function for a single particle that would take them to the exit door of an empty room in the least amount of time. In \autoref{fig:EmptyRoom} is depicted the domain considered, with some sample paths used for the training process.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{example-image}
	\caption{Domain}
	\label{fig:EmptyRoom}
\end{figure}

In this case, we would want to solve the HJB equation
\begin{equation}
	\label{eqn:HJB2D}
	\dpartial{V}{t}+\nu \Delta V -\lambda |\nabla V|^2+1=0
\end{equation} 
subject to the Dirichlet and Neumann conditions
\begin{equation}
	V(t,x)=0 \quad \text{ for } x\in \partial\Omega_d, 
\end{equation}
\begin{equation}
	\dpartial{V}{\vec{n}}(t,x)=0 \quad \text{ for } x\in \partial\Omega_n, 
\end{equation}
and the terminal condition
\begin{equation}
	V(1.0,x)=0 \quad \text{ for } x\in \Omega.
\end{equation}

The constant $1$ in the equation \eqref{eqn:HJB2D} models a steady running cost that will impulse the particle to exit the domain faster. The Dirichlet condition at the door implies that a process that reaches this part of the boundary will stay there without increasing its running cost. The Neumann boundary conditions represent the condition that the process is bounded in the room, which means that it is reflected along those boundary points when touched. Finally, the terminal condition implies that there is no cost in ending at every other part of the room. 


