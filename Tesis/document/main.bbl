% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{none/global//global/global}
    \entry{higham_deep_2019}{article}{}
      \name{author}{2}{}{%
        {{hash=794dc0781d5c862fe8d567e564bdbd1a}{%
           family={Higham},
           familyi={H\bibinitperiod},
           given={Catherine\bibnamedelima F.},
           giveni={C\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
        {{hash=595c1684f5fe70f9a29914bdda6d2e9e}{%
           family={Higham},
           familyi={H\bibinitperiod},
           given={Desmond\bibnamedelima J.},
           giveni={D\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{e17027d1dfcef26462d04886515cd994}
      \strng{fullhash}{e17027d1dfcef26462d04886515cd994}
      \strng{bibnamehash}{e17027d1dfcef26462d04886515cd994}
      \strng{authorbibnamehash}{e17027d1dfcef26462d04886515cd994}
      \strng{authornamehash}{e17027d1dfcef26462d04886515cd994}
      \strng{authorfullhash}{e17027d1dfcef26462d04886515cd994}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Multilayered artiﬁcial neural networks are becoming a pervasive tool in a host of application ﬁelds. At the heart of this deep learning revolution are familiar concepts from applied and computational mathematics; notably, in calculus, approximation theory, optimization and linear algebra. This article provides a very brief introduction to the basic ideas that underlie deep learning from an applied mathematics perspective. Our target audience includes postgraduate and ﬁnal year undergraduate students in mathematics who are keen to learn about the area. The article may also be useful for instructors in mathematics who wish to enliven their classes with references to the application of deep learning techniques. We focus on three fundamental questions: what is a deep neural network? how is a network trained? what is the stochastic gradient method? We illustrate the ideas with a short {MATLAB} code that sets up and trains a network. We also show the use of state-of-the art software on a large scale image classiﬁcation problem. We ﬁnish with references to the current literature.}
      \field{issn}{0036-1445, 1095-7200}
      \field{journaltitle}{{SIAM} Review}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{3}
      \field{shortjournal}{{SIAM} Rev.}
      \field{shorttitle}{Deep Learning}
      \field{title}{Deep Learning: An Introduction for Applied Mathematicians}
      \field{urlday}{26}
      \field{urlmonth}{9}
      \field{urlyear}{2022}
      \field{volume}{61}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{860\bibrangedash 891}
      \range{pages}{32}
      \verb{doi}
      \verb 10.1137/18M1165748
      \endverb
      \verb{file}
      \verb Higham y Higham - 2019 - Deep Learning An Introduction for Applied Mathema.pdf:/home/carlos/Zotero/storage/YTREYN46/Higham y Higham - 2019 - Deep Learning An Introduction for Applied Mathema.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://epubs.siam.org/doi/10.1137/18M1165748
      \endverb
      \verb{url}
      \verb https://epubs.siam.org/doi/10.1137/18M1165748
      \endverb
    \endentry
    \entry{raissi_physics-informed_2019}{article}{}
      \name{author}{3}{}{%
        {{hash=a3194cb4f8e3959e569236521aa2fd86}{%
           family={Raissi},
           familyi={R\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=c2e8423b7b49343a85abf9af92ee2a82}{%
           family={Perdikaris},
           familyi={P\bibinitperiod},
           given={P.},
           giveni={P\bibinitperiod}}}%
        {{hash=1c2f5930e36485e8d38a87746769fdcc}{%
           family={Karniadakis},
           familyi={K\bibinitperiod},
           given={G.\bibnamedelimi E.},
           giveni={G\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \strng{namehash}{a17a0649dc8bad70026488d4ea37c508}
      \strng{fullhash}{a17a0649dc8bad70026488d4ea37c508}
      \strng{bibnamehash}{a17a0649dc8bad70026488d4ea37c508}
      \strng{authorbibnamehash}{a17a0649dc8bad70026488d4ea37c508}
      \strng{authornamehash}{a17a0649dc8bad70026488d4ea37c508}
      \strng{authorfullhash}{a17a0649dc8bad70026488d4ea37c508}
      \field{sortinit}{7}
      \field{sortinithash}{108d0be1b1bee9773a1173443802c0a3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.}
      \field{day}{1}
      \field{issn}{0021-9991}
      \field{journaltitle}{Journal of Computational Physics}
      \field{langid}{english}
      \field{month}{2}
      \field{shortjournal}{Journal of Computational Physics}
      \field{shorttitle}{Physics-informed neural networks}
      \field{title}{Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations}
      \field{urlday}{30}
      \field{urlmonth}{5}
      \field{urlyear}{2023}
      \field{volume}{378}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{686\bibrangedash 707}
      \range{pages}{22}
      \verb{doi}
      \verb 10.1016/j.jcp.2018.10.045
      \endverb
      \verb{file}
      \verb ScienceDirect Snapshot:/home/carlos/Zotero/storage/565WBVVH/S0021999118307125.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0021999118307125
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0021999118307125
      \endverb
      \keyw{Data-driven scientific computing,Machine learning,Nonlinear dynamics,Predictive modeling,Runge–Kutta methods}
    \endentry
    \entry{sirignano_dgm_2018}{article}{}
      \name{author}{2}{}{%
        {{hash=63a950b98d85daffb2acb228fc44a30b}{%
           family={Sirignano},
           familyi={S\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod}}}%
        {{hash=b3f57aca002dd1e7484cf81299998414}{%
           family={Spiliopoulos},
           familyi={S\bibinitperiod},
           given={Konstantinos},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{fb5add8979e6ca053be0b10341d44fe1}
      \strng{fullhash}{fb5add8979e6ca053be0b10341d44fe1}
      \strng{bibnamehash}{fb5add8979e6ca053be0b10341d44fe1}
      \strng{authorbibnamehash}{fb5add8979e6ca053be0b10341d44fe1}
      \strng{authornamehash}{fb5add8979e6ca053be0b10341d44fe1}
      \strng{authorfullhash}{fb5add8979e6ca053be0b10341d44fe1}
      \field{sortinit}{7}
      \field{sortinithash}{108d0be1b1bee9773a1173443802c0a3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{High-dimensional {PDEs} have been a longstanding computational challenge. We propose to solve highdimensional {PDEs} by approximating the solution with a deep neural network which is trained to satisfy the diﬀerential operator, initial condition, and boundary conditions. Our algorithm is meshfree, which is key since meshes become infeasible in higher dimensions. Instead of forming a mesh, the neural network is trained on batches of randomly sampled time and space points. The algorithm is tested on a class of high-dimensional free boundary {PDEs}, which we are able to accurately solve in up to 200 dimensions. The algorithm is also tested on a high-dimensional Hamilton-Jacobi-Bellman {PDE} and Burgers’ equation. The deep learning algorithm approximates the general solution to the Burgers’ equation for a continuum of diﬀerent boundary conditions and physical conditions (which can be viewed as a high-dimensional space). We call the algorithm a “Deep Galerkin Method ({DGM})” since it is similar in spirit to Galerkin methods, with the solution approximated by a neural network instead of a linear combination of basis functions. In addition, we prove a theorem regarding the approximation power of neural networks for a class of quasilinear parabolic {PDEs}.}
      \field{issn}{00219991}
      \field{journaltitle}{Journal of Computational Physics}
      \field{langid}{english}
      \field{month}{12}
      \field{shortjournal}{Journal of Computational Physics}
      \field{shorttitle}{{DGM}}
      \field{title}{{DGM}: A deep learning algorithm for solving partial differential equations}
      \field{urlday}{10}
      \field{urlmonth}{10}
      \field{urlyear}{2022}
      \field{volume}{375}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1339\bibrangedash 1364}
      \range{pages}{26}
      \verb{doi}
      \verb 10.1016/j.jcp.2018.08.029
      \endverb
      \verb{file}
      \verb Sirignano y Spiliopoulos - 2018 - DGM A deep learning algorithm for solving partial.pdf:/home/carlos/Zotero/storage/HSUX3UV9/Sirignano y Spiliopoulos - 2018 - DGM A deep learning algorithm for solving partial.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0021999118305527
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0021999118305527
      \endverb
    \endentry
    \entry{li_fourier_2021}{misc}{}
      \name{author}{7}{}{%
        {{hash=009036050bf23abe561429f6eaa0b018}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Zongyi},
           giveni={Z\bibinitperiod}}}%
        {{hash=d3715d69863d59245589f244c5866bd4}{%
           family={Kovachki},
           familyi={K\bibinitperiod},
           given={Nikola},
           giveni={N\bibinitperiod}}}%
        {{hash=3648b51d63e1ae389e46f87296d4c89a}{%
           family={Azizzadenesheli},
           familyi={A\bibinitperiod},
           given={Kamyar},
           giveni={K\bibinitperiod}}}%
        {{hash=9caea1a7b561311e5146f4c7f740496c}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Burigede},
           giveni={B\bibinitperiod}}}%
        {{hash=1e523aae18c868f77439b35add494ff9}{%
           family={Bhattacharya},
           familyi={B\bibinitperiod},
           given={Kaushik},
           giveni={K\bibinitperiod}}}%
        {{hash=9fdd1b883dec513483f9ee5c99b7e251}{%
           family={Stuart},
           familyi={S\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=bd4a2be6ede169a3c794a1cd7e3fb9a2}{%
           family={Anandkumar},
           familyi={A\bibinitperiod},
           given={Anima},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{edf93f47ab09a8c56b86e9ad2e628607}
      \strng{fullhash}{3e58006f2c869702116637d04136c3b9}
      \strng{bibnamehash}{edf93f47ab09a8c56b86e9ad2e628607}
      \strng{authorbibnamehash}{edf93f47ab09a8c56b86e9ad2e628607}
      \strng{authornamehash}{edf93f47ab09a8c56b86e9ad2e628607}
      \strng{authorfullhash}{3e58006f2c869702116637d04136c3b9}
      \field{sortinit}{8}
      \field{sortinithash}{a231b008ebf0ecbe0b4d96dcc159445f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations ({PDEs}), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of {PDEs}, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first {ML}-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional {PDE} solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.}
      \field{day}{16}
      \field{eprinttype}{arxiv}
      \field{month}{5}
      \field{number}{{arXiv}:2010.08895}
      \field{title}{Fourier Neural Operator for Parametric Partial Differential Equations}
      \field{urlday}{10}
      \field{urlmonth}{10}
      \field{urlyear}{2022}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2010.08895 [cs, math]
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/carlos/Zotero/storage/SBBEPWWE/Li et al. - 2021 - Fourier Neural Operator for Parametric Partial Dif.pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/NDLMSUIA/2010.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2010.08895
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2010.08895
      \endverb
      \keyw{Computer Science - Machine Learning,Mathematics - Numerical Analysis}
    \endentry
    \entry{cuomo_scientific_2022}{misc}{}
      \name{author}{6}{}{%
        {{hash=a149dbc0c7d8c7b44289299d659521f4}{%
           family={Cuomo},
           familyi={C\bibinitperiod},
           given={Salvatore},
           giveni={S\bibinitperiod}}}%
        {{hash=9bc9686a73763abee74c1103182e61b4}{%
           family={Cola},
           familyi={C\bibinitperiod},
           given={Vincenzo\bibnamedelima Schiano},
           giveni={V\bibinitperiod\bibinitdelim S\bibinitperiod},
           prefix={di},
           prefixi={d\bibinitperiod}}}%
        {{hash=07970330b2a43b5c2e55ae13af5a7097}{%
           family={Giampaolo},
           familyi={G\bibinitperiod},
           given={Fabio},
           giveni={F\bibinitperiod}}}%
        {{hash=2b969effc2e931cc3f6118c144824d3f}{%
           family={Rozza},
           familyi={R\bibinitperiod},
           given={Gianluigi},
           giveni={G\bibinitperiod}}}%
        {{hash=95a17c39168b9e6b8812f207b4e036c1}{%
           family={Raissi},
           familyi={R\bibinitperiod},
           given={Maziar},
           giveni={M\bibinitperiod}}}%
        {{hash=5e071190ec9de33600de48969adb345b}{%
           family={Piccialli},
           familyi={P\bibinitperiod},
           given={Francesco},
           giveni={F\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ecacc4512ae1bd881356a9535bcb4121}
      \strng{fullhash}{27f0bb500f48733ffa04338eaf617bf2}
      \strng{bibnamehash}{ecacc4512ae1bd881356a9535bcb4121}
      \strng{authorbibnamehash}{ecacc4512ae1bd881356a9535bcb4121}
      \strng{authornamehash}{ecacc4512ae1bd881356a9535bcb4121}
      \strng{authorfullhash}{27f0bb500f48733ffa04338eaf617bf2}
      \field{sortinit}{9}
      \field{sortinithash}{0a5ebc79d83c96b6579069544c73c7d4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Physics-Informed Neural Networks ({PINN}) are neural networks ({NNs}) that encode model equations, like Partial Differential Equations ({PDE}), as a component of the neural network itself. {PINNs} are nowadays used to solve {PDEs}, fractional equations, integral-differential equations, and stochastic {PDEs}. This novel methodology has arisen as a multi-task learning framework in which a {NN} must fit observed data while reducing a {PDE} residual. This article provides a comprehensive review of the literature on {PINNs}: while the primary goal of the study was to characterize these networks and their related advantages and disadvantages. The review also attempts to incorporate publications on a broader range of collocation-based physics informed neural networks, which stars form the vanilla {PINN}, as well as many other variants, such as physics-constrained neural networks ({PCNN}), variational hp-{VPINN}, and conservative {PINN} ({CPINN}). The study indicates that most research has focused on customizing the {PINN} through different activation functions, gradient optimization techniques, neural network structures, and loss function structures. Despite the wide range of applications for which {PINNs} have been used, by demonstrating their ability to be more feasible in some contexts than classical numerical techniques like Finite Element Method ({FEM}), advancements are still possible, most notably theoretical issues that remain unresolved.}
      \field{day}{7}
      \field{eprinttype}{arxiv}
      \field{month}{6}
      \field{number}{{arXiv}:2201.05624}
      \field{shorttitle}{Scientific Machine Learning through Physics-Informed Neural Networks}
      \field{title}{Scientific Machine Learning through Physics-Informed Neural Networks: Where we are and What's next}
      \field{urlday}{5}
      \field{urlmonth}{10}
      \field{urlyear}{2022}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2201.05624 [physics]
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/carlos/Zotero/storage/H855KTYN/Cuomo et al. - 2022 - Scientific Machine Learning through Physics-Inform.pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/GDJA3DPU/2201.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2201.05624
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2201.05624
      \endverb
      \keyw{Computer Science - Machine Learning,Mathematics - Numerical Analysis,Computer Science - Artificial Intelligence,Physics - Data Analysis,Statistics and Probability}
    \endentry
    \entry{blechschmidt_three_2021}{article}{}
      \name{author}{2}{}{%
        {{hash=6213b438cffb8de57f89b006e11ed2c1}{%
           family={Blechschmidt},
           familyi={B\bibinitperiod},
           given={Jan},
           giveni={J\bibinitperiod}}}%
        {{hash=240a7f26b82eba0cbec8214e6287c703}{%
           family={Ernst},
           familyi={E\bibinitperiod},
           given={Oliver\bibnamedelima G.},
           giveni={O\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \strng{namehash}{1c18533cebbda08fb288ae5804f700a2}
      \strng{fullhash}{1c18533cebbda08fb288ae5804f700a2}
      \strng{bibnamehash}{1c18533cebbda08fb288ae5804f700a2}
      \strng{authorbibnamehash}{1c18533cebbda08fb288ae5804f700a2}
      \strng{authornamehash}{1c18533cebbda08fb288ae5804f700a2}
      \strng{authorfullhash}{1c18533cebbda08fb288ae5804f700a2}
      \field{sortinit}{9}
      \field{sortinithash}{0a5ebc79d83c96b6579069544c73c7d4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Neural networks are increasingly used to construct numerical solution methods for partial diﬀerential equations. In this expository review, we introduce and contrast three important recent approaches attractive in their simplicity and their suitability for high-dimensional problems: physics-informed neural networks, methods based on the Feynman-Kac formula and methods based on the solution of backward stochastic diﬀerential equations. The article is accompanied by a suite of expository software in the form of Jupyter notebooks in which each basic methodology is explained step by step, allowing for a quick assimilation and experimentation. An extensive bibliography summarizes the state of the art.}
      \field{issn}{0936-7195, 1522-2608}
      \field{journaltitle}{{GAMM}-Mitteilungen}
      \field{langid}{english}
      \field{month}{6}
      \field{number}{2}
      \field{shortjournal}{{GAMM}‐Mitteilungen}
      \field{title}{Three ways to solve partial differential equations with neural networks — A review}
      \field{urlday}{26}
      \field{urlmonth}{9}
      \field{urlyear}{2022}
      \field{volume}{44}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1002/gamm.202100006
      \endverb
      \verb{file}
      \verb Blechschmidt y Ernst - 2021 - Three ways to solve partial differential equations.pdf:/home/carlos/Zotero/storage/BSRAWXLL/Blechschmidt y Ernst - 2021 - Three ways to solve partial differential equations.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/10.1002/gamm.202100006
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/10.1002/gamm.202100006
      \endverb
    \endentry
    \entry{han_solving_2018}{article}{}
      \name{author}{3}{}{%
        {{hash=dcbed821c92a82aa9d46cf353c58ec62}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Jiequn},
           giveni={J\bibinitperiod}}}%
        {{hash=31ce46557e2d08499e8b06d041f40bf2}{%
           family={Jentzen},
           familyi={J\bibinitperiod},
           given={Arnulf},
           giveni={A\bibinitperiod}}}%
        {{hash=268e9715905f2ab3cb20df636d3750c1}{%
           family={E},
           familyi={E\bibinitperiod},
           given={Weinan},
           giveni={W\bibinitperiod}}}%
      }
      \strng{namehash}{d917cfee603f491b8bf02638f1d9d19c}
      \strng{fullhash}{d917cfee603f491b8bf02638f1d9d19c}
      \strng{bibnamehash}{d917cfee603f491b8bf02638f1d9d19c}
      \strng{authorbibnamehash}{d917cfee603f491b8bf02638f1d9d19c}
      \strng{authornamehash}{d917cfee603f491b8bf02638f1d9d19c}
      \strng{authorfullhash}{d917cfee603f491b8bf02638f1d9d19c}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Significance Partial differential equations ({PDEs}) are among the most ubiquitous tools used in modeling problems in nature. However, solving high-dimensional {PDEs} has been notoriously difficult due to the “curse of dimensionality.” This paper introduces a practical algorithm for solving nonlinear {PDEs} in very high (hundreds and potentially thousands of) dimensions. Numerical results suggest that the proposed algorithm is quite effective for a wide variety of problems, in terms of both accuracy and speed. We believe that this opens up a host of possibilities in economics, finance, operational research, and physics, by considering all participating agents, assets, resources, or particles together at the same time, instead of making ad hoc assumptions on their interrelationships. , Developing algorithms for solving high-dimensional partial differential equations ({PDEs}) has been an exceedingly difficult task for a long time, due to the notoriously difficult problem known as the “curse of dimensionality.” This paper introduces a deep learning-based approach that can handle general high-dimensional parabolic {PDEs}. To this end, the {PDEs} are reformulated using backward stochastic differential equations and the gradient of the unknown solution is approximated by neural networks, very much in the spirit of deep reinforcement learning with the gradient acting as the policy function. Numerical results on examples including the nonlinear Black–Scholes equation, the Hamilton–Jacobi–Bellman equation, and the Allen–Cahn equation suggest that the proposed algorithm is quite effective in high dimensions, in terms of both accuracy and cost. This opens up possibilities in economics, finance, operational research, and physics, by considering all participating agents, assets, resources, or particles together at the same time, instead of making ad hoc assumptions on their interrelationships.}
      \field{day}{21}
      \field{issn}{0027-8424, 1091-6490}
      \field{journaltitle}{Proceedings of the National Academy of Sciences}
      \field{langid}{english}
      \field{month}{8}
      \field{number}{34}
      \field{shortjournal}{Proc. Natl. Acad. Sci. U.S.A.}
      \field{title}{Solving high-dimensional partial differential equations using deep learning}
      \field{urlday}{26}
      \field{urlmonth}{9}
      \field{urlyear}{2022}
      \field{volume}{115}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{8505\bibrangedash 8510}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1073/pnas.1718942115
      \endverb
      \verb{file}
      \verb pnas.1718942115.pdf:/home/carlos/Descargas/pnas.1718942115.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://pnas.org/doi/full/10.1073/pnas.1718942115
      \endverb
      \verb{url}
      \verb https://pnas.org/doi/full/10.1073/pnas.1718942115
      \endverb
    \endentry
    \entry{bismut_conjugate_1973}{article}{}
      \name{author}{1}{}{%
        {{hash=eace1db2158ab018d2d2bb076c56909b}{%
           family={Bismut},
           familyi={B\bibinitperiod},
           given={Jean-Michel},
           giveni={J\bibinithyphendelim M\bibinitperiod}}}%
      }
      \strng{namehash}{eace1db2158ab018d2d2bb076c56909b}
      \strng{fullhash}{eace1db2158ab018d2d2bb076c56909b}
      \strng{bibnamehash}{eace1db2158ab018d2d2bb076c56909b}
      \strng{authorbibnamehash}{eace1db2158ab018d2d2bb076c56909b}
      \strng{authornamehash}{eace1db2158ab018d2d2bb076c56909b}
      \strng{authorfullhash}{eace1db2158ab018d2d2bb076c56909b}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{day}{1}
      \field{issn}{0022-247X}
      \field{journaltitle}{Journal of Mathematical Analysis and Applications}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{2}
      \field{shortjournal}{Journal of Mathematical Analysis and Applications}
      \field{title}{Conjugate convex functions in optimal stochastic control}
      \field{urlday}{21}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{volume}{44}
      \field{year}{1973}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{384\bibrangedash 404}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1016/0022-247X(73)90066-8
      \endverb
      \verb{file}
      \verb ScienceDirect Snapshot:/home/carlos/Zotero/storage/LPAD3QIB/0022247X73900668.html:text/html;Texto completo:/home/carlos/Zotero/storage/YYCCH67B/Bismut - 1973 - Conjugate convex functions in optimal stochastic c.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/0022247X73900668
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/0022247X73900668
      \endverb
    \endentry
    \entry{pardoux_adapted_1990}{article}{}
      \name{author}{2}{}{%
        {{hash=beb50fd846984359b348be4d69121f20}{%
           family={Pardoux},
           familyi={P\bibinitperiod},
           given={E.},
           giveni={E\bibinitperiod}}}%
        {{hash=ac7006e144f696982cf65b2368e9b59e}{%
           family={Peng},
           familyi={P\bibinitperiod},
           given={S.\bibnamedelimi G.},
           giveni={S\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \strng{namehash}{ca377fe79cb834ca805a5a3cd77da393}
      \strng{fullhash}{ca377fe79cb834ca805a5a3cd77da393}
      \strng{bibnamehash}{ca377fe79cb834ca805a5a3cd77da393}
      \strng{authorbibnamehash}{ca377fe79cb834ca805a5a3cd77da393}
      \strng{authornamehash}{ca377fe79cb834ca805a5a3cd77da393}
      \strng{authorfullhash}{ca377fe79cb834ca805a5a3cd77da393}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Let Wt; t ϵ [0, 1] be a standard k-dimensional Weiner process defined on a probability space (Ω, F, P), and let Ft denote its natural filtration. Given a F1 measurable d-dimensional random vector X, we look for an adapted pair of processes \{x(t), y(t); t ϵ [0, 1]\} with values in Rd and Rd×k respectively, which solves an equation of the form: x(t) + ∫t1f(s, x(s), y(s)) ds + ∫t1 [g(s, x(s)) + y(s)] {dWs} = X. A linearized version of that equation appears in stochastic control theory as the equation satisfied by the adjoint process. We also generalize our results to the following equation: x(t) + ∫t1f(s, x(s), y(s)) ds + ∫t1 g(s, x(s)) + y(s)) {dWs} = X under rather restrictive assumptions on g.}
      \field{day}{1}
      \field{issn}{0167-6911}
      \field{journaltitle}{Systems \& Control Letters}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{Systems \& Control Letters}
      \field{title}{Adapted solution of a backward stochastic differential equation}
      \field{urlday}{21}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{volume}{14}
      \field{year}{1990}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{55\bibrangedash 61}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1016/0167-6911(90)90082-6
      \endverb
      \verb{file}
      \verb ScienceDirect Snapshot:/home/carlos/Zotero/storage/K7LSR34R/0167691190900826.html:text/html;Texto completo:/home/carlos/Zotero/storage/XQ5TYGKE/Pardoux y Peng - 1990 - Adapted solution of a backward stochastic differen.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/0167691190900826
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/0167691190900826
      \endverb
      \keyw{adapted process,Backward stochastic differential equation}
    \endentry
    \entry{zhang_backward_2017}{book}{}
      \name{author}{1}{}{%
        {{hash=17f34ccb8b943a37fda9e3c1e404f6d9}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Jianfeng},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, {NY}}%
      }
      \list{publisher}{1}{%
        {Springer New York}%
      }
      \strng{namehash}{17f34ccb8b943a37fda9e3c1e404f6d9}
      \strng{fullhash}{17f34ccb8b943a37fda9e3c1e404f6d9}
      \strng{bibnamehash}{17f34ccb8b943a37fda9e3c1e404f6d9}
      \strng{authorbibnamehash}{17f34ccb8b943a37fda9e3c1e404f6d9}
      \strng{authornamehash}{17f34ccb8b943a37fda9e3c1e404f6d9}
      \strng{authorfullhash}{17f34ccb8b943a37fda9e3c1e404f6d9}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-1-4939-7254-8 978-1-4939-7256-2}
      \field{langid}{english}
      \field{series}{Probability Theory and Stochastic Modelling}
      \field{title}{Backward Stochastic Differential Equations}
      \field{urlday}{15}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{volume}{86}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-1-4939-7256-2
      \endverb
      \verb{file}
      \verb Zhang - 2017 - Backward Stochastic Differential Equations.pdf:/home/carlos/Zotero/storage/F6YQFTJV/Zhang - 2017 - Backward Stochastic Differential Equations.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-1-4939-7256-2
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-1-4939-7256-2
      \endverb
    \endentry
    \entry{pardoux_stochastic_2014}{book}{}
      \name{author}{2}{}{%
        {{hash=2f28ac591a047725e4340ab36bd8955e}{%
           family={Pardoux},
           familyi={P\bibinitperiod},
           given={Etienne},
           giveni={E\bibinitperiod}}}%
        {{hash=d420cdbe4cdc09cefe2b55d2d8b72ddb}{%
           family={Rӑşcanu},
           familyi={R\bibinitperiod},
           given={Aurel},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{4765bb24c67ec2d8037bb9a5ed16432f}
      \strng{fullhash}{4765bb24c67ec2d8037bb9a5ed16432f}
      \strng{bibnamehash}{4765bb24c67ec2d8037bb9a5ed16432f}
      \strng{authorbibnamehash}{4765bb24c67ec2d8037bb9a5ed16432f}
      \strng{authornamehash}{4765bb24c67ec2d8037bb9a5ed16432f}
      \strng{authorfullhash}{4765bb24c67ec2d8037bb9a5ed16432f}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-3-319-05713-2 978-3-319-05714-9}
      \field{langid}{english}
      \field{series}{Stochastic Modelling and Applied Probability}
      \field{title}{Stochastic Differential Equations, Backward {SDEs}, Partial Differential Equations}
      \field{urlday}{15}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{volume}{69}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-3-319-05714-9
      \endverb
      \verb{file}
      \verb Pardoux y Rӑşcanu - 2014 - Stochastic Differential Equations, Backward SDEs, .pdf:/home/carlos/Zotero/storage/BDAF2XD5/Pardoux y Rӑşcanu - 2014 - Stochastic Differential Equations, Backward SDEs, .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/10.1007/978-3-319-05714-9
      \endverb
      \verb{url}
      \verb https://link.springer.com/10.1007/978-3-319-05714-9
      \endverb
    \endentry
    \entry{romero_maestro_nodate}{article}{}
      \name{author}{1}{}{%
        {{hash=04b1ed251efdd057328781524789a201}{%
           family={Romero},
           familyi={R\bibinitperiod},
           given={Ricardo\bibnamedelima Romo},
           giveni={R\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \strng{namehash}{04b1ed251efdd057328781524789a201}
      \strng{fullhash}{04b1ed251efdd057328781524789a201}
      \strng{bibnamehash}{04b1ed251efdd057328781524789a201}
      \strng{authorbibnamehash}{04b1ed251efdd057328781524789a201}
      \strng{authornamehash}{04b1ed251efdd057328781524789a201}
      \strng{authorfullhash}{04b1ed251efdd057328781524789a201}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{spanish}
      \field{title}{Maestro en ciencias con especialidad en probabilidad y estadística}
      \verb{file}
      \verb Romero - Maestro en ciencias con especialidad en probabilid.pdf:/home/carlos/Zotero/storage/42NT3R4Z/Romero - Maestro en ciencias con especialidad en probabilid.pdf:application/pdf
      \endverb
    \endentry
    \entry{touzi_optimal_2013}{book}{}
      \name{author}{1}{}{%
        {{hash=701a2d95e8b3a75c89608e9b91902077}{%
           family={Touzi},
           familyi={T\bibinitperiod},
           given={Nizar},
           giveni={N\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, {NY}}%
      }
      \list{publisher}{1}{%
        {Springer New York}%
      }
      \strng{namehash}{701a2d95e8b3a75c89608e9b91902077}
      \strng{fullhash}{701a2d95e8b3a75c89608e9b91902077}
      \strng{bibnamehash}{701a2d95e8b3a75c89608e9b91902077}
      \strng{authorbibnamehash}{701a2d95e8b3a75c89608e9b91902077}
      \strng{authornamehash}{701a2d95e8b3a75c89608e9b91902077}
      \strng{authorfullhash}{701a2d95e8b3a75c89608e9b91902077}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-1-4614-4285-1 978-1-4614-4286-8}
      \field{langid}{english}
      \field{series}{Fields Institute Monographs}
      \field{title}{Optimal Stochastic Control, Stochastic Target Problems, and Backward {SDE}}
      \field{urlday}{15}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{volume}{29}
      \field{year}{2013}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-1-4614-4286-8
      \endverb
      \verb{file}
      \verb Touzi - 2013 - Optimal Stochastic Control, Stochastic Target Prob.pdf:/home/carlos/Zotero/storage/U27F2JS9/Touzi - 2013 - Optimal Stochastic Control, Stochastic Target Prob.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/10.1007/978-1-4614-4286-8
      \endverb
      \verb{url}
      \verb https://link.springer.com/10.1007/978-1-4614-4286-8
      \endverb
    \endentry
    \entry{mao_stochastic_2008}{book}{}
      \name{author}{1}{}{%
        {{hash=3b63fe742f76c1fafd56bf6fa698114e}{%
           family={Mao},
           familyi={M\bibinitperiod},
           given={Xuerong},
           giveni={X\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Chichester}%
      }
      \list{publisher}{1}{%
        {Horwood Pub}%
      }
      \strng{namehash}{3b63fe742f76c1fafd56bf6fa698114e}
      \strng{fullhash}{3b63fe742f76c1fafd56bf6fa698114e}
      \strng{bibnamehash}{3b63fe742f76c1fafd56bf6fa698114e}
      \strng{authorbibnamehash}{3b63fe742f76c1fafd56bf6fa698114e}
      \strng{authornamehash}{3b63fe742f76c1fafd56bf6fa698114e}
      \strng{authorfullhash}{3b63fe742f76c1fafd56bf6fa698114e}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{edition}{2nd ed}
      \field{isbn}{978-1-904275-34-3}
      \field{langid}{english}
      \field{note}{{OCLC}: ocn176925635}
      \field{pagetotal}{422}
      \field{title}{Stochastic differential equations and applications}
      \field{year}{2008}
      \field{dateera}{ce}
      \verb{file}
      \verb Mao - 2008 - Stochastic differential equations and applications.pdf:/home/carlos/Zotero/storage/ZXFKXEYC/Mao - 2008 - Stochastic differential equations and applications.pdf:application/pdf
      \endverb
      \keyw{Stochastic differential equations}
    \endentry
    \entry{chessari_numerical_2022}{misc}{}
      \name{author}{4}{}{%
        {{hash=c1d0f307f0c2d7d48bb314367196e0e9}{%
           family={Chessari},
           familyi={C\bibinitperiod},
           given={Jared},
           giveni={J\bibinitperiod}}}%
        {{hash=fd042e1f6aa8f34fe4594b6276a466d5}{%
           family={Kawai},
           familyi={K\bibinitperiod},
           given={Reiichiro},
           giveni={R\bibinitperiod}}}%
        {{hash=460bb8d894ff160172b3e3d0e376ea7b}{%
           family={Shinozaki},
           familyi={S\bibinitperiod},
           given={Yuji},
           giveni={Y\bibinitperiod}}}%
        {{hash=cb66cb34e25f56f889d7b1053e4c0823}{%
           family={Yamada},
           familyi={Y\bibinitperiod},
           given={Toshihiro},
           giveni={T\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{3cc26ef31ed487cc0d1e401f969fc83a}
      \strng{fullhash}{86dfdd9b393215828f78e1e7d3b76b9d}
      \strng{bibnamehash}{3cc26ef31ed487cc0d1e401f969fc83a}
      \strng{authorbibnamehash}{3cc26ef31ed487cc0d1e401f969fc83a}
      \strng{authornamehash}{3cc26ef31ed487cc0d1e401f969fc83a}
      \strng{authorfullhash}{86dfdd9b393215828f78e1e7d3b76b9d}
      \field{extraname}{1}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Backward Stochastic Differential Equations ({BSDEs}) have been widely employed in various areas of social and natural sciences, such as the pricing and hedging of financial derivatives, stochastic optimal control problems, optimal stopping problems and gene expression. Most {BSDEs} cannot be solved analytically and thus numerical methods must be applied in order to approximate their solutions. There have been a variety of numerical methods proposed over the past few decades as well as many more currently being developed. For the most part, they exist in a complex and scattered manner with each requiring different and similar assumptions and conditions. The aim of the present work is thus to systematically survey various numerical methods for {BSDEs}, and in particular, compare and categorize them, for further developments and improvements. To achieve this goal, we focus primarily on the core features of each method on the basis of an exhaustive collection of 303 references: the main assumptions, the numerical algorithm itself, key convergence properties and advantages and disadvantages, in order to provide a full up-to-date coverage of numerical methods for {BSDEs}, with insightful summaries of each and a useful comparison and categorization.}
      \field{day}{10}
      \field{eprinttype}{arxiv}
      \field{month}{3}
      \field{number}{{arXiv}:2101.08936}
      \field{shorttitle}{Numerical Methods for Backward Stochastic Differential Equations}
      \field{title}{Numerical Methods for Backward Stochastic Differential Equations: A Survey}
      \field{urlday}{24}
      \field{urlmonth}{1}
      \field{urlyear}{2023}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2101.08936 [cs, math]
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/carlos/Zotero/storage/8NI933ZB/Chessari et al. - 2022 - Numerical Methods for Backward Stochastic Differen.pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/C62HB45E/2101.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2101.08936
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2101.08936
      \endverb
      \keyw{Mathematics - Numerical Analysis,65C30,65C05,93E24,49L20,60H07,Mathematics - Probability}
    \endentry
    \entry{pham_continuous-time_2009}{book}{}
      \name{author}{1}{}{%
        {{hash=63008f832cd1b7bff2b7965308101cb3}{%
           family={Pham},
           familyi={P\bibinitperiod},
           given={Huyên},
           giveni={H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{63008f832cd1b7bff2b7965308101cb3}
      \strng{fullhash}{63008f832cd1b7bff2b7965308101cb3}
      \strng{bibnamehash}{63008f832cd1b7bff2b7965308101cb3}
      \strng{authorbibnamehash}{63008f832cd1b7bff2b7965308101cb3}
      \strng{authornamehash}{63008f832cd1b7bff2b7965308101cb3}
      \strng{authorfullhash}{63008f832cd1b7bff2b7965308101cb3}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-3-540-89499-5 978-3-540-89500-8}
      \field{langid}{english}
      \field{series}{Stochastic Modelling and Applied Probability}
      \field{title}{Continuous-time Stochastic Control and Optimization with Financial Applications}
      \field{urlday}{28}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{volume}{61}
      \field{year}{2009}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-3-540-89500-8
      \endverb
      \verb{file}
      \verb Pham - 2009 - Continuous-time Stochastic Control and Optimizatio.pdf:/home/carlos/Zotero/storage/XKHCZZK5/Pham - 2009 - Continuous-time Stochastic Control and Optimizatio.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/10.1007/978-3-540-89500-8
      \endverb
      \verb{url}
      \verb https://link.springer.com/10.1007/978-3-540-89500-8
      \endverb
    \endentry
    \entry{el_karoui_backward_1997}{article}{}
      \name{author}{3}{}{%
        {{hash=ff2bb8c1d58b07a9a92b7d53737af7f5}{%
           family={El\bibnamedelima Karoui},
           familyi={E\bibinitperiod\bibinitdelim K\bibinitperiod},
           given={N.},
           giveni={N\bibinitperiod}}}%
        {{hash=4a6ecdbb82702190711310c3bb7a7ee0}{%
           family={Peng},
           familyi={P\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=3525040aff8e5e5ef0c9c437dcb534cf}{%
           family={Quenez},
           familyi={Q\bibinitperiod},
           given={M.\bibnamedelimi C.},
           giveni={M\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \strng{namehash}{bbe43688d649da783741badb0ca7daf5}
      \strng{fullhash}{bbe43688d649da783741badb0ca7daf5}
      \strng{bibnamehash}{bbe43688d649da783741badb0ca7daf5}
      \strng{authorbibnamehash}{bbe43688d649da783741badb0ca7daf5}
      \strng{authornamehash}{bbe43688d649da783741badb0ca7daf5}
      \strng{authorfullhash}{bbe43688d649da783741badb0ca7daf5}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We are concerned with different properties of backward stochastic differential equations and their applications to finance. These equations, first introduced by Pardoux and Peng (1990), are useful for the theory of contingent claim valuation, especially cases with constraints and for the theory of recursive utilities, introduced by Duffie and Epstein (1992a, 1992b).}
      \field{issn}{1467-9965}
      \field{journaltitle}{Mathematical Finance}
      \field{langid}{english}
      \field{note}{\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9965.00022}
      \field{number}{1}
      \field{title}{Backward Stochastic Differential Equations in Finance}
      \field{urlday}{27}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{volume}{7}
      \field{year}{1997}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 71}
      \range{pages}{71}
      \verb{doi}
      \verb 10.1111/1467-9965.00022
      \endverb
      \verb{file}
      \verb Snapshot:/home/carlos/Zotero/storage/B5QFU6J9/1467-9965.html:text/html;Texto completo:/home/carlos/Zotero/storage/A6PFJXXE/El Karoui et al. - 1997 - Backward Stochastic Differential Equations in Fina.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9965.00022
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9965.00022
      \endverb
      \keyw{backward stochastic equation,constrained portfolio,hedging portfolios,incomplete market,Malliavin derivative,mathematical finance,pricing,recursive utility,stochastic control,viscosity solution of {PDE}}
    \endentry
    \entry{carmona_lectures_2016}{book}{}
      \name{author}{1}{}{%
        {{hash=370488c27988d8e01125afd81ea71055}{%
           family={Carmona},
           familyi={C\bibinitperiod},
           given={René},
           giveni={R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Philadelphia, {PA}}%
      }
      \list{publisher}{2}{%
        {Society for Industrial}%
        {Applied Mathematics}%
      }
      \strng{namehash}{370488c27988d8e01125afd81ea71055}
      \strng{fullhash}{370488c27988d8e01125afd81ea71055}
      \strng{bibnamehash}{370488c27988d8e01125afd81ea71055}
      \strng{authorbibnamehash}{370488c27988d8e01125afd81ea71055}
      \strng{authornamehash}{370488c27988d8e01125afd81ea71055}
      \strng{authorfullhash}{370488c27988d8e01125afd81ea71055}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{day}{18}
      \field{isbn}{978-1-61197-423-2 978-1-61197-424-9}
      \field{langid}{english}
      \field{month}{2}
      \field{title}{Lectures on {BSDEs}, Stochastic Control, and Stochastic Differential Games with Financial Applications}
      \field{urlday}{21}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1137/1.9781611974249
      \endverb
      \verb{file}
      \verb Carmona - 2016 - Lectures on BSDEs, Stochastic Control, and Stochas.pdf:/home/carlos/Zotero/storage/45ZWRYKP/Carmona - 2016 - Lectures on BSDEs, Stochastic Control, and Stochas.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://epubs.siam.org/doi/book/10.1137/1.9781611974249
      \endverb
      \verb{url}
      \verb http://epubs.siam.org/doi/book/10.1137/1.9781611974249
      \endverb
    \endentry
    \entry{yong_stochastic_1999}{book}{}
      \name{author}{2}{}{%
        {{hash=f9d70f3c2c2541b9a22eb8859d1c10bf}{%
           family={Yong},
           familyi={Y\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
        {{hash=d617810777fb638be82bead5cc462d00}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Xun\bibnamedelima Yu},
           giveni={X\bibinitperiod\bibinitdelim Y\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{e2738e7aff8fd009fe2fbaf318cdea4a}
      \strng{fullhash}{e2738e7aff8fd009fe2fbaf318cdea4a}
      \strng{bibnamehash}{e2738e7aff8fd009fe2fbaf318cdea4a}
      \strng{authorbibnamehash}{e2738e7aff8fd009fe2fbaf318cdea4a}
      \strng{authornamehash}{e2738e7aff8fd009fe2fbaf318cdea4a}
      \strng{authorfullhash}{e2738e7aff8fd009fe2fbaf318cdea4a}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{isbn}{978-0-387-98723-1}
      \field{langid}{english}
      \field{number}{43}
      \field{pagetotal}{438}
      \field{series}{Applications of mathematics}
      \field{shorttitle}{Stochastic controls}
      \field{title}{Stochastic controls: Hamiltonian systems and {HJB} equations}
      \field{year}{1999}
      \field{dateera}{ce}
      \verb{file}
      \verb Yong y Zhou - 1999 - Stochastic controls Hamiltonian systems and HJB e.pdf:/home/carlos/Zotero/storage/BRVMD8JT/Yong y Zhou - 1999 - Stochastic controls Hamiltonian systems and HJB e.pdf:application/pdf
      \endverb
      \keyw{Hamilton-Jacobi equations,Hamiltonian systems,Mathematical optimization,Stochastic control theory}
    \endentry
    \entry{chessari_numerical_nodate}{article}{}
      \name{author}{4}{}{%
        {{hash=c1d0f307f0c2d7d48bb314367196e0e9}{%
           family={Chessari},
           familyi={C\bibinitperiod},
           given={Jared},
           giveni={J\bibinitperiod}}}%
        {{hash=fd042e1f6aa8f34fe4594b6276a466d5}{%
           family={Kawai},
           familyi={K\bibinitperiod},
           given={Reiichiro},
           giveni={R\bibinitperiod}}}%
        {{hash=460bb8d894ff160172b3e3d0e376ea7b}{%
           family={Shinozaki},
           familyi={S\bibinitperiod},
           given={Yuji},
           giveni={Y\bibinitperiod}}}%
        {{hash=cb66cb34e25f56f889d7b1053e4c0823}{%
           family={Yamada},
           familyi={Y\bibinitperiod},
           given={Toshihiro},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{3cc26ef31ed487cc0d1e401f969fc83a}
      \strng{fullhash}{86dfdd9b393215828f78e1e7d3b76b9d}
      \strng{bibnamehash}{3cc26ef31ed487cc0d1e401f969fc83a}
      \strng{authorbibnamehash}{3cc26ef31ed487cc0d1e401f969fc83a}
      \strng{authornamehash}{3cc26ef31ed487cc0d1e401f969fc83a}
      \strng{authorfullhash}{86dfdd9b393215828f78e1e7d3b76b9d}
      \field{extraname}{2}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Backward Stochastic Differential Equations ({BSDEs}) have been widely employed in various areas of social and natural sciences, such as the pricing and hedging of ﬁnancial derivatives, stochastic optimal control problems, optimal stopping problems and gene expression. Most {BSDEs} cannot be solved analytically and thus numerical methods must be applied to approximate their solutions. There have been a variety of numerical methods proposed over the past few decades as well as many more currently being developed. For the most part, they exist in a complex and scattered manner with each requiring a variety of assumptions and conditions. The aim of the present work is thus to systematically survey various numerical methods for {BSDEs}, and in particular, compare and categorize them, for further developments and improvements. To achieve this goal, we focus primarily on the core features of each method based on an extensive collection of 333 references: the main assumptions, the numerical algorithm itself, key convergence properties and advantages and disadvantages, to provide an up-to-date coverage of numerical methods for {BSDEs}, with insightful summaries of each and a useful comparison and categorization.}
      \field{langid}{english}
      \field{title}{Numerical methods for backward stochastic differential equations: A survey}
      \verb{file}
      \verb Chessari et al. - Numerical methods for backward stochastic differen.pdf:/home/carlos/Zotero/storage/YUYKMCJ8/Chessari et al. - Numerical methods for backward stochastic differen.pdf:application/pdf
      \endverb
    \endentry
    \entry{e_algorithms_2022}{article}{}
      \name{author}{3}{}{%
        {{hash=268e9715905f2ab3cb20df636d3750c1}{%
           family={E},
           familyi={E\bibinitperiod},
           given={Weinan},
           giveni={W\bibinitperiod}}}%
        {{hash=dcbed821c92a82aa9d46cf353c58ec62}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Jiequn},
           giveni={J\bibinitperiod}}}%
        {{hash=31ce46557e2d08499e8b06d041f40bf2}{%
           family={Jentzen},
           familyi={J\bibinitperiod},
           given={Arnulf},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \strng{fullhash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \strng{bibnamehash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \strng{authorbibnamehash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \strng{authornamehash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \strng{authorfullhash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \field{extraname}{1}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In recent years, tremendous progress has been made on numerical algorithms for solving partial diﬀerential equations ({PDEs}) in a very high dimension, using ideas from either nonlinear (multilevel) Monte Carlo or deep learning. They are potentially free of the curse of dimensionality for many diﬀerent applications and have been proven to be so in the case of some nonlinear Monte Carlo methods for nonlinear parabolic {PDEs}.}
      \field{day}{6}
      \field{issn}{0951-7715, 1361-6544}
      \field{journaltitle}{Nonlinearity}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{Nonlinearity}
      \field{shorttitle}{Algorithms for solving high dimensional {PDEs}}
      \field{title}{Algorithms for solving high dimensional {PDEs}: from nonlinear Monte Carlo to machine learning}
      \field{urlday}{14}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{volume}{35}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{278\bibrangedash 310}
      \range{pages}{33}
      \verb{doi}
      \verb 10.1088/1361-6544/ac337f
      \endverb
      \verb{file}
      \verb E et al. - 2022 - Algorithms for solving high dimensional PDEs from.pdf:/home/carlos/Zotero/storage/YBENMVKA/E et al. - 2022 - Algorithms for solving high dimensional PDEs from.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://iopscience.iop.org/article/10.1088/1361-6544/ac337f
      \endverb
      \verb{url}
      \verb https://iopscience.iop.org/article/10.1088/1361-6544/ac337f
      \endverb
    \endentry
    \entry{beck_machine_2019}{article}{}
      \name{author}{3}{}{%
        {{hash=53a777055b139b74439193de18ada60c}{%
           family={Beck},
           familyi={B\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=268e9715905f2ab3cb20df636d3750c1}{%
           family={E},
           familyi={E\bibinitperiod},
           given={Weinan},
           giveni={W\bibinitperiod}}}%
        {{hash=31ce46557e2d08499e8b06d041f40bf2}{%
           family={Jentzen},
           familyi={J\bibinitperiod},
           given={Arnulf},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{bb592905e95486ef5243870097ddb251}
      \strng{fullhash}{bb592905e95486ef5243870097ddb251}
      \strng{bibnamehash}{bb592905e95486ef5243870097ddb251}
      \strng{authorbibnamehash}{bb592905e95486ef5243870097ddb251}
      \strng{authornamehash}{bb592905e95486ef5243870097ddb251}
      \strng{authorfullhash}{bb592905e95486ef5243870097ddb251}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{High-dimensional partial differential equations ({PDE}) appear in a number of models from the financial industry, such as in derivative pricing models, credit valuation adjustment ({CVA}) models, or portfolio optimization models. The {PDEs} in such applications are high-dimensional as the dimension corresponds to the number of financial assets in a portfolio. Moreover, such {PDEs} are often fully nonlinear due to the need to incorporate certain nonlinear phenomena in the model such as default risks, transaction costs, volatility uncertainty (Knightian uncertainty), or trading constraints in the model. Such high-dimensional fully nonlinear {PDEs} are exceedingly difficult to solve as the computational effort for standard approximation methods grows exponentially with the dimension. In this work we propose a new method for solving high-dimensional fully nonlinear second-order {PDEs}. Our method can in particular be used to sample from high-dimensional nonlinear expectations. The method is based on (i) a connection between fully nonlinear second-order {PDEs} and second-order backward stochastic differential equations (2BSDEs), (ii) a merged formulation of the {PDE} and the 2BSDE problem, (iii) a temporal forward discretization of the 2BSDE and a spatial approximation via deep neural nets, and (iv) a stochastic gradient descent-type optimization procedure. Numerical results obtained using \$\{{\textbackslash}rm T\{{\textbackslash}small {ENSOR}\}F\{{\textbackslash}small {LOW}\}\}\$ in \$\{{\textbackslash}rm P\{{\textbackslash}small {YTHON}\}\}\$ illustrate the efficiency and the accuracy of the method in the cases of a \$100\$-dimensional Black-Scholes-Barenblatt equation, a \$100\$-dimensional Hamilton-Jacobi-Bellman equation, and a nonlinear expectation of a \$ 100 \$-dimensional \$ G \$-Brownian motion.}
      \field{eprinttype}{arxiv}
      \field{issn}{0938-8974, 1432-1467}
      \field{journaltitle}{Journal of Nonlinear Science}
      \field{month}{8}
      \field{number}{4}
      \field{shortjournal}{J Nonlinear Sci}
      \field{title}{Machine learning approximation algorithms for high-dimensional fully nonlinear partial differential equations and second-order backward stochastic differential equations}
      \field{urlday}{5}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{volume}{29}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1563\bibrangedash 1619}
      \range{pages}{57}
      \verb{doi}
      \verb 10.1007/s00332-018-9525-3
      \endverb
      \verb{eprint}
      \verb 1709.05963 [cs, math, stat]
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/carlos/Zotero/storage/33RP8QD8/Beck et al. - 2019 - Machine learning approximation algorithms for high.pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/93WCBBBX/1709.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1709.05963
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1709.05963
      \endverb
      \keyw{Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning,Mathematics - Probability,65C99,65M99,60H30,65-05,Computer Science - Neural and Evolutionary Computing}
    \endentry
    \entry{e_deep_2017}{article}{}
      \name{author}{3}{}{%
        {{hash=268e9715905f2ab3cb20df636d3750c1}{%
           family={E},
           familyi={E\bibinitperiod},
           given={Weinan},
           giveni={W\bibinitperiod}}}%
        {{hash=dcbed821c92a82aa9d46cf353c58ec62}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Jiequn},
           giveni={J\bibinitperiod}}}%
        {{hash=31ce46557e2d08499e8b06d041f40bf2}{%
           family={Jentzen},
           familyi={J\bibinitperiod},
           given={Arnulf},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \strng{fullhash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \strng{bibnamehash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \strng{authorbibnamehash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \strng{authornamehash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \strng{authorfullhash}{5e547ff0c21fdf3d6461d7f7c3449b5e}
      \field{extraname}{2}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We study a new algorithm for solving parabolic partial differential equations ({PDEs}) and backward stochastic differential equations ({BSDEs}) in high dimension, which is based on an analogy between the {BSDE} and reinforcement learning with the gradient of the solution playing the role of the policy function, and the loss function given by the error between the prescribed terminal condition and the solution of the {BSDE}. The policy function is then approximated by a neural network, as is done in deep reinforcement learning. Numerical results using {TensorFlow} illustrate the efficiency and accuracy of the studied algorithm for several 100-dimensional nonlinear {PDEs} from physics and finance such as the Allen–Cahn equation, the Hamilton–Jacobi–Bellman equation, and a nonlinear pricing model for financial derivatives.}
      \field{day}{1}
      \field{issn}{2194-671X}
      \field{journaltitle}{Communications in Mathematics and Statistics}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{4}
      \field{shortjournal}{Commun. Math. Stat.}
      \field{title}{Deep Learning-Based Numerical Methods for High-Dimensional Parabolic Partial Differential Equations and Backward Stochastic Differential Equations}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2023}
      \field{volume}{5}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{349\bibrangedash 380}
      \range{pages}{32}
      \verb{doi}
      \verb 10.1007/s40304-017-0117-6
      \endverb
      \verb{file}
      \verb Versión enviada:/home/carlos/Zotero/storage/DEBYV7F3/E et al. - 2017 - Deep Learning-Based Numerical Methods for High-Dim.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s40304-017-0117-6
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s40304-017-0117-6
      \endverb
      \keyw{60H35,65C30,65M75,Backward stochastic differential equations,Control,Deep learning,Feynman-Kac,High dimension,{PDEs}}
    \endentry
    \entry{chan-wai-nam_machine_2018}{misc}{}
      \name{author}{3}{}{%
        {{hash=427d043f7276d80858a4d6ce40ffd384}{%
           family={Chan-Wai-Nam},
           familyi={C\bibinithyphendelim W\bibinithyphendelim N\bibinitperiod},
           given={Quentin},
           giveni={Q\bibinitperiod}}}%
        {{hash=a221d9622d6b04d560b45619cd365e38}{%
           family={Mikael},
           familyi={M\bibinitperiod},
           given={Joseph},
           giveni={J\bibinitperiod}}}%
        {{hash=ea3f10f25d882688b0162b224cc49e89}{%
           family={Warin},
           familyi={W\bibinitperiod},
           given={Xavier},
           giveni={X\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{bdec6dc3095b91a40f7ee97ab7e4d528}
      \strng{fullhash}{bdec6dc3095b91a40f7ee97ab7e4d528}
      \strng{bibnamehash}{bdec6dc3095b91a40f7ee97ab7e4d528}
      \strng{authorbibnamehash}{bdec6dc3095b91a40f7ee97ab7e4d528}
      \strng{authornamehash}{bdec6dc3095b91a40f7ee97ab7e4d528}
      \strng{authorfullhash}{bdec6dc3095b91a40f7ee97ab7e4d528}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recent machine learning algorithms dedicated to solving semi-linear {PDEs} are improved by using different neural network architectures and different parameterizations. These algorithms are compared to a new one that solves a fixed point problem by using deep learning techniques. This new algorithm appears to be competitive in terms of accuracy with the best existing algorithms.}
      \field{day}{10}
      \field{eprinttype}{arxiv}
      \field{month}{12}
      \field{number}{{arXiv}:1809.07609}
      \field{title}{Machine Learning for semi linear {PDEs}}
      \field{urlday}{26}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 1809.07609 [cs, math, stat]
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/carlos/Zotero/storage/88IC72XX/Chan-Wai-Nam et al. - 2018 - Machine Learning for semi linear PDEs.pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/LXCE4JAV/1809.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1809.07609
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1809.07609
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning,65C05,49L25,65C99,Mathematics - Analysis of {PDEs}}
    \endentry
    \entry{han_convergence_2020}{article}{}
      \name{author}{2}{}{%
        {{hash=dcbed821c92a82aa9d46cf353c58ec62}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Jiequn},
           giveni={J\bibinitperiod}}}%
        {{hash=fd05e790c41c09661660ac4f35ed744a}{%
           family={Long},
           familyi={L\bibinitperiod},
           given={Jihao},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{e06737126e5207ae99c037f5c4b22882}
      \strng{fullhash}{e06737126e5207ae99c037f5c4b22882}
      \strng{bibnamehash}{e06737126e5207ae99c037f5c4b22882}
      \strng{authorbibnamehash}{e06737126e5207ae99c037f5c4b22882}
      \strng{authornamehash}{e06737126e5207ae99c037f5c4b22882}
      \strng{authorfullhash}{e06737126e5207ae99c037f5c4b22882}
      \field{sortinit}{4}
      \field{sortinithash}{9381316451d1b9788675a07e972a12a7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The recently proposed numerical algorithm, deep {BSDE} method, has shown remarkable performance in solving high-dimensional forward-backward stochastic differential equations ({FBSDEs}) and parabolic partial differential equations ({PDEs}). This article lays a theoretical foundation for the deep {BSDE} method in the general case of coupled {FBSDEs}. In particular, a posteriori error estimation of the solution is provided and it is proved that the error converges to zero given the universal approximation capability of neural networks. Numerical results are presented to demonstrate the accuracy of the analyzed algorithm in solving high-dimensional coupled {FBSDEs}.}
      \field{eprinttype}{arxiv}
      \field{issn}{2367-0126}
      \field{journaltitle}{Probability, Uncertainty and Quantitative Risk}
      \field{month}{12}
      \field{number}{1}
      \field{shortjournal}{Probab Uncertain Quant Risk}
      \field{title}{Convergence of the Deep {BSDE} Method for Coupled {FBSDEs}}
      \field{urlday}{10}
      \field{urlmonth}{4}
      \field{urlyear}{2023}
      \field{volume}{5}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{5}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s41546-020-00047-w
      \endverb
      \verb{eprint}
      \verb 1811.01165 [cs, math]
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/carlos/Zotero/storage/ZBMYGA95/Han y Long - 2020 - Convergence of the Deep BSDE Method for Coupled FB.pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/W623V8KV/1811.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1811.01165
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1811.01165
      \endverb
      \keyw{Computer Science - Machine Learning,Mathematics - Numerical Analysis,Mathematics - Probability}
    \endentry
    \entry{hure_deep_2020}{article}{}
      \name{author}{3}{}{%
        {{hash=3b6075cd0ba05bc749910ae11cd359c0}{%
           family={Huré},
           familyi={H\bibinitperiod},
           given={Côme},
           giveni={C\bibinitperiod}}}%
        {{hash=63008f832cd1b7bff2b7965308101cb3}{%
           family={Pham},
           familyi={P\bibinitperiod},
           given={Huyên},
           giveni={H\bibinitperiod}}}%
        {{hash=ea3f10f25d882688b0162b224cc49e89}{%
           family={Warin},
           familyi={W\bibinitperiod},
           given={Xavier},
           giveni={X\bibinitperiod}}}%
      }
      \strng{namehash}{3a46552915079364d2429ce9381a76a9}
      \strng{fullhash}{3a46552915079364d2429ce9381a76a9}
      \strng{bibnamehash}{3a46552915079364d2429ce9381a76a9}
      \strng{authorbibnamehash}{3a46552915079364d2429ce9381a76a9}
      \strng{authornamehash}{3a46552915079364d2429ce9381a76a9}
      \strng{authorfullhash}{3a46552915079364d2429ce9381a76a9}
      \field{sortinit}{4}
      \field{sortinithash}{9381316451d1b9788675a07e972a12a7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose new machine learning schemes for solving high dimensional nonlinear partial diﬀerential equations ({PDEs}). Relying on the classical backward stochastic diﬀerential equation ({BSDE}) representation of {PDEs}, our algorithms estimate simultaneously the solution and its gradient by deep neural networks. These approximations are performed at each time step from the minimization of loss functions deﬁned recursively by backward induction. The methodology is extended to variational inequalities arising in optimal stopping problems. We analyze the convergence of the deep learning schemes and provide error estimates in terms of the universal approximation of neural networks. Numerical results show that our algorithms give very good results till dimension 50 (and certainly above), for both {PDEs} and variational inequalities problems. For the {PDEs} resolution, our results are very similar to those obtained by the recent method in [{EHJ}17] when the latter converges to the right solution or does not diverge. Numerical tests indicate that the proposed methods are not stuck in poor local minima as it can be the case with the algorithm designed in [{EHJ}17], and no divergence is experienced. The only limitation seems to be due to the inability of the considered deep neural networks to represent a solution with a too complex structure in high dimension.}
      \field{day}{31}
      \field{issn}{0025-5718, 1088-6842}
      \field{journaltitle}{Mathematics of Computation}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{324}
      \field{shortjournal}{Math. Comp.}
      \field{title}{Deep backward schemes for high-dimensional nonlinear {PDEs}}
      \field{urlday}{28}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{volume}{89}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1547\bibrangedash 1579}
      \range{pages}{33}
      \verb{doi}
      \verb 10.1090/mcom/3514
      \endverb
      \verb{file}
      \verb Huré et al. - 2020 - Deep backward schemes for high-dimensional nonline.pdf:/home/carlos/Zotero/storage/F337CQZ3/Huré et al. - 2020 - Deep backward schemes for high-dimensional nonline.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.ams.org/mcom/2020-89-324/S0025-5718-2020-03514-5/
      \endverb
      \verb{url}
      \verb https://www.ams.org/mcom/2020-89-324/S0025-5718-2020-03514-5/
      \endverb
    \endentry
    \entry{raissi_forward-backward_2018}{misc}{}
      \name{author}{1}{}{%
        {{hash=95a17c39168b9e6b8812f207b4e036c1}{%
           family={Raissi},
           familyi={R\bibinitperiod},
           given={Maziar},
           giveni={M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{95a17c39168b9e6b8812f207b4e036c1}
      \strng{fullhash}{95a17c39168b9e6b8812f207b4e036c1}
      \strng{bibnamehash}{95a17c39168b9e6b8812f207b4e036c1}
      \strng{authorbibnamehash}{95a17c39168b9e6b8812f207b4e036c1}
      \strng{authornamehash}{95a17c39168b9e6b8812f207b4e036c1}
      \strng{authorfullhash}{95a17c39168b9e6b8812f207b4e036c1}
      \field{sortinit}{5}
      \field{sortinithash}{20e9b4b0b173788c5dace24730f47d8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Classical numerical methods for solving partial differential equations suffer from the curse dimensionality mainly due to their reliance on meticulously generated spatio-temporal grids. Inspired by modern deep learning based techniques for solving forward and inverse problems associated with partial differential equations, we circumvent the tyranny of numerical discretization by devising an algorithm that is scalable to high-dimensions. In particular, we approximate the unknown solution by a deep neural network which essentially enables us to benefit from the merits of automatic differentiation. To train the aforementioned neural network we leverage the well-known connection between high-dimensional partial differential equations and forward-backward stochastic differential equations. In fact, independent realizations of a standard Brownian motion will act as training data. We test the effectiveness of our approach for a couple of benchmark problems spanning a number of scientific domains including Black-Scholes-Barenblatt and Hamilton-Jacobi-Bellman equations, both in 100-dimensions.}
      \field{day}{19}
      \field{eprinttype}{arxiv}
      \field{month}{4}
      \field{number}{{arXiv}:1804.07010}
      \field{shorttitle}{Forward-Backward Stochastic Neural Networks}
      \field{title}{Forward-Backward Stochastic Neural Networks: Deep Learning of High-dimensional Partial Differential Equations}
      \field{urlday}{22}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 1804.07010 [cs, math, stat]
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/carlos/Zotero/storage/XR8RPSHY/Raissi - 2018 - Forward-Backward Stochastic Neural Networks Deep .pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/KHWY7D98/1804.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1804.07010
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1804.07010
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning,Mathematics - Optimization and Control,Mathematics - Analysis of {PDEs},Electrical Engineering and Systems Science - Systems and Control}
    \endentry
    \entry{nusken_interpolating_2023}{misc}{}
      \name{author}{2}{}{%
        {{hash=1809e073002f6b361a45b910e990e573}{%
           family={Nüsken},
           familyi={N\bibinitperiod},
           given={Nikolas},
           giveni={N\bibinitperiod}}}%
        {{hash=320a939ee9de885642a8b23fb9d71407}{%
           family={Richter},
           familyi={R\bibinitperiod},
           given={Lorenz},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{3fda6a4067919d21da05be927834cf75}
      \strng{fullhash}{3fda6a4067919d21da05be927834cf75}
      \strng{bibnamehash}{3fda6a4067919d21da05be927834cf75}
      \strng{authorbibnamehash}{3fda6a4067919d21da05be927834cf75}
      \strng{authornamehash}{3fda6a4067919d21da05be927834cf75}
      \strng{authorfullhash}{3fda6a4067919d21da05be927834cf75}
      \field{extraname}{1}
      \field{sortinit}{5}
      \field{sortinithash}{20e9b4b0b173788c5dace24730f47d8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Solving high-dimensional partial differential equations is a recurrent challenge in economics, science and engineering. In recent years, a great number of computational approaches have been developed, most of them relying on a combination of Monte Carlo sampling and deep learning based approximation. For elliptic and parabolic problems, existing methods can broadly be classified into those resting on reformulations in terms of \${\textbackslash}textit\{backward stochastic differential equations\}\$ ({BSDEs}) and those aiming to minimize a regression-type \$L{\textasciicircum}2\$-error (\${\textbackslash}textit\{physics-informed neural networks\}\$, {PINNs}). In this paper, we review the literature and suggest a methodology based on the novel \${\textbackslash}textit\{diffusion loss\}\$ that interpolates between {BSDEs} and {PINNs}. Our contribution opens the door towards a unified understanding of numerical approaches for high-dimensional {PDEs}, as well as for implementations that combine the strengths of {BSDEs} and {PINNs}. The diffusion loss furthermore bears close similarities to \${\textbackslash}textit\{(least squares) temporal difference\}\$ objectives found in reinforcement learning. We also discuss eigenvalue problems and perform extensive numerical studies, including calculations of the ground state for nonlinear Schr{\textbackslash}"odinger operators and committor functions relevant in molecular dynamics.}
      \field{day}{29}
      \field{eprinttype}{arxiv}
      \field{month}{1}
      \field{number}{{arXiv}:2112.03749}
      \field{shorttitle}{Interpolating between {BSDEs} and {PINNs}}
      \field{title}{Interpolating between {BSDEs} and {PINNs}: deep learning for elliptic and parabolic boundary value problems}
      \field{urlday}{26}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2112.03749 [cs, math, stat]
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/carlos/Zotero/storage/F6XGPLPR/Nüsken y Richter - 2023 - Interpolating between BSDEs and PINNs deep learni.pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/W2J945H2/2112.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2112.03749
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2112.03749
      \endverb
      \keyw{Mathematics - Numerical Analysis,Statistics - Machine Learning,Mathematics - Probability}
    \endentry
    \entry{hu_recent_nodate}{article}{}
      \name{author}{2}{}{%
        {{hash=839da6ced1e86337b95ea9d732662ae8}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Ruimeng},
           giveni={R\bibinitperiod}}}%
        {{hash=b784c21c4869994f46ae1f521c97ae04}{%
           family={Laurière},
           familyi={L\bibinitperiod},
           given={Mathieu},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{820231d08c0487c8a23bc9fdc78b245d}
      \strng{fullhash}{820231d08c0487c8a23bc9fdc78b245d}
      \strng{bibnamehash}{820231d08c0487c8a23bc9fdc78b245d}
      \strng{authorbibnamehash}{820231d08c0487c8a23bc9fdc78b245d}
      \strng{authornamehash}{820231d08c0487c8a23bc9fdc78b245d}
      \strng{authorfullhash}{820231d08c0487c8a23bc9fdc78b245d}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we give an overview of recently developed machine learning methods for stochastic control problems and games. The main focus is on deep learning methods that have unlocked the possibility to solve such problems even when the structure is very complex or when the dimension is very high, which is not feasible with traditional numerical methods. Many of these new approaches build on recent breakthrough machine learning methods for partial diﬀerential equations or backward stochastic diﬀerential equations, or on model-free reinforcement learning for Markov decision processes. This review summarizes state-of-the-art works at the crossroad of artiﬁcial intelligence and stochastic control and games. It also discusses connections with real applications and identiﬁes unsolved challenges.}
      \field{langid}{english}
      \field{title}{Recent Developments in Machine Learning Methods for Stochastic Control and Games}
      \verb{file}
      \verb Hu y Laurière - Recent Developments in Machine Learning Methods fo.pdf:/home/carlos/Zotero/storage/YF566UKJ/Hu y Laurière - Recent Developments in Machine Learning Methods fo.pdf:application/pdf
      \endverb
    \endentry
    \entry{han_deep_2020}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=dcbed821c92a82aa9d46cf353c58ec62}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Jiequn},
           giveni={J\bibinitperiod}}}%
        {{hash=839da6ced1e86337b95ea9d732662ae8}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Ruimeng},
           giveni={R\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {PMLR}%
      }
      \strng{namehash}{e1992e87e0b3c2d8d658d195b466215a}
      \strng{fullhash}{e1992e87e0b3c2d8d658d195b466215a}
      \strng{bibnamehash}{e1992e87e0b3c2d8d658d195b466215a}
      \strng{authorbibnamehash}{e1992e87e0b3c2d8d658d195b466215a}
      \strng{authornamehash}{e1992e87e0b3c2d8d658d195b466215a}
      \strng{authorfullhash}{e1992e87e0b3c2d8d658d195b466215a}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a deep neural network-based algorithm to identify the Markovian Nash equilibrium of general large \$N\$-player stochastic differential games. Following the idea of fictitious play, we recast the \$N\$-player game into \$N\$ decoupled decision problems (one for each player) and solve them iteratively. The individual decision problem is characterized by a semilinear Hamilton-Jacobi-Bellman equation, to solve which we employ the recently developed deep {BSDE} method. The resulted algorithm can solve large \$N\$-player games for which conventional numerical methods would suffer from the curse of dimensionality. Multiple numerical examples involving identical or heterogeneous agents, with risk-neutral or risk-sensitive objectives, are tested to validate the accuracy of the proposed algorithm in large group games. Even for a fifty-player game with the presence of common noise, the proposed algorithm still finds the approximate Nash equilibrium accurately, which, to our best knowledge, is difficult to achieve by other numerical algorithms.}
      \field{booktitle}{Proceedings of The First Mathematical and Scientific Machine Learning Conference}
      \field{day}{16}
      \field{eventtitle}{Mathematical and Scientific Machine Learning}
      \field{langid}{english}
      \field{month}{8}
      \field{note}{{ISSN}: 2640-3498}
      \field{title}{Deep Fictitious Play for Finding Markovian Nash Equilibrium in Multi-Agent Games}
      \field{urlday}{28}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{221\bibrangedash 245}
      \range{pages}{25}
      \verb{file}
      \verb Full Text PDF:/home/carlos/Zotero/storage/ELYE2Q4K/Han y Hu - 2020 - Deep Fictitious Play for Finding Markovian Nash Eq.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.mlr.press/v107/han20a.html
      \endverb
      \verb{url}
      \verb https://proceedings.mlr.press/v107/han20a.html
      \endverb
    \endentry
    \entry{brown_notes_1949}{report}{}
      \name{author}{1}{}{%
        {{hash=a84f0ecb7dc3c25662e69881f1b264ff}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={George\bibnamedelima W.},
           giveni={G\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {{RAND} Corporation}%
      }
      \strng{namehash}{a84f0ecb7dc3c25662e69881f1b264ff}
      \strng{fullhash}{a84f0ecb7dc3c25662e69881f1b264ff}
      \strng{bibnamehash}{a84f0ecb7dc3c25662e69881f1b264ff}
      \strng{authorbibnamehash}{a84f0ecb7dc3c25662e69881f1b264ff}
      \strng{authornamehash}{a84f0ecb7dc3c25662e69881f1b264ff}
      \strng{authorfullhash}{a84f0ecb7dc3c25662e69881f1b264ff}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A presentation of several dynamical systems whose steady-state solutions yield solutions to a discrete game matrix. Considered in the report are (1) various systems of differential equations for a symmetric game, (2) related systems of difference eq...}
      \field{day}{1}
      \field{langid}{english}
      \field{month}{1}
      \field{title}{Some Notes on Computation of Games Solutions}
      \field{urlday}{29}
      \field{urlmonth}{5}
      \field{urlyear}{2023}
      \field{year}{1949}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://www.rand.org/pubs/research_memoranda/RM125.html
      \endverb
      \verb{url}
      \verb https://www.rand.org/pubs/research_memoranda/RM125.html
      \endverb
    \endentry
    \entry{achdou_mean_2020}{inbook}{}
      \name{author}{2}{}{%
        {{hash=eb4516e653879aec80029cb07f197092}{%
           family={Achdou},
           familyi={A\bibinitperiod},
           given={Yves},
           giveni={Y\bibinitperiod}}}%
        {{hash=b784c21c4869994f46ae1f521c97ae04}{%
           family={Laurière},
           familyi={L\bibinitperiod},
           given={Mathieu},
           giveni={M\bibinitperiod}}}%
      }
      \name{bookauthor}{5}{}{%
        {{hash=eb4516e653879aec80029cb07f197092}{%
           family={Achdou},
           familyi={A\bibinitperiod},
           given={Yves},
           giveni={Y\bibinitperiod}}}%
        {{hash=5fa5d4a72b012ed8ba98f5e624da13a7}{%
           family={Cardaliaguet},
           familyi={C\bibinitperiod},
           given={Pierre},
           giveni={P\bibinitperiod}}}%
        {{hash=799c6f3ae3f94478b9b2d2aadabd8387}{%
           family={Delarue},
           familyi={D\bibinitperiod},
           given={François},
           giveni={F\bibinitperiod}}}%
        {{hash=6a1aa7a56daed411aec694ed4130867c}{%
           family={Porretta},
           familyi={P\bibinitperiod},
           given={Alessio},
           giveni={A\bibinitperiod}}}%
        {{hash=deb5f5e08d40c7c61a19403771acf3c3}{%
           family={Santambrogio},
           familyi={S\bibinitperiod},
           given={Filippo},
           giveni={F\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=5fa5d4a72b012ed8ba98f5e624da13a7}{%
           family={Cardaliaguet},
           familyi={C\bibinitperiod},
           given={Pierre},
           giveni={P\bibinitperiod}}}%
        {{hash=6a1aa7a56daed411aec694ed4130867c}{%
           family={Porretta},
           familyi={P\bibinitperiod},
           given={Alessio},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{a6c60fda753b0dde230fcf6f74ee8978}
      \strng{fullhash}{a6c60fda753b0dde230fcf6f74ee8978}
      \strng{bibnamehash}{a6c60fda753b0dde230fcf6f74ee8978}
      \strng{authorbibnamehash}{a6c60fda753b0dde230fcf6f74ee8978}
      \strng{authornamehash}{a6c60fda753b0dde230fcf6f74ee8978}
      \strng{authorfullhash}{a6c60fda753b0dde230fcf6f74ee8978}
      \strng{bookauthorbibnamehash}{7445715211e5ef60e5abac064d45ce87}
      \strng{bookauthornamehash}{7445715211e5ef60e5abac064d45ce87}
      \strng{bookauthorfullhash}{6ac653996326b90757c979c79e4b66de}
      \strng{editorbibnamehash}{f725986ef5f98c13fea36f5308b7c206}
      \strng{editornamehash}{f725986ef5f98c13fea36f5308b7c206}
      \strng{editorfullhash}{f725986ef5f98c13fea36f5308b7c206}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The theory of mean ﬁeld games aims at studying deterministic or stochastic diﬀerential games (Nash equilibria) as the number of agents tends to inﬁnity. Since very few mean ﬁeld games have explicit or semi-explicit solutions, numerical simulations play a crucial role in obtaining quantitative information from this class of models. They may lead to systems of evolutive partial diﬀerential equations coupling a backward Bellman equation and a forward Fokker-Planck equation. In the present survey, we focus on such systems. The forward-backward structure is an important feature of this system, which makes it necessary to design unusual strategies for mathematical analysis and numerical approximation. In this survey, several aspects of a ﬁnite diﬀerence method used to approximate the previously mentioned system of {PDEs} are discussed, including convergence, variational aspects and algorithms for solving the resulting systems of nonlinear equations. Finally, we discuss in details two applications of mean ﬁeld games to the study of crowd motion and to macroeconomics, a comparison with mean ﬁeld type control, and present numerical simulations.}
      \field{booktitle}{Mean Field Games}
      \field{isbn}{978-3-030-59836-5 978-3-030-59837-2}
      \field{langid}{english}
      \field{note}{Series Title: Lecture Notes in Mathematics}
      \field{shorttitle}{Mean Field Games and Applications}
      \field{title}{Mean Field Games and Applications: Numerical Aspects}
      \field{urlday}{17}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{volume}{2281}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{249\bibrangedash 307}
      \range{pages}{59}
      \verb{doi}
      \verb 10.1007/978-3-030-59837-2_4
      \endverb
      \verb{file}
      \verb Achdou y Laurière - 2020 - Mean Field Games and Applications Numerical Aspec.pdf:/home/carlos/Zotero/storage/HHG2RD4U/Achdou y Laurière - 2020 - Mean Field Games and Applications Numerical Aspec.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-3-030-59837-2_4
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-3-030-59837-2_4
      \endverb
    \endentry
    \entry{carmona_control_2013}{article}{}
      \name{author}{3}{}{%
        {{hash=370488c27988d8e01125afd81ea71055}{%
           family={Carmona},
           familyi={C\bibinitperiod},
           given={René},
           giveni={R\bibinitperiod}}}%
        {{hash=799c6f3ae3f94478b9b2d2aadabd8387}{%
           family={Delarue},
           familyi={D\bibinitperiod},
           given={François},
           giveni={F\bibinitperiod}}}%
        {{hash=5d456ff8726dbd089fd8e928030848e9}{%
           family={Lachapelle},
           familyi={L\bibinitperiod},
           given={Aimé},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{1a9ae48dcdb0534a8fc804a88b02ee7a}
      \strng{fullhash}{1a9ae48dcdb0534a8fc804a88b02ee7a}
      \strng{bibnamehash}{1a9ae48dcdb0534a8fc804a88b02ee7a}
      \strng{authorbibnamehash}{1a9ae48dcdb0534a8fc804a88b02ee7a}
      \strng{authornamehash}{1a9ae48dcdb0534a8fc804a88b02ee7a}
      \strng{authorfullhash}{1a9ae48dcdb0534a8fc804a88b02ee7a}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We discuss and compare two methods of investigations for the asymptotic regime of stochastic diﬀerential games with a ﬁnite number of players as the number of players tends to the inﬁnity. These two methods diﬀer in the order in which optimization and passage to the limit are performed. When optimizing ﬁrst, the asymptotic problem is usually referred to as a mean-ﬁeld game. Otherwise, it reads as an optimization problem over controlled dynamics of {McKean}-Vlasov type. Both problems lead to the analysis of forward-backward stochastic diﬀerential equations, the coeﬃcients of which depend on the marginal distributions of the solutions. We explain the diﬀerence between the nature and solutions to the two approaches by investigating the corresponding forward-backward systems. General results are stated and speciﬁc examples are treated, especially when cost functionals are of linear-quadratic type.}
      \field{issn}{1862-9679, 1862-9660}
      \field{journaltitle}{Mathematics and Financial Economics}
      \field{langid}{english}
      \field{month}{3}
      \field{number}{2}
      \field{shortjournal}{Math Finan Econ}
      \field{title}{Control of {McKean}–Vlasov dynamics versus mean field games}
      \field{urlday}{30}
      \field{urlmonth}{5}
      \field{urlyear}{2023}
      \field{volume}{7}
      \field{year}{2013}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{131\bibrangedash 166}
      \range{pages}{36}
      \verb{doi}
      \verb 10.1007/s11579-012-0089-y
      \endverb
      \verb{file}
      \verb Carmona et al. - 2013 - Control of McKean–Vlasov dynamics versus mean fiel.pdf:/home/carlos/Zotero/storage/PSXLZ4LD/Carmona et al. - 2013 - Control of McKean–Vlasov dynamics versus mean fiel.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/s11579-012-0089-y
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/s11579-012-0089-y
      \endverb
    \endentry
    \entry{nusken_solving_2023}{misc}{}
      \name{author}{2}{}{%
        {{hash=1809e073002f6b361a45b910e990e573}{%
           family={Nüsken},
           familyi={N\bibinitperiod},
           given={Nikolas},
           giveni={N\bibinitperiod}}}%
        {{hash=320a939ee9de885642a8b23fb9d71407}{%
           family={Richter},
           familyi={R\bibinitperiod},
           given={Lorenz},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{3fda6a4067919d21da05be927834cf75}
      \strng{fullhash}{3fda6a4067919d21da05be927834cf75}
      \strng{bibnamehash}{3fda6a4067919d21da05be927834cf75}
      \strng{authorbibnamehash}{3fda6a4067919d21da05be927834cf75}
      \strng{authornamehash}{3fda6a4067919d21da05be927834cf75}
      \strng{authorfullhash}{3fda6a4067919d21da05be927834cf75}
      \field{extraname}{2}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Optimal control of diffusion processes is intimately connected to the problem of solving certain Hamilton-Jacobi-Bellman equations. Building on recent machine learning inspired approaches towards high-dimensional {PDEs}, we investigate the potential of \${\textbackslash}textit\{iterative diffusion optimisation\}\$ techniques, in particular considering applications in importance sampling and rare event simulation, and focusing on problems without diffusion control, with linearly controlled drift and running costs that depend quadratically on the control. More generally, our methods apply to nonlinear parabolic {PDEs} with a certain shift invariance. The choice of an appropriate loss function being a central element in the algorithmic design, we develop a principled framework based on divergences between path measures, encompassing various existing methods. Motivated by connections to forward-backward {SDEs}, we propose and study the novel \${\textbackslash}textit\{log-variance\}\$ divergence, showing favourable properties of corresponding Monte Carlo estimators. The promise of the developed approach is exemplified by a range of high-dimensional and metastable numerical examples.}
      \field{day}{29}
      \field{eprinttype}{arxiv}
      \field{month}{1}
      \field{number}{{arXiv}:2005.05409}
      \field{shorttitle}{Solving high-dimensional Hamilton-Jacobi-Bellman {PDEs} using neural networks}
      \field{title}{Solving high-dimensional Hamilton-Jacobi-Bellman {PDEs} using neural networks: perspectives from the theory of controlled diffusions and measures on path space}
      \field{urlday}{27}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2005.05409 [cs, math, stat]
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/home/carlos/Zotero/storage/Z5QRXEMC/Nüsken y Richter - 2023 - Solving high-dimensional Hamilton-Jacobi-Bellman P.pdf:application/pdf;arXiv.org Snapshot:/home/carlos/Zotero/storage/PWJBXAF3/2005.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2005.05409
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2005.05409
      \endverb
      \keyw{Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning,Mathematics - Probability,Mathematics - Optimization and Control}
    \endentry
  \enddatalist
\endrefsection
\endinput

