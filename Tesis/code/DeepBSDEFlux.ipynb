{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3082e04-9306-4f91-a478-e9d4b8997c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux,Random,Optimisers,Statistics,.Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f831b8-7866-4a41-ac64-1544a75186a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_dim (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_dim(x::Array) = reshape(x, (size(x)...,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f1b355c-a70e-4d67-967c-96cd52dae3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g_T (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct HJBEquation\n",
    "    dim::Int64\n",
    "    total_time::Float64\n",
    "    Ndis::Int64\n",
    "    delta_t::Float64\n",
    "    sigma::Float64\n",
    "    x_init::Vector{Float64}\n",
    "    function HJBEquation(eqn_config)\n",
    "        new(eqn_config[\"dim\"],\n",
    "            eqn_config[\"total_time\"],\n",
    "            eqn_config[\"Ndis\"],\n",
    "            eqn_config[\"total_time\"]/eqn_config[\"Ndis\"],\n",
    "            sqrt(2),\n",
    "            zeros(eqn_config[\"dim\"]))\n",
    "    end\n",
    "end \n",
    "\n",
    "function sample(eqn::HJBEquation,num_sample)\n",
    "    dw_sample=randn((num_sample,eqn.dim,eqn.Ndis))*eqn.delta_t^0.5\n",
    "    x_sample = zeros((num_sample, eqn.dim, eqn.Ndis + 1))\n",
    "    x_sample[begin:end,begin:end,1]=transpose(eqn.x_init).*ones((num_sample, eqn.dim))\n",
    "    for i in 1:eqn.Ndis-1\n",
    "        x_sample[begin:end, begin:end, i + 1]=x_sample[begin:end, begin:end, i] .+ eqn.sigma .* dw_sample[begin:end, begin:end, i]\n",
    "    end\n",
    "    return dw_sample, x_sample\n",
    "end\n",
    "\n",
    "function f_t(t,x,y,z)\n",
    "    return sum(z.^2,dims=2)./2\n",
    "end\n",
    "\n",
    "function g_T(t,x)\n",
    "    return log.((1.0 .+ sum(x.^2,dims=2) ./ 2.0))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431ef89a-580c-41d5-8653-a70083ebb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct FF_subnet\n",
    "    model\n",
    "    function FF_subnet(eqn)\n",
    "        modelNN=Chain(\n",
    "        BatchNorm(eqn.dim, initβ=zeros, initγ=ones,ϵ=1e-6, momentum= 0.99),\n",
    "        Dense(eqn.dim=>eqn.dim+100,bias=false,init=rand),\n",
    "        BatchNorm(eqn.dim+100, initβ=zeros, initγ=ones,ϵ=1e-6, momentum= 0.99),\n",
    "        relu,\n",
    "        Dense(eqn.dim+100=>eqn.dim+100,bias=false,init=rand), \n",
    "        BatchNorm(eqn.dim+100, initβ=zeros, initγ=ones,ϵ=1e-6, momentum= 0.99),  \n",
    "        relu,\n",
    "        Dense(eqn.dim+100=>eqn.dim,bias=false,init=rand), \n",
    "        BatchNorm(eqn.dim, initβ=zeros, initγ=ones,ϵ=1e-6, momentum= 0.99),  \n",
    "        )\n",
    "        new(modelNN)\n",
    "    end\n",
    "    (subnet::FF_subnet)(x) =subnet.model(x)\n",
    "end\n",
    "\n",
    "mutable struct GlobalModel\n",
    "    eqn::HJBEquation\n",
    "    subnets\n",
    "    y_init\n",
    "    z_init\n",
    "    function GlobalModel(eqn)\n",
    "        subnets=[FF_subnet(eqn).model for _ in 1:eqn.Ndis]\n",
    "        y_init=rand(Float64,(1))\n",
    "        z_init=(rand(Float64,(1,eqn.dim)).*0.2).-0.1\n",
    "        new(eqn,subnets,y_init,z_init)\n",
    "    end\n",
    "end\n",
    "\n",
    "function call_train(glob::GlobalModel,inputs)\n",
    "    dw, x = inputs\n",
    "    Nmuestras=size(dw)[1]\n",
    "    time=range(0, stop = glob.eqn.Ndis*glob.eqn.delta_t, length = glob.eqn.Ndis) |> collect\n",
    "    y=add_dim((repeat(y_init,Nmuestras)))\n",
    "    z=repeat(z_init,Nmuestras)\n",
    "     \n",
    "    for i in 1:length(glob.subnets)\n",
    "        Flux.trainmode!(glob.subnets[i])\n",
    "    end\n",
    "    \n",
    "    for i in 1:glob.eqn.Ndis-1\n",
    "        y=y-glob.eqn.delta_t*(f_t(time[i],x[begin:end,begin:end,:],y,z))+sum(z.*dw[:, :, i],dims=2)\n",
    "        z=transpose(glob.subnets[i](transpose(x[begin:end,begin:end, i + 1]))./(glob.eqn.dim))\n",
    "    end\n",
    "        \n",
    "    y=y-glob.eqn.delta_t*(f_t(time[end],x[begin:end,begin:end,end-1],y,z))+sum(z.*dw[:, :, end],dims=2)\n",
    "    return y\n",
    "end\n",
    "\n",
    "function call_test(glob::GlobalModel,inputs)\n",
    "    dw, x = inputs\n",
    "    Nmuestras=size(dw)[1]\n",
    "    time=range(0, stop = glob.eqn.Ndis*glob.eqn.delta_t, length = glob.eqn.Ndis) |> collect\n",
    "    y=add_dim((repeat(y_init,Nmuestras)))\n",
    "    z=repeat(z_init,Nmuestras)\n",
    "     \n",
    "    for i in 1:length(glob.subnets)\n",
    "        Flux.testmode!(glob.subnets[i])\n",
    "    end\n",
    "    \n",
    "    for i in 1:glob.eqn.Ndis-1\n",
    "        y=y-glob.eqn.delta_t*(f_t(time[i],x[begin:end,begin:end,:],y,z))+sum(z.*dw[:, :, i],dims=2)\n",
    "        z=transpose(glob.subnets[i](transpose(x[begin:end,begin:end, i + 1]))./(glob.eqn.dim))\n",
    "    end\n",
    "        \n",
    "    y=y-glob.eqn.delta_t*(f_t(time[end],x[begin:end,begin:end,end-1],y,z))+sum(z.*dw[:, :, end],dims=2)\n",
    "    return y\n",
    "end\n",
    "\n",
    "(glob::GlobalModel)(inputs) =call_train(glob,inputs)\n",
    "Flux.@functor GlobalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3168b0-7b1a-4149-871d-acf44079ffaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve_deepBSDE (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DELTA_CLIP=50.0\n",
    "function loss(glob,inputs)\n",
    "    dw,x=inputs\n",
    "    y_terminal=glob(inputs)\n",
    "    delta = y_terminal .- g_T(glob.eqn.total_time, x[begin:end,begin:end, end])\n",
    "    return mean(ifelse.(delta .< DELTA_CLIP, delta.^2, 2 * DELTA_CLIP * abs.(delta) .- DELTA_CLIP^2))\n",
    "end\n",
    "\n",
    "function loss_test(glob,inputs)\n",
    "    dw,x=inputs\n",
    "    y_terminal=call_test(glob,inputs)\n",
    "    delta = y_terminal .- g_T(glob.eqn.total_time, x[begin:end,begin:end, end])\n",
    "    return mean(ifelse.(delta .< DELTA_CLIP, delta.^2, 2 * DELTA_CLIP * abs.(delta) .- DELTA_CLIP^2))\n",
    "end\n",
    "\n",
    "function solve_deepBSDE(glob::GlobalModel)\n",
    "    #opt = Optimisers.Adam(0.01)\n",
    "    #opt_state = Optimisers.setup(opt, glob)\n",
    "    optim = Flux.setup(Flux.Adam(0.01), glob.subnets)\n",
    "    \n",
    "    my_log = []\n",
    "    for epoch in 1:2000\n",
    "        losses = Float32[]\n",
    "        input=sample(glob.eqn,64)\n",
    "\n",
    "        val, grads = Flux.withgradient(glob.subnets) do m\n",
    "          # Any code inside here is differentiated.\n",
    "          # Evaluation of the model and loss must be inside!\n",
    "        result = glob(input)\n",
    "        loss(glob, input)\n",
    "        end\n",
    "\n",
    "        # Save the loss from the forward pass. (Done outside of gradient.)\n",
    "        push!(losses, val)\n",
    "\n",
    "        # Detect loss of Inf or NaN. Print a warning, and then skip update!\n",
    "        if !isfinite(val)\n",
    "          @warn \"loss is $val on item $i\" epoch\n",
    "          continue\n",
    "        end\n",
    "        if epoch%100==0\n",
    "            println(\"Epoch \",epoch, \" losses \",loss_test(glob,sample(glob.eqn,254)))\n",
    "        end\n",
    "\n",
    "        Flux.update!(optim, glob.subnets, grads[1])\n",
    "        #state, model = Optimisers.update(opt_state, glob, grads[1])\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d3ecdf-f41a-4b5b-a417-bb762c95d3ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: HJBEquation not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: HJBEquation not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:1",
      " [2] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "eqn=HJBEquation(Dict(\"dim\"=>100,\"total_time\"=>1.0,\"Ndis\"=>20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1cd72e-fc1c-4654-b415-04ef9582c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw,x=sample(eqn,15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e846814-6e48-4eb5-9133-607f70ee9cba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×10 Matrix{Float64}:\n",
       " -0.010744  -0.0168559  0.085374  …  -0.00974729  0.0153075  0.0177779"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_init=rand(Float64,(1))\n",
    "z_init=(rand(Float64,(1,10)).*0.2).-0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed794157-9d4e-487e-93d2-eb3b26a8c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob=GlobalModel(eqn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074a6c04-848c-4865-94e2-6a5f15605f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 losses 0.7948490405567581\n",
      "Epoch 200 losses 0.7755333527766887\n",
      "Epoch 300 losses 0.8033820337035619\n",
      "Epoch 400 losses 0.7496778880126584\n",
      "Epoch 500 losses 0.7595727514283246\n",
      "Epoch 600 losses 0.8635234437202844\n",
      "Epoch 700 losses 0.857349550372989\n",
      "Epoch 800 losses 0.7767400126213\n",
      "Epoch 900 losses 0.8270851965812074\n",
      "Epoch 1000 losses 0.7726272830609059\n",
      "Epoch 1100 losses 0.7295494389715612\n",
      "Epoch 1200 losses 0.6746803115249647\n",
      "Epoch 1300 losses 0.796480948826693\n",
      "Epoch 1400 losses 0.8577938825165058\n",
      "Epoch 1500 losses 0.7826781960710344\n",
      "Epoch 1600 losses 0.8026195889658705\n",
      "Epoch 1700 losses 0.8072196031427402\n",
      "Epoch 1800 losses 0.8454634639948534\n",
      "Epoch 1900 losses 0.74170846484631\n",
      "Epoch 2000 losses 0.8033973525332977\n",
      "127.328162 seconds (345.05 M allocations: 140.478 GiB, 8.42% gc time, 30.64% compilation time)\n"
     ]
    }
   ],
   "source": [
    "@time solve_deepBSDE(glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95f136-2446-444b-9d71-344479da4e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
