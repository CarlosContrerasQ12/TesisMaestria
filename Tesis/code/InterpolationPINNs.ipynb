{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db451c1e-59ef-4f4f-baf5-b5dc49ad4d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm as WN\n",
    "from torch.optim.lr_scheduler import MultiStepLR, StepLR,ReduceLROnPlateau\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from matplotlib.animation import FuncAnimation\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "types=torch.float64\n",
    "torch.set_default_dtype(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f451f6-eb21-4243-bfee-f061a1c564fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDE_boundary_PINN_BSDE():\n",
    "    def __init__(self, eqn_config):\n",
    "        self.dim=eqn_config[\"dim\"]\n",
    "        self.total_time=eqn_config[\"total_time\"]\n",
    "        self.lambd = 4.0\n",
    "        self.model=ResNetLikeDGM(3,1)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(),lr=0.01,weight_decay=0.00001)\n",
    "        self.scheduler2 = StepLR(self.optimizer,step_size=5000,gamma=0.5)\n",
    "        self.scheduler=ReduceLROnPlateau(self.optimizer, 'min',factor=0.8,threshold=1e-3,patience=15)\n",
    "        \n",
    "    def interior_sample(self,num_sample):\n",
    "        t=np.random.uniform(low=0,high=self.total_time,size=[num_sample,1])\n",
    "        x=np.random.uniform(size=(num_sample,self.dim))\n",
    "        return torch.tensor(np.hstack((t,x)),requires_grad=True)\n",
    "    \n",
    "    def dirichlet_sample(self,num_sample):\n",
    "        t=np.random.uniform(low=0,high=self.total_time,size=[num_sample,1])\n",
    "        x=np.stack((np.ones(num_sample),np.random.uniform(size=num_sample)*0.2),axis=1)\n",
    "        return torch.tensor(np.hstack((t,x)),requires_grad=True)\n",
    "    \n",
    "    def neumann_sample(self,num_sample):\n",
    "        Ns=int(num_sample/4)\n",
    "        iz=np.stack((np.zeros(Ns),np.random.uniform(size=Ns)),axis=1)\n",
    "        niz=np.repeat([[1.0,0.0]],Ns,0)\n",
    "        up=np.stack((np.random.uniform(size=Ns),np.ones(Ns)),axis=1)\n",
    "        nup=np.repeat([[0.0,1.0]],Ns,0)\n",
    "        down=np.stack((np.random.uniform(size=Ns),np.zeros(Ns)),axis=1)\n",
    "        ndown=np.repeat([[0.0,-1.0]],Ns,0)\n",
    "        der=np.stack((np.ones(Ns),0.2+np.random.uniform(size=Ns)*0.8),axis=1)\n",
    "        nder=np.repeat([[-1.0,0.0]],Ns,0)\n",
    "        x=np.concatenate((iz,up,down,der))\n",
    "        t=np.random.uniform(low=0,high=self.total_time,size=[x.shape[0],1])\n",
    "        return torch.tensor(np.hstack((t,x)),requires_grad=True),torch.tensor(np.concatenate((niz,nup,ndown,nder)))\n",
    "    \n",
    "    def terminal_sample(self,num_sample):\n",
    "        T=np.ones(shape=[num_sample,1])*self.total_time\n",
    "        x=np.random.uniform(size=[num_sample,self.dim])\n",
    "        return torch.tensor(np.hstack((T,x)),requires_grad=True)\n",
    "        \n",
    "    def loss(self,interior_sample,neumann_sample,dirichlet_sample,terminal_sample):\n",
    "        \n",
    "        V=self.model(interior_sample)\n",
    "        dV=torch.autograd.grad(V,interior_sample, grad_outputs=torch.ones_like(V),retain_graph=True,create_graph=True,only_inputs=True)[0]\n",
    "        V_t=dV[:,0]\n",
    "        V_x=dV[:,1:]\n",
    "        V_xx=torch.autograd.grad(dV,interior_sample,grad_outputs=torch.ones_like(dV),retain_graph=True,create_graph=True,only_inputs=True)[0][:,1:]\n",
    "        diff_V=self.Lv(interior_sample, V_t,V_x,V_xx)\n",
    "        L1=torch.mean(torch.square(diff_V))\n",
    "        \n",
    "        x_neumann,n_neumann=neumann_sample\n",
    "        Vn=self.model(x_neumann)\n",
    "        dVn=torch.autograd.grad(Vn,x_neumann, grad_outputs=torch.ones_like(Vn),retain_graph=True,create_graph=True,only_inputs=True)[0]\n",
    "        V_nx=dVn[:,1:]\n",
    "        normaldVn=torch.sum(V_nx*n_neumann,axis=1)\n",
    "        L2=torch.mean(torch.square(normaldVn-self.h_n(x_neumann)))\n",
    "        \n",
    "        Vd=self.model(dirichlet_sample)\n",
    "        L3=torch.mean(torch.square(Vd-self.h_d(dirichlet_sample)))\n",
    "        \n",
    "        Vter=self.model(terminal_sample)\n",
    "        L4=torch.mean(torch.square(Vter-self.g_Tf(terminal_sample)))\n",
    "        \n",
    "        return L1+L2+2*L3+L4\n",
    "    \n",
    "    def h_n(self,x):\n",
    "        \"\"\"Neumann boundary condition\"\"\"\n",
    "        return torch.zeros(x.shape[0])\n",
    "    \n",
    "    def h_d(self,x):\n",
    "        \"\"\"Dirichlet boundary condition\"\"\"\n",
    "        return -1.0*torch.ones(x.shape[0])\n",
    "    \n",
    "    def g_Tf(self,x):\n",
    "        \"\"\"Terminal condition\"\"\"\n",
    "        lens=x[:,1:]-torch.tensor(np.repeat([[1.0,0.05]],x.shape[0],0))\n",
    "        #return torch.zeros(x.shape[0])\n",
    "        return torch.sqrt(torch.sum(lens*lens,axis=1))\n",
    "        \n",
    "    def Lv(self, x, V_t,V_x,V_xx):\n",
    "        #return V_t-0.5*torch.sum(V_xx,axis=1)\n",
    "        return V_t+torch.sum(V_xx,axis=1)-self.lambd*torch.sum(V_x*V_x,axis=1)\n",
    "    \n",
    "    def train(self,Nsteps):\n",
    "        start_time = time.time()\n",
    "        training_history = []\n",
    "        interior_valid = self.interior_sample(512)\n",
    "        neumann_valid= self.neumann_sample(512)\n",
    "        dirichlet_valid=self.dirichlet_sample(512)\n",
    "        terminal_valid=self.terminal_sample(512)\n",
    "\n",
    "        # begin sgd iteration\n",
    "        for step in range(Nsteps+1):\n",
    "            #print(step)\n",
    "            interior = self.interior_sample(512)\n",
    "            neumann= self.neumann_sample(512)\n",
    "            dirichlet=self.dirichlet_sample(512)\n",
    "            terminal=self.terminal_sample(512)\n",
    "            loss=self.loss(interior,neumann,dirichlet,terminal)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            for _ in range(10):\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step(loss)\n",
    "            \n",
    "            \n",
    "            if step % 200==0:\n",
    "                self.scheduler2.step()\n",
    "                loss = self.loss(interior_valid,neumann_valid,dirichlet_valid,terminal_valid).detach().numpy()\n",
    "                #y_init = self.y_0.detach().numpy()[0]\n",
    "                elapsed_time = time.time() - start_time\n",
    "                training_history.append([step, loss, elapsed_time])\n",
    "                print(\"Epoch \",step,\" time \", elapsed_time,\" loss \", loss)\n",
    "\n",
    "        return np.array(training_history)\n",
    "    def save_model(self,file_name):\n",
    "        torch.save(self.model.state_dict(), file_name)\n",
    "    def load_model(self,file_name):\n",
    "        self.model.load_state_dict(torch.load(file_name))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
