{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76dc506a-f19e-4861-ad23-e8e117b85ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import time\n",
    "types=torch.float32\n",
    "torch.set_default_dtype(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "729f6242-129d-483d-ba14-d253e319ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HJBEquation():\n",
    "    \"\"\"HJB equation in PNAS paper doi.org/10.1073/pnas.1718942115\"\"\"\n",
    "    def __init__(self, eqn_config):\n",
    "        self.dim=eqn_config[\"dim\"]\n",
    "        self.total_time=eqn_config[\"total_time\"]\n",
    "        self.Ndis=eqn_config[\"Ndis\"]\n",
    "        self.delta_t=self.total_time/self.Ndis\n",
    "        self.sqrt_delta_t = np.sqrt(self.delta_t)\n",
    "        self.x_init = torch.zeros(self.dim,requires_grad=False)\n",
    "        self.sigma = np.sqrt(2.0)\n",
    "        self.lambd = 1.0\n",
    "\n",
    "    def sample(self, num_sample):\n",
    "        dw_sample =torch.tensor( np.random.normal(size=[num_sample, self.dim, self.Ndis]) * self.sqrt_delta_t,requires_grad=False)\n",
    "        x_sample = torch.zeros([num_sample, self.dim, self.Ndis + 1],requires_grad=False)\n",
    "        x_sample[:, :, 0] = torch.ones([num_sample, self.dim]) * self.x_init\n",
    "        for i in range(self.Ndis):\n",
    "            x_sample[:, :, i + 1] = x_sample[:, :, i] + self.sigma * dw_sample[:, :, i]\n",
    "        return dw_sample, x_sample\n",
    "\n",
    "    def f_tf(self, t, x, y, z):\n",
    "        return -self.lambd * torch.sum(torch.square(z), 1, keepdims=True) / 2\n",
    "\n",
    "    def g_tf(self, x):\n",
    "        return torch.log((1 + torch.sum(torch.square(x), 1, keepdims=True)) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d1f85b-f4a0-4b10-88d3-f3a2843ec3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalModelDeepBSDE(nn.Module):\n",
    "    def __init__(self, net_config, eqn):\n",
    "        super(GlobalModelDeepBSDE, self).__init__()\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "        self.y_0=nn.Parameter(torch.rand(1))\n",
    "        self.z_0=nn.Parameter((torch.rand((1,self.eqn.dim))*0.2)-0.1)\n",
    "        self.subnet = [FF_subnet_DBSDE(self.eqn,net_config) for _ in range(self.eqn.Ndis-1)]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        dw, x = inputs\n",
    "        time_stamp = np.arange(0, self.eqn.Ndis) * self.eqn.delta_t\n",
    "        all_one_vec = torch.ones((dw.shape[0], 1))\n",
    "        y = all_one_vec * self.y_0\n",
    "        z = torch.matmul(all_one_vec, self.z_0)\n",
    "\n",
    "        for t in range(0, self.eqn.Ndis-1):\n",
    "            y = y - self.eqn.delta_t * (\n",
    "                self.eqn.f_tf(time_stamp[t], x[:, :, t], y, z)\n",
    "            ) + torch.sum(z * dw[:, :, t], 1, keepdims=True)\n",
    "            z = self.subnet[t](x[:, :, t + 1]) / self.eqn.dim\n",
    "        # terminal time\n",
    "        y = y - self.eqn.delta_t * self.eqn.f_tf(time_stamp[-1], x[:, :, -2], y, z) + \\\n",
    "            torch.sum(z * dw[:, :, -1], 1, keepdims=True)\n",
    "        return y\n",
    "\n",
    "\n",
    "class FF_subnet_DBSDE(nn.Module):\n",
    "    def __init__(self, eqn,net_config):\n",
    "        super(FF_subnet_DBSDE, self).__init__()\n",
    "        self.dim = eqn.dim\n",
    "        self.num_hiddens = net_config[\"num_hiddens\"]\n",
    "        self.net=nn.Sequential(\n",
    "                            nn.BatchNorm1d(self.dim, eps=1e-06, momentum=0.99,affine=False,dtype=types),\n",
    "                            nn.Linear(self.dim,self.dim+10,bias=False),\n",
    "                            nn.BatchNorm1d(self.dim+10, eps=1e-06, momentum=0.99,affine=False,dtype=types),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(self.dim+10,self.dim+10,bias=False),\n",
    "                            nn.BatchNorm1d(self.dim+10, eps=1e-06, momentum=0.99,affine=False,dtype=types),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(self.dim+10,self.dim,bias=False),\n",
    "                            nn.BatchNorm1d(self.dim, eps=1e-06, momentum=0.99,affine=False,dtype=types)\n",
    "                            )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class BSDESolver(object):\n",
    "    \"\"\"The fully connected neural network model.\"\"\"\n",
    "    def __init__(self,eqn, net_config):\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "\n",
    "        #self.model = torch.compile(GlobalModel(net_config, eqn), mode=\"max-autotune\")\n",
    "        self.model = GlobalModelDeepBSDE(net_config, eqn)\n",
    "        self.y_0 = self.model.y_0\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        #lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "            #self.net_config.lr_boundaries, self.net_config.lr_values)\n",
    "        #self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, epsilon=1e-8)\n",
    "\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        training_history = []\n",
    "        valid_data = self.eqn.sample(256)\n",
    "\n",
    "        # begin sgd iteration\n",
    "        for step in range(2001):\n",
    "            #print(step)\n",
    "            inputs=self.eqn.sample(64)\n",
    "            results=self.model(inputs)\n",
    "            loss=self.loss_fn(inputs,results)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if step % 200==0:\n",
    "                loss = self.loss_fn(valid_data, self.model(valid_data)).detach().numpy()\n",
    "                y_init = self.y_0.detach().numpy()[0]\n",
    "                elapsed_time = time.time() - start_time\n",
    "                training_history.append([step, loss, y_init, elapsed_time])\n",
    "                print(\"Epoch \",step, \" y_0 \",y_init,\" time \", elapsed_time,\" loss \", loss)\n",
    "\n",
    "        return np.array(training_history)\n",
    "\n",
    "    def loss_fn(self, inputs,results):\n",
    "        DELTA_CLIP = 50.0\n",
    "        dw, x = inputs\n",
    "        y_terminal = self.model(inputs)\n",
    "        delta = results - self.eqn.g_tf(x[:, :, -1])\n",
    "        # use linear approximation outside the clipped range\n",
    "        loss = torch.mean(torch.where(torch.abs(delta) < DELTA_CLIP, torch.square(delta),\n",
    "                                       2 * DELTA_CLIP * torch.abs(delta) - DELTA_CLIP ** 2))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440fc0b5-8277-44b7-880a-2b31b136dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalModelMergedDeepBSDE(nn.Module):\n",
    "    def __init__(self, net_config, eqn):\n",
    "        super(GlobalModelMergedDeepBSDE, self).__init__()\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "        self.dim=eqn.dim\n",
    "        self.model=FF_subnet_Merged_DBSDE(self.eqn,net_config)\n",
    "        self.y_0=nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        dw, x = inputs\n",
    "        time_stamp = np.arange(0, self.eqn.Ndis) * self.eqn.delta_t\n",
    "        all_one_vec = torch.ones((dw.shape[0], 1))\n",
    "        y = all_one_vec * self.y_0\n",
    "        #z = torch.matmul(all_one_vec, self.z_0)\n",
    "\n",
    "        for t in range(0, self.eqn.Ndis):\n",
    "            inp=torch.hstack((time_stamp[t]*all_one_vec,x[:,:,t]))\n",
    "            z = self.model(inp) / self.eqn.dim\n",
    "            y = y - self.eqn.delta_t * (\n",
    "                self.eqn.f_tf(time_stamp[t], x[:, :, t], y, z)\n",
    "            ) + torch.sum(z * dw[:, :, t], 1, keepdims=True)\n",
    "            \n",
    "        return y\n",
    "\n",
    "class FF_subnet_Merged_DBSDE(nn.Module):\n",
    "    def __init__(self, eqn,net_config):\n",
    "        super(FF_subnet_Merged_DBSDE, self).__init__()\n",
    "        self.dim = eqn.dim\n",
    "        self.net = nn.Sequential(\n",
    "                            nn.Linear(self.dim+1,2*self.dim,bias=False),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,2*self.dim,bias=False),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,2*self.dim,bias=False),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,self.dim,bias=False)\n",
    "                            )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Merged_BSDE_Solver(object):\n",
    "    \"\"\"The fully connected neural network model.\"\"\"\n",
    "    def __init__(self,eqn, net_config):\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "\n",
    "        #self.model = torch.compile(GlobalModel(net_config, eqn), mode=\"max-autotune\")\n",
    "        self.model = GlobalModelMergedDeepBSDE(net_config, eqn)\n",
    "        self.y_0 = self.model.y_0\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        #lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "            #self.net_config.lr_boundaries, self.net_config.lr_values)\n",
    "        #self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, epsilon=1e-8)\n",
    "\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        training_history = []\n",
    "        valid_data = self.eqn.sample(256)\n",
    "\n",
    "        # begin sgd iteration\n",
    "        for step in range(2001):\n",
    "            #print(step)\n",
    "            inputs=self.eqn.sample(64)\n",
    "            results=self.model(inputs)\n",
    "            loss=self.loss_fn(inputs,results)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if step % 200==0:\n",
    "                loss = self.loss_fn(valid_data, self.model(valid_data)).detach().numpy()\n",
    "                y_init = self.y_0.detach().numpy()[0]\n",
    "                elapsed_time = time.time() - start_time\n",
    "                training_history.append([step, loss, y_init, elapsed_time])\n",
    "                print(\"Epoch \",step, \" y_0 \",y_init,\" time \", elapsed_time,\" loss \", loss)\n",
    "\n",
    "        return np.array(training_history)\n",
    "\n",
    "    def loss_fn(self, inputs,results):\n",
    "        DELTA_CLIP = 50.0\n",
    "        dw, x = inputs\n",
    "        y_terminal = self.model(inputs)\n",
    "        delta = results - self.eqn.g_tf(x[:, :, -1])\n",
    "        # use linear approximation outside the clipped range\n",
    "        loss = torch.mean(torch.where(torch.abs(delta) < DELTA_CLIP, torch.square(delta),\n",
    "                                       2 * DELTA_CLIP * torch.abs(delta) - DELTA_CLIP ** 2))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5a10d388-1347-48b3-a37b-9abe32acf328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,11)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "855a146a-74c9-453d-bbf0-384c0cd0aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FF_net_Raissi(nn.Module):\n",
    "    def __init__(self, eqn,net_config):\n",
    "        super(FF_net_Raissi, self).__init__()\n",
    "        self.dim = eqn.dim\n",
    "        self.net = nn.Sequential(\n",
    "                            nn.Linear(self.dim+1,2*self.dim,bias=True),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,2*self.dim,bias=True),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,2*self.dim,bias=True),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,2*self.dim,bias=True),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,1,bias=True),\n",
    "                            )\n",
    "    def forward(self,tx):\n",
    "        return self.net(tx)\n",
    "        #return self.net(torch.hstack((t*torch.ones((x.shape[0], 1)),x)))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class Raissi_BSDE_Solver(object):\n",
    "    \"\"\"The fully connected neural network model.\"\"\"\n",
    "    def __init__(self,eqn, net_config):\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "\n",
    "        #self.model = torch.compile(GlobalModel(net_config, eqn), mode=\"max-autotune\")\n",
    "        self.net = FF_net_Raissi(eqn,net_config)\n",
    "        #self.y_0 = nn.Parameter(torch.rand(1))\n",
    "        self.times=np.arange(0, self.eqn.Ndis+1) * self.eqn.delta_t\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=0.01)\n",
    "\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        training_history = []\n",
    "        valid_data = self.eqn.sample(256)\n",
    "        dw, x =valid_data\n",
    "\n",
    "        # begin sgd iteration\n",
    "        for step in range(2001):\n",
    "            #print(step)\n",
    "            inputs=self.eqn.sample(64)\n",
    "            #results=self.model(inputs)\n",
    "            loss=self.loss_total(inputs)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if step % 200==0:\n",
    "                loss = self.loss_total(valid_data).detach().numpy()\n",
    "                tx=torch.hstack((self.times[0]*torch.ones((x.shape[0], 1)),x[:,:,0]))\n",
    "                y_init = self.net(tx).detach().numpy()[0][0]\n",
    "                elapsed_time = time.time() - start_time\n",
    "                training_history.append([step, loss, y_init, elapsed_time])\n",
    "                print(\"Epoch \",step, \" y_0 \",y_init,\" time \", elapsed_time,\" loss \", loss)\n",
    "\n",
    "        return np.array(training_history)\n",
    "    def Dg_tf(self,X): # M x D\n",
    "        Gt=self.eqn.g_tf(X)\n",
    "        return torch.autograd.grad(Gt, X, create_graph=True,grad_outputs=torch.ones_like(Gt),allow_unused=True)[0]\n",
    "    \n",
    "    def loss_total(self, inputs):\n",
    "        loss=0.0\n",
    "        dw, x = inputs\n",
    "        tx=torch.hstack((self.times[0]*torch.ones((x.shape[0], 1)),x[:,:,0]))\n",
    "        tx.requires_grad_()\n",
    "        Y0=self.net(tx)\n",
    "        Z0 = torch.autograd.grad(Y0, tx, create_graph=True,grad_outputs=torch.ones_like(Y0),allow_unused=True)[0][:,1:]\n",
    "        \n",
    "        for t in range(self.eqn.Ndis):\n",
    "            Y1_tilde = Y0 + self.eqn.f_tf(self.times[t],x[:,:,0],Y0,Z0)*self.eqn.delta_t + torch.sum(Z0 * dw[:, :, t], 1, keepdims=True)\n",
    "            tx=torch.hstack((self.times[t+1]*torch.ones((x.shape[0], 1)),x[:,:,t+1]))\n",
    "            tx.requires_grad_()\n",
    "            Y1=self.net(tx)\n",
    "            Z1=torch.autograd.grad(Y1, tx, create_graph=True,grad_outputs=torch.ones_like(Y1),allow_unused=True)[0][:,1:]\n",
    "            loss+=torch.sum(torch.square(Y1_tilde-Y1))\n",
    "            Y0=Y1\n",
    "            Z0=Z1\n",
    "        \n",
    "        loss += torch.sum(torch.square(Y1 - self.eqn.g_tf(x[:,:,-1])))\n",
    "        x.requires_grad_()\n",
    "        loss += torch.sum(torch.square(Z1 - self.Dg_tf(x[:,:,-1])))\n",
    "        return loss\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "26f62faf-b354-446a-b516-51122b44b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqn=HJBEquation({\"dim\":100,\"total_time\":1.0,\"Ndis\":20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "90ceeb72-7398-4f6b-830e-b7337d14e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsde_solver = BSDESolver(eqn,{\"num_hiddens\":2,\"dtype\":'float64'})\n",
    "merged_bsde_solver = BSDESolver(eqn,{\"num_hiddens\":2,\"dtype\":'float64'})\n",
    "raissi_bsde_solver=Raissi_BSDE_Solver(eqn,{\"num_hiddens\":2,\"dtype\":'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f3c89d-c5ac-47d8-ac35-e943c1bca050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  y_0  0.024651418  time  0.11657214164733887  loss  21.008406567426228\n",
      "Epoch  200  y_0  1.7480297  time  5.101586818695068  loss  5.965802361533653\n",
      "Epoch  400  y_0  2.5713747  time  9.989607572555542  loss  3.1400265639773015\n",
      "Epoch  600  y_0  3.2447877  time  14.885701179504395  loss  1.8466851338470927\n",
      "Epoch  800  y_0  3.9214158  time  19.769885778427124  loss  0.6652847482735919\n",
      "Epoch  1000  y_0  4.3777547  time  24.661163568496704  loss  0.11554710254698819\n",
      "Epoch  1200  y_0  4.5520897  time  29.545178174972534  loss  0.03571667198614602\n",
      "Epoch  1400  y_0  4.5878286  time  34.431739807128906  loss  0.032207409658111974\n",
      "Epoch  1600  y_0  4.5954113  time  39.327043771743774  loss  0.031009219598391556\n",
      "Epoch  1800  y_0  4.598763  time  44.22826647758484  loss  0.03173958647942544\n",
      "Epoch  2000  y_0  4.5953074  time  49.11518955230713  loss  0.03190324346831917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 2.10084066e+01, 2.46514175e-02, 1.16572142e-01],\n",
       "       [2.00000000e+02, 5.96580236e+00, 1.74802971e+00, 5.10158682e+00],\n",
       "       [4.00000000e+02, 3.14002656e+00, 2.57137465e+00, 9.98960757e+00],\n",
       "       [6.00000000e+02, 1.84668513e+00, 3.24478769e+00, 1.48857012e+01],\n",
       "       [8.00000000e+02, 6.65284748e-01, 3.92141581e+00, 1.97698858e+01],\n",
       "       [1.00000000e+03, 1.15547103e-01, 4.37775469e+00, 2.46611636e+01],\n",
       "       [1.20000000e+03, 3.57166720e-02, 4.55208969e+00, 2.95451782e+01],\n",
       "       [1.40000000e+03, 3.22074097e-02, 4.58782864e+00, 3.44317398e+01],\n",
       "       [1.60000000e+03, 3.10092196e-02, 4.59541130e+00, 3.93270438e+01],\n",
       "       [1.80000000e+03, 3.17395865e-02, 4.59876299e+00, 4.42282665e+01],\n",
       "       [2.00000000e+03, 3.19032435e-02, 4.59530735e+00, 4.91151896e+01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsde_solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef0bf70-4ac2-4ab0-b75e-1ae3de567170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  y_0  0.8912061  time  0.07808279991149902  loss  13.67742695001863\n",
      "Epoch  200  y_0  2.5708623  time  5.006568908691406  loss  3.4231703089464363\n",
      "Epoch  400  y_0  3.4342017  time  9.888447761535645  loss  1.495930806863312\n",
      "Epoch  600  y_0  4.0999155  time  14.765660762786865  loss  0.3966359336852514\n",
      "Epoch  800  y_0  4.471634  time  19.64422583580017  loss  0.05698976950765269\n",
      "Epoch  1000  y_0  4.577501  time  24.534709453582764  loss  0.03384459338410853\n",
      "Epoch  1200  y_0  4.593001  time  29.413618326187134  loss  0.03387129571859156\n",
      "Epoch  1400  y_0  4.5921683  time  34.290764808654785  loss  0.03251961704018899\n",
      "Epoch  1600  y_0  4.5948195  time  39.1920850276947  loss  0.03286078295005468\n",
      "Epoch  1800  y_0  4.5956793  time  44.14352083206177  loss  0.03386297165276013\n",
      "Epoch  2000  y_0  4.5951767  time  49.03537082672119  loss  0.03344524612148178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.36774270e+01, 8.91206086e-01, 7.80827999e-02],\n",
       "       [2.00000000e+02, 3.42317031e+00, 2.57086229e+00, 5.00656891e+00],\n",
       "       [4.00000000e+02, 1.49593081e+00, 3.43420172e+00, 9.88844776e+00],\n",
       "       [6.00000000e+02, 3.96635934e-01, 4.09991550e+00, 1.47656608e+01],\n",
       "       [8.00000000e+02, 5.69897695e-02, 4.47163391e+00, 1.96442258e+01],\n",
       "       [1.00000000e+03, 3.38445934e-02, 4.57750082e+00, 2.45347095e+01],\n",
       "       [1.20000000e+03, 3.38712957e-02, 4.59300089e+00, 2.94136183e+01],\n",
       "       [1.40000000e+03, 3.25196170e-02, 4.59216833e+00, 3.42907648e+01],\n",
       "       [1.60000000e+03, 3.28607830e-02, 4.59481955e+00, 3.91920850e+01],\n",
       "       [1.80000000e+03, 3.38629717e-02, 4.59567928e+00, 4.41435208e+01],\n",
       "       [2.00000000e+03, 3.34452461e-02, 4.59517670e+00, 4.90353708e+01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_bsde_solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "97440362-3340-4b99-bed4-d89fd840c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  y_0  [0.8659583]  time  0.1250009536743164  loss  2377.671400258971\n",
      "Epoch  200  y_0  [4.51918]  time  8.195310831069946  loss  10.066446997864508\n",
      "Epoch  400  y_0  [4.5304646]  time  16.30252981185913  loss  9.850023431799535\n",
      "Epoch  600  y_0  [4.5362096]  time  24.36612558364868  loss  9.330826614109046\n",
      "Epoch  800  y_0  [4.5330725]  time  32.407026052474976  loss  9.489533338991754\n",
      "Epoch  1000  y_0  [4.5201335]  time  40.50288701057434  loss  8.900748463315185\n",
      "Epoch  1200  y_0  [4.5890684]  time  48.672719955444336  loss  10.100365392985488\n",
      "Epoch  1400  y_0  [4.5701017]  time  56.72680640220642  loss  8.745620604769396\n",
      "Epoch  1600  y_0  [4.5049753]  time  64.78528261184692  loss  8.401678908261598\n",
      "Epoch  1800  y_0  [4.5326095]  time  72.94533801078796  loss  8.456892131958792\n",
      "Epoch  2000  y_0  [4.5011926]  time  81.32745790481567  loss  8.357344548002208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10057/3181540992.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(training_history)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, array(2377.67140026), array([0.8659583], dtype=float32),\n",
       "        0.1250009536743164],\n",
       "       [200, array(10.066447), array([4.51918], dtype=float32),\n",
       "        8.195310831069946],\n",
       "       [400, array(9.85002343), array([4.5304646], dtype=float32),\n",
       "        16.30252981185913],\n",
       "       [600, array(9.33082661), array([4.5362096], dtype=float32),\n",
       "        24.36612558364868],\n",
       "       [800, array(9.48953334), array([4.5330725], dtype=float32),\n",
       "        32.407026052474976],\n",
       "       [1000, array(8.90074846), array([4.5201335], dtype=float32),\n",
       "        40.50288701057434],\n",
       "       [1200, array(10.10036539), array([4.5890684], dtype=float32),\n",
       "        48.672719955444336],\n",
       "       [1400, array(8.7456206), array([4.5701017], dtype=float32),\n",
       "        56.72680640220642],\n",
       "       [1600, array(8.40167891), array([4.5049753], dtype=float32),\n",
       "        64.78528261184692],\n",
       "       [1800, array(8.45689213), array([4.5326095], dtype=float32),\n",
       "        72.94533801078796],\n",
       "       [2000, array(8.35734455), array([4.5011926], dtype=float32),\n",
       "        81.32745790481567]], dtype=object)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raissi_bsde_solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ec1c8-a32b-4469-9bcd-8d3bf2881061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
