{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ffbef5b-f7ae-41c2-8123-84454d67e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcc2c51a-9193-4ba2-a7f2-18e4f22d8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HJBEquation():\n",
    "    \"\"\"HJB equation in PNAS paper doi.org/10.1073/pnas.1718942115\"\"\"\n",
    "    def __init__(self, eqn_config):\n",
    "        self.dim=eqn_config[\"dim\"]\n",
    "        self.total_time=eqn_config[\"total_time\"]\n",
    "        self.Ndis=eqn_config[\"Ndis\"]\n",
    "        self.delta_t=self.total_time/self.Ndis\n",
    "        self.sqrt_delta_t = np.sqrt(self.delta_t)\n",
    "        self.x_init = np.zeros(self.dim)\n",
    "        self.sigma = np.sqrt(2.0)\n",
    "        self.lambd = 1.0\n",
    "        self.key=random.PRNGKey(758493)\n",
    "\n",
    "    def sample(self, num_sample):\n",
    "        self.key, subkey = random.split(self.key)\n",
    "        dw_sample =np.random.normal(size=(num_sample, self.dim, self.Ndis)) * self.sqrt_delta_t\n",
    "        x_sample = np.zeros([num_sample, self.dim, self.Ndis + 1])\n",
    "        x_sample[:, :, 0] = np.ones([num_sample, self.dim]) * self.x_init\n",
    "        for i in range(self.Ndis):\n",
    "            x_sample[:, :, i + 1] = x_sample[:, :, i] + self.sigma * dw_sample[:, :, i]\n",
    "        return dw_sample, x_sample\n",
    "\n",
    "    def f_tf(self, t, x, y, z):\n",
    "        return -self.lambd * jnp.sum(jnp.square(z), axis=1, keepdims=True) / 2\n",
    "\n",
    "    def g_tf(self, t, x):\n",
    "        return jnp.log((1 + jnp.sum(jnp.square(x), axis=1, keepdims=True)) / 2)\n",
    "    \n",
    "class GlobalModel(eqx.Module):\n",
    "    def __init__(self, net_config, eqn):\n",
    "        super(GlobalModel, self).__init__()\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "        self.y_0=nn.Parameter(torch.rand(1))\n",
    "        self.z_0=nn.Parameter((torch.rand((1,self.eqn.dim))*0.2)-0.1)\n",
    "        self.subnet = [FF_subnet(self.eqn,net_config) for _ in range(self.eqn.Ndis-1)]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        dw, x = inputs\n",
    "        time_stamp = np.arange(0, self.eqn.Ndis) * self.eqn.delta_t\n",
    "        all_one_vec = torch.ones((dw.shape[0], 1))\n",
    "        y = all_one_vec * self.y_0\n",
    "        z = torch.matmul(all_one_vec, self.z_0)\n",
    "\n",
    "        for t in range(0, self.eqn.Ndis-1):\n",
    "            y = y - self.eqn.delta_t * (\n",
    "                self.eqn.f_tf(time_stamp[t], x[:, :, t], y, z)\n",
    "            ) + torch.sum(z * dw[:, :, t], 1, keepdims=True)\n",
    "            z = self.subnet[t](x[:, :, t + 1]) / self.eqn.dim\n",
    "        # terminal time\n",
    "        y = y - self.eqn.delta_t * self.eqn.f_tf(time_stamp[-1], x[:, :, -2], y, z) + \\\n",
    "            torch.sum(z * dw[:, :, -1], 1, keepdims=True)\n",
    "        return y\n",
    "\n",
    "\n",
    "class FF_subnet(eqx.Module):\n",
    "    def __init__(self, eqn,net_config):\n",
    "        super(FF_subnet, self).__init__()\n",
    "        self.dim = eqn.dim\n",
    "        self.num_hiddens = net_config[\"num_hiddens\"]\n",
    "        self.net=nn.Sequential(\n",
    "                            nn.BatchNorm1d(self.dim, eps=1e-06, momentum=0.99,affine=False,dtype=types),\n",
    "                            nn.Linear(self.dim,self.dim+10,bias=False),\n",
    "                            nn.BatchNorm1d(self.dim+10, eps=1e-06, momentum=0.99,affine=False,dtype=types),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(self.dim+10,self.dim+10,bias=False),\n",
    "                            nn.BatchNorm1d(self.dim+10, eps=1e-06, momentum=0.99,affine=False,dtype=types),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(self.dim+10,self.dim,bias=False),\n",
    "                            nn.BatchNorm1d(self.dim, eps=1e-06, momentum=0.99,affine=False,dtype=types)\n",
    "                            )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)    \n",
    "    \n",
    "class BSDESolver(object):\n",
    "    \"\"\"The fully connected neural network model.\"\"\"\n",
    "    def __init__(self,eqn, net_config):\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "\n",
    "        #self.model = torch.compile(GlobalModel(net_config, eqn), mode=\"max-autotune\")\n",
    "        self.model = GlobalModel(net_config, eqn)\n",
    "        self.y_0 = self.model.y_0\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        #lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "            #self.net_config.lr_boundaries, self.net_config.lr_values)\n",
    "        #self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, epsilon=1e-8)\n",
    "\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        training_history = []\n",
    "        valid_data = self.eqn.sample(256)\n",
    "\n",
    "        # begin sgd iteration\n",
    "        for step in range(2001):\n",
    "            #print(step)\n",
    "            inputs=self.eqn.sample(64)\n",
    "            results=self.model(inputs)\n",
    "            loss=self.loss_fn(inputs,results)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if step % 200==0:\n",
    "                loss = self.loss_fn(valid_data, self.model(valid_data)).detach().numpy()\n",
    "                y_init = self.y_0.detach().numpy()[0]\n",
    "                elapsed_time = time.time() - start_time\n",
    "                training_history.append([step, loss, y_init, elapsed_time])\n",
    "                print(\"Epoch \",step, \" y_0 \",y_init,\" time \", elapsed_time,\" loss \", loss)\n",
    "\n",
    "        return np.array(training_history)\n",
    "\n",
    "    def loss_fn(self, inputs,results):\n",
    "        DELTA_CLIP = 50.0\n",
    "        dw, x = inputs\n",
    "        y_terminal = self.model(inputs)\n",
    "        delta = results - self.eqn.g_tf(self.eqn.total_time, x[:, :, -1])\n",
    "        # use linear approximation outside the clipped range\n",
    "        loss = torch.mean(torch.where(torch.abs(delta) < DELTA_CLIP, torch.square(delta),\n",
    "                                       2 * DELTA_CLIP * torch.abs(delta) - DELTA_CLIP ** 2))\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9042e760-b125-4b99-87b3-78c7a3562364",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqn=HJBEquation({\"dim\":100,\"total_time\":1.0,\"Ndis\":20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f1fa028-548a-442e-abf9-5d3909488d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-0.13107446,  0.02267763, -0.03232467, ..., -0.00603461,\n",
       "           0.05157448, -0.05713857],\n",
       "         [ 0.17831186, -0.22858924,  0.03958036, ..., -0.19402191,\n",
       "           0.23676424, -0.01694009],\n",
       "         [-0.28806086, -0.25812933, -0.04439494, ..., -0.41843162,\n",
       "           0.03761025,  0.34126305],\n",
       "         ...,\n",
       "         [-0.09962596,  0.02040972,  0.18814015, ..., -0.19727514,\n",
       "           0.17905706, -0.05603662],\n",
       "         [-0.06603878,  0.04707486,  0.31875176, ..., -0.06467424,\n",
       "          -0.41317003, -0.2223989 ],\n",
       "         [ 0.09717593,  0.00421439, -0.26804713, ...,  0.22567109,\n",
       "           0.12604418,  0.30575494]],\n",
       " \n",
       "        [[-0.00561743, -0.02884686,  0.20773038, ...,  0.12909941,\n",
       "          -0.15114446,  0.16043468],\n",
       "         [-0.13266738, -0.35348947, -0.08268627, ...,  0.18449425,\n",
       "           0.36994297, -0.29058522],\n",
       "         [-0.16980532, -0.21608765, -0.00421219, ...,  0.21589302,\n",
       "           0.27888215,  0.41125244],\n",
       "         ...,\n",
       "         [ 0.25579357, -0.05966359,  0.24576297, ...,  0.07608229,\n",
       "           0.50945432,  0.04063149],\n",
       "         [-0.14346918,  0.34381657,  0.29738513, ...,  0.03724454,\n",
       "           0.26027873,  0.28360236],\n",
       "         [-0.38022719,  0.23771542,  0.30601632, ...,  0.05419318,\n",
       "           0.16824752, -0.52175001]],\n",
       " \n",
       "        [[-0.00629651, -0.33507912, -0.3379428 , ..., -0.21339642,\n",
       "          -0.53966961, -0.35756272],\n",
       "         [ 0.1414459 ,  0.10813756,  0.16839179, ...,  0.18400283,\n",
       "          -0.1758305 ,  0.44351779],\n",
       "         [ 0.10201398,  0.20887344, -0.01124707, ...,  0.31903162,\n",
       "          -0.05345401,  0.23814909],\n",
       "         ...,\n",
       "         [ 0.16785161, -0.42923104, -0.04015975, ...,  0.26852989,\n",
       "          -0.00272073,  0.04962555],\n",
       "         [ 0.15165522,  0.05985723,  0.217122  , ...,  0.09116077,\n",
       "           0.07105176, -0.07688391],\n",
       "         [ 0.00430428,  0.15742779, -0.44884739, ...,  0.03286195,\n",
       "          -0.15220675,  0.24853994]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.14147188,  0.22321014, -0.12469753, ..., -0.12488824,\n",
       "           0.16297486,  0.04381425],\n",
       "         [-0.25890884, -0.1722924 ,  0.18728098, ..., -0.11879431,\n",
       "          -0.30633155,  0.53093213],\n",
       "         [-0.10558453,  0.17282881,  0.55048877, ..., -0.56408072,\n",
       "           0.03335753, -0.0983004 ],\n",
       "         ...,\n",
       "         [-0.11633882,  0.12647042,  0.26918546, ...,  0.23827083,\n",
       "          -0.05322125, -0.05953434],\n",
       "         [-0.20989961,  0.19841625, -0.09010438, ...,  0.34523881,\n",
       "           0.02902282, -0.06406989],\n",
       "         [-0.28203302,  0.356709  ,  0.07943369, ..., -0.06136724,\n",
       "          -0.07729052, -0.20615071]],\n",
       " \n",
       "        [[-0.2604991 , -0.08754534, -0.26662927, ...,  0.32773782,\n",
       "           0.08671589,  0.22200864],\n",
       "         [ 0.33143607,  0.02287233, -0.03864469, ..., -0.19786246,\n",
       "           0.21836878, -0.20321095],\n",
       "         [ 0.2809902 ,  0.02178918,  0.28736975, ..., -0.06259144,\n",
       "           0.46880804,  0.47470787],\n",
       "         ...,\n",
       "         [ 0.08772926,  0.59107364, -0.17027234, ..., -0.31808452,\n",
       "          -0.08933612, -0.44439993],\n",
       "         [-0.14905486,  0.11417984, -0.06909596, ...,  0.04700792,\n",
       "           0.27423891,  0.02027063],\n",
       "         [-0.43584957, -0.18108879,  0.18867017, ...,  0.07466401,\n",
       "          -0.09892248,  0.18363963]],\n",
       " \n",
       "        [[-0.20944018, -0.15858477, -0.11760931, ...,  0.03941284,\n",
       "           0.30493235, -0.45237719],\n",
       "         [-0.00652161, -0.45628951, -0.10830894, ..., -0.2372879 ,\n",
       "          -0.06193608, -0.02253744],\n",
       "         [-0.26129911,  0.50794356,  0.10635138, ...,  0.01533883,\n",
       "           0.30878553,  0.03463543],\n",
       "         ...,\n",
       "         [-0.07556858,  0.05155031,  0.20620463, ...,  0.0819785 ,\n",
       "          -0.13427406, -0.25782741],\n",
       "         [ 0.02735549,  0.26577659,  0.11120823, ..., -0.08460415,\n",
       "           0.07346429,  0.01838494],\n",
       "         [-0.33402002, -0.29418375, -0.35863581, ..., -0.17166222,\n",
       "           0.19091504, -0.03787575]]]),\n",
       " array([[[ 0.        , -0.18536728, -0.15329627, ..., -1.54895291,\n",
       "          -1.47601557, -1.55682172],\n",
       "         [ 0.        ,  0.25217105, -0.07110296, ..., -1.90172975,\n",
       "          -1.56689454, -1.59085144],\n",
       "         [ 0.        , -0.40737958, -0.77242958, ..., -1.51301994,\n",
       "          -1.45983101, -0.97721217],\n",
       "         ...,\n",
       "         [ 0.        , -0.14089238, -0.11202868, ..., -0.4243953 ,\n",
       "          -0.17117038, -0.25041813],\n",
       "         [ 0.        , -0.09339294, -0.02681904, ...,  1.29715317,\n",
       "           0.7128425 ,  0.39832297],\n",
       "         [ 0.        ,  0.13742752,  0.14338757, ..., -1.19961944,\n",
       "          -1.02136605, -0.58896327]],\n",
       " \n",
       "        [[ 0.        , -0.00794425, -0.04873987, ...,  1.66889467,\n",
       "           1.45514412,  1.68203301],\n",
       "         [ 0.        , -0.18762001, -0.68752961, ..., -1.1753289 ,\n",
       "          -0.65215054, -1.06310009],\n",
       "         [ 0.        , -0.24014098, -0.54573506, ..., -1.6122877 ,\n",
       "          -1.21788878, -0.63629   ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.36174674,  0.27736968, ..., -0.6240211 ,\n",
       "           0.0964561 ,  0.1539177 ],\n",
       "         [ 0.        , -0.20289606,  0.28333399, ...,  1.7480198 ,\n",
       "           2.11610951,  2.51718381],\n",
       "         [ 0.        , -0.53772244, -0.20154208, ...,  1.93877946,\n",
       "           2.17671738,  1.43885144]],\n",
       " \n",
       "        [[ 0.        , -0.00890461, -0.48277806, ..., -1.2792846 ,\n",
       "          -2.04249268, -2.54816273],\n",
       "         [ 0.        ,  0.20003471,  0.35296432, ..., -1.60868375,\n",
       "          -1.85734562, -1.23011675],\n",
       "         [ 0.        ,  0.14426956,  0.43966121, ...,  2.47762661,\n",
       "           2.40203123,  2.7388249 ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.23737803, -0.36964633, ..., -0.25059815,\n",
       "          -0.25444584, -0.18426472],\n",
       "         [ 0.        ,  0.21447287,  0.29912377, ..., -0.78790916,\n",
       "          -0.6874268 , -0.79615706],\n",
       "         [ 0.        ,  0.00608718,  0.22872369, ...,  1.11835938,\n",
       "           0.90310652,  1.25459507]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.        , -0.20007146,  0.11559535, ..., -0.83184257,\n",
       "          -0.60136132, -0.53939861],\n",
       "         [ 0.        , -0.36615239, -0.60981064, ..., -1.49407795,\n",
       "          -1.92729618, -1.17644476],\n",
       "         [ 0.        , -0.14931908,  0.09509777, ..., -0.01065186,\n",
       "           0.0365228 , -0.10249495],\n",
       "         ...,\n",
       "         [ 0.        , -0.16452794,  0.01432824, ...,  1.34135165,\n",
       "           1.26608543,  1.18189117],\n",
       "         [ 0.        , -0.29684287, -0.01623993, ...,  0.88423637,\n",
       "           0.92528083,  0.83467232],\n",
       "         [ 0.        , -0.39885492,  0.10560779, ..., -0.78035064,\n",
       "          -0.88965595, -1.18119708]],\n",
       " \n",
       "        [[ 0.        , -0.36840137, -0.49220918, ...,  0.35323834,\n",
       "           0.47587312,  0.78984075],\n",
       "         [ 0.        ,  0.46872138,  0.50106774, ..., -1.08814666,\n",
       "          -0.77932657, -1.06671024],\n",
       "         [ 0.        ,  0.39738015,  0.42819471, ..., -0.44598349,\n",
       "           0.21701121,  0.88834951],\n",
       "         ...,\n",
       "         [ 0.        ,  0.12406791,  0.95997227, ...,  0.98648036,\n",
       "           0.86014001,  0.23166359],\n",
       "         [ 0.        , -0.21079541, -0.04932073, ..., -0.29748306,\n",
       "           0.09034932,  0.11901632],\n",
       "         [ 0.        , -0.61638437, -0.87248259, ...,  0.70478214,\n",
       "           0.56488463,  0.82459029]],\n",
       " \n",
       "        [[ 0.        , -0.29619314, -0.52046587, ..., -0.84870201,\n",
       "          -0.41746254, -1.0572205 ],\n",
       "         [ 0.        , -0.00922295, -0.65451376, ..., -1.4206666 ,\n",
       "          -1.50825743, -1.54013019],\n",
       "         [ 0.        , -0.36953275,  0.34880792, ...,  0.08598956,\n",
       "           0.52267824,  0.57166014],\n",
       "         ...,\n",
       "         [ 0.        , -0.10687011, -0.03396696, ...,  2.42359741,\n",
       "           2.23370521,  1.86908219],\n",
       "         [ 0.        ,  0.0386865 ,  0.41455137, ..., -0.93587379,\n",
       "          -0.83197959, -0.80597936],\n",
       "         [ 0.        , -0.47237564, -0.88841429, ..., -0.26554607,\n",
       "           0.00444856, -0.04911584]]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqn.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f57955c-4aad-45ad-96b9-d15cd0e9b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2, key3 = jax.random.split(jax.random.PRNGKey(0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89c910d1-6d0f-429e-b079-296b14657c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([3186719485, 3840466878], dtype=uint32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccbf62-1bf3-451d-9c75-acb665bf69b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
