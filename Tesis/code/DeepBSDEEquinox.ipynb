{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ffbef5b-f7ae-41c2-8123-84454d67e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc2c51a-9193-4ba2-a7f2-18e4f22d8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Equation(object):\n",
    "    \"\"\"Base class for defining PDE related function.\"\"\"\n",
    "    def __init__(self, eqn_config):\n",
    "        self.dim = eqn_config['dim']\n",
    "        self.total_time = eqn_config['total_time']\n",
    "        self.Ndis = eqn_config['Ndis']\n",
    "        self.delta_t = self.total_time / self.Ndis\n",
    "        self.sqrt_delta_t = jnp.sqrt(self.delta_t)\n",
    "        self.y_init = None\n",
    "\n",
    "    def sample(self, num_sample):\n",
    "        \"\"\"Sample forward SDE.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def f_tf(self, t, x, y, z):\n",
    "        \"\"\"Generator function in the PDE.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def g_tf(self, t, x):\n",
    "        \"\"\"Terminal condition of the PDE.\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe951f59-86fe-402d-80ee-cc5a002b30a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HJBLQ(Equation):\n",
    "    \"\"\"HJB equation in PNAS paper doi.org/10.1073/pnas.1718942115\"\"\"\n",
    "    def __init__(self, eqn_config):\n",
    "        super(HJBLQ, self).__init__(eqn_config)\n",
    "        self.x_init = jnp.zeros(self.dim)\n",
    "        self.sigma = jnp.sqrt(2.0)\n",
    "        self.lambd = 1.0\n",
    "\n",
    "    def sample(self, num_sample):\n",
    "        key = jax.random.PRNGKey(23)\n",
    "        dw_sample = jax.random.normal(key,shape=[num_sample, self.dim, self.Ndis]) * self.sqrt_delta_t\n",
    "        x_sample = jnp.zeros([num_sample, self.dim, self.Ndis + 1])\n",
    "        x_sample.at[:, :, 0].set(jnp.ones([num_sample, self.dim]) * self.x_init)\n",
    "        for i in range(self.Ndis):\n",
    "            x_sample=x_sample.at[:, :, i + 1].set(x_sample[:, :, i] + self.sigma * dw_sample[:, :, i])\n",
    "        return dw_sample, x_sample\n",
    "\n",
    "    def f_tf(self, t, x, y, z):\n",
    "        return -self.lambd * jnp.sum(z**2) / 2\n",
    "\n",
    "    def g_tf(self, t, x):\n",
    "        return jnp.log((1 + jnp.sum(x**2) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3217e7-e65b-49cd-a4b9-d39f0c5af89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardSubNet(eqx.Module):\n",
    "    layers:  list\n",
    "    \n",
    "    def __init__(self, key,eqn_config,config_subnet):\n",
    "        dim = eqn_config[\"dim\"]\n",
    "        num_hiddens = config_subnet.num_hiddens\n",
    "        self.layers = [\n",
    "            eqx.experimental.BatchNorm(input_size=4, axis_name=\"batch\",momentum=0.99,eps=1e-6)\n",
    "            \n",
    "            \n",
    "        ]\n",
    "        self.bn_layers = [\n",
    "            tf.keras.layers.BatchNormalization(\n",
    "                momentum=0.99,\n",
    "                epsilon=1e-6,\n",
    "                beta_initializer=tf.random_normal_initializer(0.0, stddev=0.1),\n",
    "                gamma_initializer=tf.random_uniform_initializer(0.1, 0.5)\n",
    "            )\n",
    "            for _ in range(len(num_hiddens) + 2)]\n",
    "        self.dense_layers = [tf.keras.layers.Dense(num_hiddens[i],\n",
    "                                                   use_bias=False,\n",
    "                                                   activation=None)\n",
    "                             for i in range(len(num_hiddens))]\n",
    "        # final output should be gradient of size dim\n",
    "        self.dense_layers.append(tf.keras.layers.Dense(dim, activation=None))\n",
    "\n",
    "    def call(self, x, training):\n",
    "        \"\"\"structure: bn -> (dense -> bn -> relu) * len(num_hiddens) -> dense -> bn\"\"\"\n",
    "        x = self.bn_layers[0](x, training)\n",
    "        for i in range(len(self.dense_layers) - 1):\n",
    "            x = self.dense_layers[i](x)\n",
    "            x = self.bn_layers[i+1](x, training)\n",
    "            x = tf.nn.relu(x)\n",
    "        x = self.dense_layers[-1](x)\n",
    "        x = self.bn_layers[-1](x, training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9042e760-b125-4b99-87b3-78c7a3562364",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqn_config={\"dim\":1,\"total_time\":1.0,\"Ndis\":20}\n",
    "eqn=HJBLQ(eqn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f57955c-4aad-45ad-96b9-d15cd0e9b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2, key3 = jax.random.split(jax.random.PRNGKey(0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89c910d1-6d0f-429e-b079-296b14657c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([3186719485, 3840466878], dtype=uint32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccbf62-1bf3-451d-9c75-acb665bf69b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
