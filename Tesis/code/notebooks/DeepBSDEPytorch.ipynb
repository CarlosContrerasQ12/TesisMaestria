{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76dc506a-f19e-4861-ad23-e8e117b85ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "types=torch.float32\n",
    "torch.set_default_dtype(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729f6242-129d-483d-ba14-d253e319ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HJBEquation():\n",
    "    \"\"\"HJB equation in PNAS paper doi.org/10.1073/pnas.1718942115\"\"\"\n",
    "    def __init__(self, eqn_config):\n",
    "        self.dim=eqn_config[\"dim\"]\n",
    "        self.total_time=eqn_config[\"total_time\"]\n",
    "        self.Ndis=eqn_config[\"Ndis\"]\n",
    "        self.delta_t=self.total_time/self.Ndis\n",
    "        self.sqrt_delta_t = np.sqrt(self.delta_t)\n",
    "        self.x_init = torch.zeros(self.dim,requires_grad=False)\n",
    "        self.sigma = np.sqrt(2.0)\n",
    "        self.lambd = 1.0\n",
    "\n",
    "    def sample(self, num_sample):\n",
    "        dw_sample =torch.tensor( np.random.normal(size=[num_sample, self.dim, self.Ndis]) * self.sqrt_delta_t,requires_grad=False)\n",
    "        x_sample = torch.zeros([num_sample, self.dim, self.Ndis + 1],requires_grad=False)\n",
    "        x_sample[:, :, 0] = torch.ones([num_sample, self.dim]) * self.x_init\n",
    "        for i in range(self.Ndis):\n",
    "            x_sample[:, :, i + 1] = x_sample[:, :, i] + self.sigma * dw_sample[:, :, i]\n",
    "        return dw_sample, x_sample\n",
    "\n",
    "    def f_tf(self, t, x, y, z):\n",
    "        return -self.lambd * torch.sum(torch.square(z), 1, keepdims=True) / 2\n",
    "\n",
    "    def g_tf(self, x):\n",
    "        return torch.log((1 + torch.sum(torch.square(x), 1, keepdims=True)) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d1f85b-f4a0-4b10-88d3-f3a2843ec3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalModelDeepBSDE(nn.Module):\n",
    "    def __init__(self, net_config, eqn):\n",
    "        super(GlobalModelDeepBSDE, self).__init__()\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "        self.y_0=nn.Parameter(torch.rand(1))\n",
    "        self.z_0=nn.Parameter((torch.rand((1,self.eqn.dim))*0.2)-0.1)\n",
    "        self.subnet = [FF_subnet_DBSDE(self.eqn,net_config) for _ in range(self.eqn.Ndis-1)]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        dw, x = inputs\n",
    "        time_stamp = np.arange(0, self.eqn.Ndis) * self.eqn.delta_t\n",
    "        all_one_vec = torch.ones((dw.shape[0], 1))\n",
    "        y = all_one_vec * self.y_0\n",
    "        z = torch.matmul(all_one_vec, self.z_0)\n",
    "\n",
    "        for t in range(0, self.eqn.Ndis-1):\n",
    "            y = y - self.eqn.delta_t * (\n",
    "                self.eqn.f_tf(time_stamp[t], x[:, :, t], y, z)\n",
    "            ) + torch.sum(z * dw[:, :, t], 1, keepdims=True)\n",
    "            z = self.subnet[t](x[:, :, t + 1]) / self.eqn.dim\n",
    "        # terminal time\n",
    "        y = y - self.eqn.delta_t * self.eqn.f_tf(time_stamp[-1], x[:, :, -2], y, z) + \\\n",
    "            torch.sum(z * dw[:, :, -1], 1, keepdims=True)\n",
    "        return y\n",
    "\n",
    "\n",
    "class FF_subnet_DBSDE(nn.Module):\n",
    "    def __init__(self, eqn,net_config):\n",
    "        super(FF_subnet_DBSDE, self).__init__()\n",
    "        self.dim = eqn.dim\n",
    "        self.num_hiddens = net_config[\"num_hiddens\"]\n",
    "        self.net=nn.Sequential(\n",
    "                            nn.BatchNorm1d(self.dim, eps=1e-06, momentum=0.99,affine=False,dtype=types),\n",
    "                            nn.Linear(self.dim,self.dim+10,bias=False),\n",
    "                            nn.BatchNorm1d(self.dim+10, eps=1e-06, momentum=0.99,affine=False,dtype=types),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(self.dim+10,self.dim+10,bias=False),\n",
    "                            nn.BatchNorm1d(self.dim+10, eps=1e-06, momentum=0.99,affine=False,dtype=types),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(self.dim+10,self.dim,bias=False),\n",
    "                            nn.BatchNorm1d(self.dim, eps=1e-06, momentum=0.99,affine=False,dtype=types)\n",
    "                            )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class BSDESolver(object):\n",
    "    \"\"\"The fully connected neural network model.\"\"\"\n",
    "    def __init__(self,eqn, net_config):\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "\n",
    "        #self.model = torch.compile(GlobalModel(net_config, eqn), mode=\"max-autotune\")\n",
    "        self.model = GlobalModelDeepBSDE(net_config, eqn)\n",
    "        self.y_0 = self.model.y_0\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        #lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "            #self.net_config.lr_boundaries, self.net_config.lr_values)\n",
    "        #self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, epsilon=1e-8)\n",
    "\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        training_history = []\n",
    "        valid_data = self.eqn.sample(256)\n",
    "\n",
    "        # begin sgd iteration\n",
    "        for step in range(2001):\n",
    "            #print(step)\n",
    "            inputs=self.eqn.sample(64)\n",
    "            results=self.model(inputs)\n",
    "            loss=self.loss_fn(inputs,results)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if step % 200==0:\n",
    "                loss = self.loss_fn(valid_data, self.model(valid_data)).detach().numpy()\n",
    "                y_init = self.y_0.detach().numpy()[0]\n",
    "                elapsed_time = time.time() - start_time\n",
    "                training_history.append([step, loss, y_init, elapsed_time])\n",
    "                print(\"Epoch \",step, \" y_0 \",y_init,\" time \", elapsed_time,\" loss \", loss)\n",
    "\n",
    "        return np.array(training_history)\n",
    "\n",
    "    def loss_fn(self, inputs,results):\n",
    "        DELTA_CLIP = 50.0\n",
    "        dw, x = inputs\n",
    "        y_terminal = self.model(inputs)\n",
    "        delta = results - self.eqn.g_tf(x[:, :, -1])\n",
    "        # use linear approximation outside the clipped range\n",
    "        loss = torch.mean(torch.where(torch.abs(delta) < DELTA_CLIP, torch.square(delta),\n",
    "                                       2 * DELTA_CLIP * torch.abs(delta) - DELTA_CLIP ** 2))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440fc0b5-8277-44b7-880a-2b31b136dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalModelMergedDeepBSDE(nn.Module):\n",
    "    def __init__(self, net_config, eqn):\n",
    "        super(GlobalModelMergedDeepBSDE, self).__init__()\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "        self.dim=eqn.dim\n",
    "        self.model=FF_subnet_Merged_DBSDE(self.eqn,net_config)\n",
    "        self.y_0=nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        dw, x = inputs\n",
    "        time_stamp = np.arange(0, self.eqn.Ndis) * self.eqn.delta_t\n",
    "        all_one_vec = torch.ones((dw.shape[0], 1))\n",
    "        y = all_one_vec * self.y_0\n",
    "        #z = torch.matmul(all_one_vec, self.z_0)\n",
    "\n",
    "        for t in range(0, self.eqn.Ndis):\n",
    "            inp=torch.hstack((time_stamp[t]*all_one_vec,x[:,:,t]))\n",
    "            z = self.model(inp) / self.eqn.dim\n",
    "            y = y - self.eqn.delta_t * (\n",
    "                self.eqn.f_tf(time_stamp[t], x[:, :, t], y, z)\n",
    "            ) + torch.sum(z * dw[:, :, t], 1, keepdims=True)\n",
    "            \n",
    "        return y\n",
    "\n",
    "class FF_subnet_Merged_DBSDE(nn.Module):\n",
    "    def __init__(self, eqn,net_config):\n",
    "        super(FF_subnet_Merged_DBSDE, self).__init__()\n",
    "        self.dim = eqn.dim\n",
    "        self.net = nn.Sequential(\n",
    "                            nn.Linear(self.dim+1,2*self.dim,bias=False),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,2*self.dim,bias=False),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,2*self.dim,bias=False),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,self.dim,bias=False)\n",
    "                            )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Merged_BSDE_Solver(object):\n",
    "    \"\"\"The fully connected neural network model.\"\"\"\n",
    "    def __init__(self,eqn, net_config):\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "\n",
    "        #self.model = torch.compile(GlobalModel(net_config, eqn), mode=\"max-autotune\")\n",
    "        self.model = GlobalModelMergedDeepBSDE(net_config, eqn)\n",
    "        self.y_0 = self.model.y_0\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        #lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "            #self.net_config.lr_boundaries, self.net_config.lr_values)\n",
    "        #self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, epsilon=1e-8)\n",
    "\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        training_history = []\n",
    "        valid_data = self.eqn.sample(256)\n",
    "\n",
    "        # begin sgd iteration\n",
    "        for step in range(2001):\n",
    "            #print(step)\n",
    "            inputs=self.eqn.sample(64)\n",
    "            results=self.model(inputs)\n",
    "            loss=self.loss_fn(inputs,results)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if step % 200==0:\n",
    "                loss = self.loss_fn(valid_data, self.model(valid_data)).detach().numpy()\n",
    "                y_init = self.y_0.detach().numpy()[0]\n",
    "                elapsed_time = time.time() - start_time\n",
    "                training_history.append([step, loss, y_init, elapsed_time])\n",
    "                print(\"Epoch \",step, \" y_0 \",y_init,\" time \", elapsed_time,\" loss \", loss)\n",
    "\n",
    "        return np.array(training_history)\n",
    "\n",
    "    def loss_fn(self, inputs,results):\n",
    "        DELTA_CLIP = 50.0\n",
    "        dw, x = inputs\n",
    "        y_terminal = self.model(inputs)\n",
    "        delta = results - self.eqn.g_tf(x[:, :, -1])\n",
    "        # use linear approximation outside the clipped range\n",
    "        loss = torch.mean(torch.where(torch.abs(delta) < DELTA_CLIP, torch.square(delta),\n",
    "                                       2 * DELTA_CLIP * torch.abs(delta) - DELTA_CLIP ** 2))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb3ea8e-cf87-4f12-9fa5-c5adaf45eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalModelMergedResidualDeepBSDE(nn.Module):\n",
    "    def __init__(self, net_config, eqn):\n",
    "        super(GlobalModelMergedResidualDeepBSDE, self).__init__()\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "        self.dim=eqn.dim\n",
    "        self.model=FF_subnet_Merged_Residual_DBSDE(self.eqn,net_config)\n",
    "        self.y_0=nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        dw, x = inputs\n",
    "        time_stamp = np.arange(0, self.eqn.Ndis) * self.eqn.delta_t\n",
    "        all_one_vec = torch.ones((dw.shape[0], 1))\n",
    "        y = all_one_vec * self.y_0\n",
    "        #z = torch.matmul(all_one_vec, self.z_0)\n",
    "\n",
    "        for t in range(0, self.eqn.Ndis):\n",
    "            inp=torch.hstack((time_stamp[t]*all_one_vec,y,self.eqn.g_tf(x[:,:,t]),x[:,:,t]))\n",
    "            z = self.model(inp) / self.eqn.dim\n",
    "            y = y - self.eqn.delta_t * (\n",
    "                self.eqn.f_tf(time_stamp[t], x[:, :, t], y, z)\n",
    "            ) + torch.sum(z * dw[:, :, t], 1, keepdims=True)\n",
    "            \n",
    "        return y\n",
    "\n",
    "class FF_subnet_Merged_Residual_DBSDE(nn.Module):\n",
    "    def __init__(self, eqn,net_config):\n",
    "        super(FF_subnet_Merged_Residual_DBSDE, self).__init__()\n",
    "        self.dim = eqn.dim\n",
    "        self.l1=nn.Linear(self.dim+1+1+1,2*self.dim,bias=False)\n",
    "        self.l2=nn.Linear(2*self.dim,2*self.dim,bias=False)\n",
    "        self.l3=nn.Linear(2*self.dim,2*self.dim,bias=False)\n",
    "        self.l4=nn.Linear(2*self.dim,self.dim,bias=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out1=F.ELU(self.l1(x))\n",
    "        out2=F.ELU(self.l3(F.ELU(self.l2(out1))))\n",
    "        return self.l4(out1+out2)\n",
    "    \n",
    "class Merged_Residual_BSDE_Solver(object):\n",
    "    \"\"\"The fully connected neural network model.\"\"\"\n",
    "    def __init__(self,eqn, net_config):\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "\n",
    "        #self.model = torch.compile(GlobalModel(net_config, eqn), mode=\"max-autotune\")\n",
    "        self.model = GlobalModelMergedDeepBSDE(net_config, eqn)\n",
    "        self.y_0 = self.model.y_0\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        #lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "            #self.net_config.lr_boundaries, self.net_config.lr_values)\n",
    "        #self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, epsilon=1e-8)\n",
    "\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        training_history = []\n",
    "        valid_data = self.eqn.sample(256)\n",
    "\n",
    "        # begin sgd iteration\n",
    "        for step in range(2001):\n",
    "            #print(step)\n",
    "            inputs=self.eqn.sample(64)\n",
    "            results=self.model(inputs)\n",
    "            loss=self.loss_fn(inputs,results)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if step % 200==0:\n",
    "                loss = self.loss_fn(valid_data, self.model(valid_data)).detach().numpy()\n",
    "                y_init = self.y_0.detach().numpy()[0]\n",
    "                elapsed_time = time.time() - start_time\n",
    "                training_history.append([step, loss, y_init, elapsed_time])\n",
    "                print(\"Epoch \",step, \" y_0 \",y_init,\" time \", elapsed_time,\" loss \", loss)\n",
    "\n",
    "        return np.array(training_history)\n",
    "\n",
    "    def loss_fn(self, inputs,results):\n",
    "        DELTA_CLIP = 50.0\n",
    "        dw, x = inputs\n",
    "        y_terminal = self.model(inputs)\n",
    "        delta = results - self.eqn.g_tf(x[:, :, -1])\n",
    "        # use linear approximation outside the clipped range\n",
    "        loss = torch.mean(torch.where(torch.abs(delta) < DELTA_CLIP, torch.square(delta),\n",
    "                                       2 * DELTA_CLIP * torch.abs(delta) - DELTA_CLIP ** 2))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc58b08-b0be-4d2d-b556-b0361fe7e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FF_subnet_DenseNet_BSDE(nn.Module):\n",
    "    def __init__(self, eqn,net_config):\n",
    "        super(FF_subnet_Merged_Residual_DBSDE, self).__init__()\n",
    "        self.dim = eqn.dim\n",
    "        self.l1=nn.Linear(self.dim,self.dim+20,bias=False)\n",
    "        self.l2=nn.Linear(2*self.dim+20,self.dim,bias=False)\n",
    "        self.l3=nn.Linear(2*self.dim,self.dim,bias=False)\n",
    "        self.l4=nn.Linear(2*self.dim,1,bias=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        y2=F.relu(self.l1(x))\n",
    "        x2=torch.hstack((x,y2))\n",
    "        y3=F.relu(self.l2(x2))\n",
    "        x3=torch.hstack((x2,y3))\n",
    "        y4=F.relu(self.l3(x3))\n",
    "        x4=torch.hstack((x3,y4))\n",
    "        return self.l4(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855a146a-74c9-453d-bbf0-384c0cd0aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FF_net_Raissi(nn.Module):\n",
    "    def __init__(self, eqn,net_config):\n",
    "        super(FF_net_Raissi, self).__init__()\n",
    "        self.dim = eqn.dim\n",
    "        self.net = nn.Sequential(\n",
    "                            nn.Linear(self.dim+1,2*self.dim,bias=True),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,2*self.dim,bias=True),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,2*self.dim,bias=True),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,2*self.dim,bias=True),\n",
    "                            nn.ELU(),\n",
    "                            nn.Linear(2*self.dim,1,bias=True),\n",
    "                            )\n",
    "    def forward(self,tx):\n",
    "        return self.net(tx)\n",
    "        #return self.net(torch.hstack((t*torch.ones((x.shape[0], 1)),x)))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class Raissi_BSDE_Solver(object):\n",
    "    \"\"\"The fully connected neural network model.\"\"\"\n",
    "    def __init__(self,eqn, net_config):\n",
    "        self.net_config = net_config\n",
    "        self.eqn = eqn\n",
    "\n",
    "        #self.model = torch.compile(GlobalModel(net_config, eqn), mode=\"max-autotune\")\n",
    "        self.net = FF_net_Raissi(eqn,net_config)\n",
    "        #self.y_0 = nn.Parameter(torch.rand(1))\n",
    "        self.times=np.arange(0, self.eqn.Ndis+1) * self.eqn.delta_t\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=0.01)\n",
    "\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        training_history = []\n",
    "        valid_data = self.eqn.sample(256)\n",
    "        dw, x =valid_data\n",
    "\n",
    "        # begin sgd iteration\n",
    "        for step in range(2001):\n",
    "            #print(step)\n",
    "            inputs=self.eqn.sample(64)\n",
    "            #results=self.model(inputs)\n",
    "            loss=self.loss_total(inputs)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if step % 200==0:\n",
    "                loss = self.loss_total(valid_data).detach().numpy()\n",
    "                tx=torch.hstack((self.times[0]*torch.ones((x.shape[0], 1)),x[:,:,0]))\n",
    "                y_init = self.net(tx).detach().numpy()[0][0]\n",
    "                elapsed_time = time.time() - start_time\n",
    "                training_history.append([step, loss, y_init, elapsed_time])\n",
    "                print(\"Epoch \",step, \" y_0 \",y_init,\" time \", elapsed_time,\" loss \", loss)\n",
    "\n",
    "        return np.array(training_history)\n",
    "    def Dg_tf(self,X): # M x D\n",
    "        Gt=self.eqn.g_tf(X)\n",
    "        return torch.autograd.grad(Gt, X, create_graph=True,grad_outputs=torch.ones_like(Gt),allow_unused=True)[0]\n",
    "    \n",
    "    def loss_total(self, inputs):\n",
    "        loss=0.0\n",
    "        dw, x = inputs\n",
    "        tx=torch.hstack((self.times[0]*torch.ones((x.shape[0], 1)),x[:,:,0]))\n",
    "        tx.requires_grad_()\n",
    "        Y0=self.net(tx)\n",
    "        Z0 = torch.autograd.grad(Y0, tx, create_graph=True,grad_outputs=torch.ones_like(Y0),allow_unused=True)[0][:,1:]\n",
    "        \n",
    "        for t in range(self.eqn.Ndis):\n",
    "            Y1_tilde = Y0 + self.eqn.f_tf(self.times[t],x[:,:,0],Y0,Z0)*self.eqn.delta_t + torch.sum(Z0 * dw[:, :, t], 1, keepdims=True)\n",
    "            tx=torch.hstack((self.times[t+1]*torch.ones((x.shape[0], 1)),x[:,:,t+1]))\n",
    "            tx.requires_grad_()\n",
    "            Y1=self.net(tx)\n",
    "            Z1=torch.autograd.grad(Y1, tx, create_graph=True,grad_outputs=torch.ones_like(Y1),allow_unused=True)[0][:,1:]\n",
    "            loss+=torch.sum(torch.square(Y1_tilde-Y1))\n",
    "            Y0=Y1\n",
    "            Z0=Z1\n",
    "        \n",
    "        loss += torch.sum(torch.square(Y1 - self.eqn.g_tf(x[:,:,-1])))\n",
    "        x.requires_grad_()\n",
    "        loss += torch.sum(torch.square(Z1 - self.Dg_tf(x[:,:,-1])))\n",
    "        return loss\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f62faf-b354-446a-b516-51122b44b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqn=HJBEquation({\"dim\":100,\"total_time\":1.0,\"Ndis\":20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ceeb72-7398-4f6b-830e-b7337d14e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsde_solver = BSDESolver(eqn,{\"num_hiddens\":2,\"dtype\":'float64'})\n",
    "merged_bsde_solver = Merged_BSDE_Solver(eqn,{\"num_hiddens\":2,\"dtype\":'float64'})\n",
    "merged_residual_bsde_solver = Merged_Residual_BSDE_Solver(eqn,{\"num_hiddens\":2,\"dtype\":'float64'})\n",
    "raissi_bsde_solver=Raissi_BSDE_Solver(eqn,{\"num_hiddens\":2,\"dtype\":'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98f3c89d-c5ac-47d8-ac35-e943c1bca050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  y_0  0.38692307  time  0.09283852577209473  loss  17.6296045420346\n",
      "Epoch  200  y_0  2.0784166  time  4.934387683868408  loss  3.9479276851932985\n",
      "Epoch  400  y_0  2.88576  time  9.793327331542969  loss  2.0068472878605927\n",
      "Epoch  600  y_0  3.5896077  time  14.63205337524414  loss  0.9711366747533632\n",
      "Epoch  800  y_0  4.198273  time  19.45731210708618  loss  0.23364227338426266\n",
      "Epoch  1000  y_0  4.502965  time  24.28793954849243  loss  0.04261526331890004\n",
      "Epoch  1200  y_0  4.5827975  time  29.12455654144287  loss  0.03163510447388217\n",
      "Epoch  1400  y_0  4.5947804  time  33.97587180137634  loss  0.03160657193441353\n",
      "Epoch  1600  y_0  4.5963  time  38.83889031410217  loss  0.031927983016275176\n",
      "Epoch  1800  y_0  4.594609  time  43.664732456207275  loss  0.03179026073366001\n",
      "Epoch  2000  y_0  4.5957284  time  48.55494570732117  loss  0.030988513138864682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.76296045e+01, 3.86923075e-01, 9.28385258e-02],\n",
       "       [2.00000000e+02, 3.94792769e+00, 2.07841659e+00, 4.93438768e+00],\n",
       "       [4.00000000e+02, 2.00684729e+00, 2.88576007e+00, 9.79332733e+00],\n",
       "       [6.00000000e+02, 9.71136675e-01, 3.58960772e+00, 1.46320534e+01],\n",
       "       [8.00000000e+02, 2.33642273e-01, 4.19827318e+00, 1.94573121e+01],\n",
       "       [1.00000000e+03, 4.26152633e-02, 4.50296497e+00, 2.42879395e+01],\n",
       "       [1.20000000e+03, 3.16351045e-02, 4.58279753e+00, 2.91245565e+01],\n",
       "       [1.40000000e+03, 3.16065719e-02, 4.59478045e+00, 3.39758718e+01],\n",
       "       [1.60000000e+03, 3.19279830e-02, 4.59630013e+00, 3.88388903e+01],\n",
       "       [1.80000000e+03, 3.17902607e-02, 4.59460878e+00, 4.36647325e+01],\n",
       "       [2.00000000e+03, 3.09885131e-02, 4.59572840e+00, 4.85549457e+01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsde_solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef0bf70-4ac2-4ab0-b75e-1ae3de567170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  y_0  0.7678617  time  0.10190987586975098  loss  14.800367954367239\n",
      "Epoch  200  y_0  1.7751629  time  4.937001943588257  loss  3.072468239566029\n",
      "Epoch  400  y_0  2.6254697  time  9.718029499053955  loss  1.4265072958530047\n",
      "Epoch  600  y_0  3.6082768  time  14.433924913406372  loss  0.9759215394144511\n",
      "Epoch  800  y_0  4.4713254  time  19.25156307220459  loss  0.04651214364877901\n",
      "Epoch  1000  y_0  4.6000304  time  23.997984647750854  loss  0.0207139657017685\n",
      "Epoch  1200  y_0  4.598907  time  28.747323513031006  loss  0.02157977348341072\n",
      "Epoch  1400  y_0  4.601288  time  33.48168683052063  loss  0.020587065153183225\n",
      "Epoch  1600  y_0  4.6000586  time  38.23451256752014  loss  0.019999116820022256\n",
      "Epoch  1800  y_0  4.595997  time  42.979350090026855  loss  0.01992012546604236\n",
      "Epoch  2000  y_0  4.598587  time  47.728952169418335  loss  0.020817297450629654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.48003680e+01, 7.67861724e-01, 1.01909876e-01],\n",
       "       [2.00000000e+02, 3.07246824e+00, 1.77516294e+00, 4.93700194e+00],\n",
       "       [4.00000000e+02, 1.42650730e+00, 2.62546968e+00, 9.71802950e+00],\n",
       "       [6.00000000e+02, 9.75921539e-01, 3.60827684e+00, 1.44339249e+01],\n",
       "       [8.00000000e+02, 4.65121436e-02, 4.47132540e+00, 1.92515631e+01],\n",
       "       [1.00000000e+03, 2.07139657e-02, 4.60003042e+00, 2.39979846e+01],\n",
       "       [1.20000000e+03, 2.15797735e-02, 4.59890699e+00, 2.87473235e+01],\n",
       "       [1.40000000e+03, 2.05870652e-02, 4.60128784e+00, 3.34816868e+01],\n",
       "       [1.60000000e+03, 1.99991168e-02, 4.60005856e+00, 3.82345126e+01],\n",
       "       [1.80000000e+03, 1.99201255e-02, 4.59599686e+00, 4.29793501e+01],\n",
       "       [2.00000000e+03, 2.08172975e-02, 4.59858704e+00, 4.77289522e+01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_bsde_solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440362-3340-4b99-bed4-d89fd840c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  y_0  0.71274763  time  0.12448453903198242  loss  3307.733676285858\n",
      "Epoch  200  y_0  4.517213  time  8.27889084815979  loss  10.49734853331923\n",
      "Epoch  400  y_0  4.491789  time  16.60650324821472  loss  10.174380070709734\n",
      "Epoch  600  y_0  4.5488873  time  24.91992950439453  loss  10.502842291889444\n",
      "Epoch  800  y_0  4.463564  time  33.19879460334778  loss  9.140609841890804\n",
      "Epoch  1000  y_0  4.4624968  time  41.50823616981506  loss  8.771660674796836\n",
      "Epoch  1200  y_0  4.483387  time  49.781808376312256  loss  8.059260242680217\n",
      "Epoch  1400  y_0  4.573529  time  58.0403196811676  loss  9.151293541494878\n",
      "Epoch  1600  y_0  4.474177  time  66.32269954681396  loss  7.8776581443452605\n",
      "Epoch  1800  y_0  4.514343  time  74.58523607254028  loss  6.945754072302962\n",
      "Epoch  2000  y_0  4.4668703  time  82.96582818031311  loss  6.355837613860909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 3.30773368e+03, 7.12747633e-01, 1.24484539e-01],\n",
       "       [2.00000000e+02, 1.04973485e+01, 4.51721287e+00, 8.27889085e+00],\n",
       "       [4.00000000e+02, 1.01743801e+01, 4.49178886e+00, 1.66065032e+01],\n",
       "       [6.00000000e+02, 1.05028423e+01, 4.54888725e+00, 2.49199295e+01],\n",
       "       [8.00000000e+02, 9.14060984e+00, 4.46356392e+00, 3.31987946e+01],\n",
       "       [1.00000000e+03, 8.77166067e+00, 4.46249676e+00, 4.15082362e+01],\n",
       "       [1.20000000e+03, 8.05926024e+00, 4.48338699e+00, 4.97818084e+01],\n",
       "       [1.40000000e+03, 9.15129354e+00, 4.57352877e+00, 5.80403197e+01],\n",
       "       [1.60000000e+03, 7.87765814e+00, 4.47417688e+00, 6.63226995e+01],\n",
       "       [1.80000000e+03, 6.94575407e+00, 4.51434278e+00, 7.45852361e+01],\n",
       "       [2.00000000e+03, 6.35583761e+00, 4.46687031e+00, 8.29658282e+01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raissi_bsde_solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac6ec1c8-a32b-4469-9bcd-8d3bf2881061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  y_0  0.97598165  time  0.10168290138244629  loss  13.162296418591458\n",
      "Epoch  200  y_0  1.9735289  time  5.021441698074341  loss  3.1716427480950564\n",
      "Epoch  400  y_0  2.8692765  time  9.858968496322632  loss  1.5456351927991623\n",
      "Epoch  600  y_0  3.8270943  time  14.847797870635986  loss  0.47027912564070457\n",
      "Epoch  800  y_0  4.544493  time  19.682626724243164  loss  0.02609388216400159\n",
      "Epoch  1000  y_0  4.599294  time  24.50575304031372  loss  0.020081667465717507\n",
      "Epoch  1200  y_0  4.59985  time  29.317641496658325  loss  0.019959196827357393\n",
      "Epoch  1400  y_0  4.599803  time  34.13115668296814  loss  0.019768003305034847\n",
      "Epoch  1600  y_0  4.602144  time  38.947619915008545  loss  0.019978553125954184\n",
      "Epoch  1800  y_0  4.5970664  time  43.76622200012207  loss  0.022010927543323677\n",
      "Epoch  2000  y_0  4.5960317  time  48.58127045631409  loss  0.020750965863285058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.31622964e+01, 9.75981653e-01, 1.01682901e-01],\n",
       "       [2.00000000e+02, 3.17164275e+00, 1.97352886e+00, 5.02144170e+00],\n",
       "       [4.00000000e+02, 1.54563519e+00, 2.86927652e+00, 9.85896850e+00],\n",
       "       [6.00000000e+02, 4.70279126e-01, 3.82709432e+00, 1.48477979e+01],\n",
       "       [8.00000000e+02, 2.60938822e-02, 4.54449320e+00, 1.96826267e+01],\n",
       "       [1.00000000e+03, 2.00816675e-02, 4.59929419e+00, 2.45057530e+01],\n",
       "       [1.20000000e+03, 1.99591968e-02, 4.59985018e+00, 2.93176415e+01],\n",
       "       [1.40000000e+03, 1.97680033e-02, 4.59980297e+00, 3.41311567e+01],\n",
       "       [1.60000000e+03, 1.99785531e-02, 4.60214376e+00, 3.89476199e+01],\n",
       "       [1.80000000e+03, 2.20109275e-02, 4.59706640e+00, 4.37662220e+01],\n",
       "       [2.00000000e+03, 2.07509659e-02, 4.59603167e+00, 4.85812705e+01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_residual_bsde_solver.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
