{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f29bac-1c05-4762-a8e9-fa840c3d1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c5e02a-ff06-46f5-8172-ddd84f693088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSDESolver(object):\n",
    "    \"\"\"The fully connected neural network model.\"\"\"\n",
    "    def __init__(self, config, bsde):\n",
    "        self.eqn_config = config.eqn_config\n",
    "        self.net_config = config.net_config\n",
    "        self.bsde = bsde\n",
    "\n",
    "        self.model = NonsharedModel(config, bsde)\n",
    "        self.y_init = self.model.y_init\n",
    "        lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "            self.net_config.lr_boundaries, self.net_config.lr_values)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, epsilon=1e-8)\n",
    "\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        training_history = []\n",
    "        valid_data = self.bsde.sample(self.net_config.valid_size)\n",
    "\n",
    "        # begin sgd iteration\n",
    "        for step in range(self.net_config.num_iterations+1):\n",
    "            if step % self.net_config.logging_frequency == 0:\n",
    "                loss = self.loss_fn(valid_data, training=False).numpy()\n",
    "                y_init = self.y_init.numpy()[0]\n",
    "                elapsed_time = time.time() - start_time\n",
    "                training_history.append([step, loss, y_init, elapsed_time])\n",
    "                if self.net_config.verbose:\n",
    "                    pass\n",
    "                    #logging.info(\"step: %5u,    loss: %.4e, Y0: %.4e,   elapsed time: %3u\" % (step, loss, y_init, elapsed_time))\n",
    "            self.train_step(self.bsde.sample(self.net_config.batch_size))\n",
    "        return np.array(training_history)\n",
    "\n",
    "    def loss_fn(self, inputs, training):\n",
    "        dw, x = inputs\n",
    "        y_terminal = self.model(inputs, training)\n",
    "        delta = y_terminal - self.bsde.g_tf(self.bsde.total_time, x[:, :, -1])\n",
    "        # use linear approximation outside the clipped range\n",
    "        loss = tf.reduce_mean(tf.where(tf.abs(delta) < DELTA_CLIP, tf.square(delta),\n",
    "                                       2 * DELTA_CLIP * tf.abs(delta) - DELTA_CLIP ** 2))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def grad(self, inputs, training):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            loss = self.loss_fn(inputs, training)\n",
    "        grad = tape.gradient(loss, self.model.trainable_variables)\n",
    "        del tape\n",
    "        return grad\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, train_data):\n",
    "        grad = self.grad(train_data, training=True)\n",
    "        self.optimizer.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "\n",
    "\n",
    "class NonsharedModel(tf.keras.Model):\n",
    "    def __init__(self, config, bsde):\n",
    "        super(NonsharedModel, self).__init__()\n",
    "        self.eqn_config = config.eqn_config\n",
    "        self.net_config = config.net_config\n",
    "        self.bsde = bsde\n",
    "        self.y_init = tf.Variable(np.random.uniform(low=self.net_config.y_init_range[0],\n",
    "                                                    high=self.net_config.y_init_range[1],\n",
    "                                                    size=[1])\n",
    "                                  )\n",
    "        self.z_init = tf.Variable(np.random.uniform(low=-.1, high=.1,\n",
    "                                                    size=[1, self.eqn_config.dim])\n",
    "                                  )\n",
    "\n",
    "        self.subnet = [FeedForwardSubNet(config) for _ in range(self.bsde.num_time_interval-1)]\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        dw, x = inputs\n",
    "        time_stamp = np.arange(0, self.eqn_config.num_time_interval) * self.bsde.delta_t\n",
    "        all_one_vec = tf.ones(shape=tf.stack([tf.shape(dw)[0], 1]), dtype=self.net_config.dtype)\n",
    "        y = all_one_vec * self.y_init\n",
    "        z = tf.matmul(all_one_vec, self.z_init)\n",
    "\n",
    "        for t in range(0, self.bsde.num_time_interval-1):\n",
    "            y = y - self.bsde.delta_t * (\n",
    "                self.bsde.f_tf(time_stamp[t], x[:, :, t], y, z)\n",
    "            ) + tf.reduce_sum(z * dw[:, :, t], 1, keepdims=True)\n",
    "            z = self.subnet[t](x[:, :, t + 1], training) / self.bsde.dim\n",
    "        # terminal time\n",
    "        y = y - self.bsde.delta_t * self.bsde.f_tf(time_stamp[-1], x[:, :, -2], y, z) + \\\n",
    "            tf.reduce_sum(z * dw[:, :, -1], 1, keepdims=True)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class FeedForwardSubNet(tf.keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super(FeedForwardSubNet, self).__init__()\n",
    "        dim = config.eqn_config.dim\n",
    "        num_hiddens = config.net_config.num_hiddens\n",
    "        self.bn_layers = [\n",
    "            tf.keras.layers.BatchNormalization(\n",
    "                momentum=0.99,\n",
    "                epsilon=1e-6,\n",
    "                beta_initializer=tf.random_normal_initializer(0.0, stddev=0.1),\n",
    "                gamma_initializer=tf.random_uniform_initializer(0.1, 0.5)\n",
    "            )\n",
    "            for _ in range(len(num_hiddens) + 2)]\n",
    "        self.dense_layers = [tf.keras.layers.Dense(num_hiddens[i],\n",
    "                                                   use_bias=False,\n",
    "                                                   activation=None)\n",
    "                             for i in range(len(num_hiddens))]\n",
    "        # final output should be gradient of size dim\n",
    "        self.dense_layers.append(tf.keras.layers.Dense(dim, activation=None))\n",
    "\n",
    "    def call(self, x, training):\n",
    "        \"\"\"structure: bn -> (dense -> bn -> relu) * len(num_hiddens) -> dense -> bn\"\"\"\n",
    "        x = self.bn_layers[0](x, training)\n",
    "        for i in range(len(self.dense_layers) - 1):\n",
    "            x = self.dense_layers[i](x)\n",
    "            x = self.bn_layers[i+1](x, training)\n",
    "            x = tf.nn.relu(x)\n",
    "        x = self.dense_layers[-1](x)\n",
    "        x = self.bn_layers[-1](x, training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ca95779-15a8-49af-a63a-893c0d74a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Equation(object):\n",
    "    \"\"\"Base class for defining PDE related function.\"\"\"\n",
    "\n",
    "    def __init__(self, eqn_config):\n",
    "        self.dim = eqn_config.dim\n",
    "        self.total_time = eqn_config.total_time\n",
    "        self.num_time_interval = eqn_config.num_time_interval\n",
    "        self.delta_t = self.total_time / self.num_time_interval\n",
    "        self.sqrt_delta_t = np.sqrt(self.delta_t)\n",
    "        self.y_init = None\n",
    "\n",
    "    def sample(self, num_sample):\n",
    "        \"\"\"Sample forward SDE.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def f_tf(self, t, x, y, z):\n",
    "        \"\"\"Generator function in the PDE.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def g_tf(self, t, x):\n",
    "        \"\"\"Terminal condition of the PDE.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class HJBLQ(Equation):\n",
    "    \"\"\"HJB equation in PNAS paper doi.org/10.1073/pnas.1718942115\"\"\"\n",
    "    def __init__(self, eqn_config):\n",
    "        super(HJBLQ, self).__init__(eqn_config)\n",
    "        self.x_init = np.zeros(self.dim)\n",
    "        self.sigma = np.sqrt(2.0)\n",
    "        self.lambd = 1.0\n",
    "\n",
    "    def sample(self, num_sample):\n",
    "        dw_sample = np.random.normal(size=[num_sample, self.dim, self.num_time_interval]) * self.sqrt_delta_t\n",
    "        x_sample = np.zeros([num_sample, self.dim, self.num_time_interval + 1])\n",
    "        x_sample[:, :, 0] = np.ones([num_sample, self.dim]) * self.x_init\n",
    "        for i in range(self.num_time_interval):\n",
    "            x_sample[:, :, i + 1] = x_sample[:, :, i] + self.sigma * dw_sample[:, :, i]\n",
    "        return dw_sample, x_sample\n",
    "\n",
    "    def f_tf(self, t, x, y, z):\n",
    "        return -self.lambd * tf.reduce_sum(tf.square(z), 1, keepdims=True) / 2\n",
    "\n",
    "    def g_tf(self, t, x):\n",
    "        return tf.math.log((1 + tf.reduce_sum(tf.square(x), 1, keepdims=True)) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb3e2699-1585-4bcd-a198-8e8efdf80eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/hjb_lq_d100.json') as json_data_file:\n",
    "    config = json.load(json_data_file)\n",
    "config = munch.munchify(config)\n",
    "bsde = HJBLQ(config.eqn_config)\n",
    "tf.keras.backend.set_floatx(config.net_config.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a60a226-85e6-4ac1-b1d2-c421b184857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_CLIP = 50.0\n",
    "bsde_solver = BSDESolver(config, bsde)\n",
    "training_history = bsde_solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e091b4d-b8fd-4868-b987-20b22ae35f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 21)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsde.sample(1)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926cf94-45c9-4076-90a3-8d80d60fedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('{}_training_history.csv'.format(path_prefix),\n",
    "               training_history,\n",
    "               fmt=['%d', '%.5e', '%.5e', '%d'],\n",
    "               delimiter=\",\",\n",
    "               header='step,loss_function,target_value,elapsed_time',\n",
    "               comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd184e3d-7bca-4719-8f2c-fe19f8d27338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200.        ,   3.95119402,   2.33412544,  17.85154223])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec7b3c-e55a-4eb5-9288-1572d927cc52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
