\newcommand{\Sspa}{\mathbb{S}^2(0,T)}
\newcommand{\Hspa}{\mathbb{H}^2(0,T)^d}

When addressing deterministic optimal control problems of dynamical systems, there are two approaches, one involving Bellman's dynamic programming principle, and the other relying on the Pontryagin's maximum principle. The former approach leads to a partial differential equation, the Hamilton-Jacobi-Bellman equation, to be solved for the value function and the optimal control of the process. The latter leads to a system of ordinary differential equations, one equation forward in time for the state and one backward in time for its adjoint.

The stochastic version of these problems is solved by methods analogous to those of the deterministic case. However, there are issues with desirable mathematical properties of solutions when we state them extending directly the ones proposed by deterministic methods. That is the case of the stochastic version of the Pontryagin's maximum principle, in which the backward differential equation cannot be stated directly as an SDE with terminal condition, as the solution is not guaranteed to be adapted to the filtration generated by the brownian motion.

The theory of backward stochastic differential equations (BSDEs) emerged in Bismut's \cite{bismut_conjugate_1973} early work, and later generalized by Pardoux and Peng \cite{pardoux_adapted_1990}, as an attempt to formalize the application of the stochastic maximum principle. Here we give an introduction and compilation of results about them based on \cite{zhang_backward_2017,pardoux_stochastic_2014,romero_maestro_nodate,touzi_optimal_2013}, including its relation with a certain class of nonlinear parabolic partial differential equations, which will be the main tool for the method explained in the following chapters. 
\section{Backward stochastic differential equations}
\subsection{Motivation}
Let's introduce the necessity for a different formulation of stochastic differential equations through an example \cite{romero_maestro_nodate}. In the usual setting for a stochastic differential equation (SDE), we specify the evolution of a $\mathbb{R}^d$-valued stochastic process $X_t$ through its dynamics and an initial value $x_0\in \mathbb{R}^d$(possibly random), in the form
\begin{equation}
	X_t=x_0 +\int_{0}^{t}\mu(t,X_t)dt+\int_{0}^{t} \sigma(t,X_t) dW_t,
\end{equation}
or equivalently,
\begin{equation}
	\label{eqn:SDE}
	\begin{split}
		dX_t&=\mu(t,X_t)dt+\sigma(t,X_t)dW_t\\
		X_0&=x_0,
	\end{split}
\end{equation}
where $W_t$ is a m-dimensional Brownian motion process and the stochastic integral is defined in the Ito sense.

We know that, under some Lipschitz and boundedness conditions for the drift $\mu$ and the volatility $\sigma$, the equation with initial condition $\eqref{eqn:SDE}$ has a unique solution which is adapted with respect to the filtration $\mathbb{F}=(\mathcal{F}_t)_t$ generated by $W_t$.

Now, what happens if we consider the problem \eqref{eqn:SDE} with a terminal condition at time $T>0$? Consider, for instance, the particular case with $\mu(t,X_t)=\sigma(t,X_t)=0$, and a square-integrable $\mathcal{F}_T$-measurable random variable $\xi\in L^2(0,T)$ for which we try to solve the problem of finding a process $Y_t$ such that
\begin{equation}
	\label{eqn:exampleBSDE}
	\begin{split}
		&dY_t=0\\
		&Y_t(T)=\xi.
	\end{split}
\end{equation}

This equation has a unique solution given by $Y(t)=\xi$, which is not necessarily $\mathcal{F}_t-$measurable for every $0\leq t \leq T$, and therefore \eqref{eqn:exampleBSDE} may not have solution in the usual SDE sense. 

Despite this, we can try to solve this problem reinterpreting the solution to \eqref{eqn:exampleBSDE} based on the following representation theorem.
\begin{theorem}[Martingale representation theorem \cite{mao_stochastic_2008}]
	\label{thm:MRT} Let $(M_t)_{0\leq t \leq T}$ be a continuous $\mathbb{R}^d$-valued square-integrable martingale with respect to $\mathcal{F}_t$, the augmented filtration generated by an $m$-dimensional Brownian motion $(W_t)_t$. Then, there is a unique $\mathbb{R}^{d\times m}$-valued $\mathcal{F}_t$-adapted stochastic process $f(s)$, with $\mathbb{E}[\int_{0}^{T}|f|^2dt]<\infty$ , such that 
	\begin{equation}
		M_t=M_0+\int_{0}^{t}f(s)dW_s \quad \text{ for } \quad t\in [0,T],
	\end{equation}
	where the uniqueness is interpreted in the mean squared norm.
\end{theorem}

We can intend to enforce the solution $Y_t$ to be $\mathcal{F}_t-$measurable for every $0 \leq t \leq T $ by taking its conditional expectation with respect to the evolving $\sigma$-algebra
\begin{equation}
	Y(t):=\mathbb{E}[\xi|\mathcal{F}_t],
\end{equation}
which satisfies the terminal condition $Y(T)=\xi$, since $\xi$ is $\mathbb{F}_T$-measurable. Thus, as a consequence of the Martingale representation theorem \ref{thm:MRT}, we conclude that there exist a square-integrable $\mathcal{F}_t$-measurable process $Z_t$ such that 
\begin{equation}
	\label{eqn:exampleBSDEintegral}
	Y(t)=Y(0)+\int_{0}^{t}Z_sdW_s\quad \text{ for } \quad t\in [0,T],
\end{equation}
which can be written as 
\begin{equation}
	\label{eqn:exampleBSDE2}
	\begin{split}
		&dY_t=Z_tdW_t\\
		&Y(T)=\xi
	\end{split}
\end{equation}
Therefore, problem \eqref{eqn:exampleBSDE} can be reinterpreted as in problem \eqref{eqn:exampleBSDE2}, that we will denote as a bacward stochastic differential equation (BSDE) , in which we seek a pair of processes $(Y_t,Z_t)$ that will provide an adapted solution to our original problem. Indeed, the process $Z_t$ will "steer" the system so that the process $Y_t$ remains adapted, and is thus called a control process. It is not possible to revert time as $t\to T-t$ as the filtration goes only in one direction \cite{chessari_numerical_2022}.

Finally, we can write this equation in another form. Note that \eqref{eqn:exampleBSDE2} is a forward SDE problem, hence we can solve for $Y(0)$ in the integral form , and so we have
\begin{equation}
	Y(0)=\xi-\int_{0}^{T}Z_sdW_s,
\end{equation}
that is inserted in \eqref{eqn:exampleBSDEintegral} to obtain
\begin{equation}
	Y(t)=\xi-\int_{0}^{T}Z_sdW_s+\int_{0}^{t}Z_sdW_s=\xi -\int_{t}^{T}Z_sdW_s \quad \forall t\in[0,T],
\end{equation}
which is the standard way to write the BSDE in integral form.
\subsection{Some useful theorems}
Now that we have motivated the use of BSDEs, we follow \cite{pham_continuous-time_2009} to provide a formal definition and prove that under certain regularity conditions, we can ensure the existence of a solution for that kind of equation.

Let be $(\Omega,\mathcal{F},\mathbb{P})$ a probability space and $T>0$ a fixed horizon time. We consider a $d$-dimensional Brownian motion $W=(W_t)_{t\in [0,T]}$ and let $\mathbb{F}=(\mathcal{F}_t)_{t\in[0,T]}$ be the corresponding natural augmented filtration (i.e with the completeness and right continuity conditions).

Denote by $\mathbb{S}^2(0,T)$ the set of real-valued progressively measurable processes $Y_t$ such that 
\begin{equation}
	\mathbb{E}\left[\sup_{0\leq t \leq T}|Y_t|^2\right]<\infty,
\end{equation}  
and by $\mathbb{H}^2(0,T)^d$ the set of $\mathbb{R}^d$-valued progressively measurable processes $Z_t$ such that
\begin{equation}
	\mathbb{E}\left[\int_{0}^{T}|Z_t|^2 dt\right]<\infty.
\end{equation}

Here we consider the backward stochastic differential equation 
\begin{equation}
	\label{eqn:BSDE}
	\begin{split}
		&dY_t=-f(t,Y_t,Z_t)dt+Z_t\cdot dW_t\\
		&Y(T)=\xi
	\end{split}
\end{equation}
\begin{definition}
	A solution to the BSDE \eqref{eqn:BSDE} is a pair $(Y,Z)\in \Sspa \times \Hspa$ such that
	\begin{equation}
	Y_t=\xi+\int_t^T f\left(s, Y_s, Z_s\right) d s-\int_t^T Z_s \cdot d W_s, \quad 0 \leq t \leq T
	\end{equation}
\end{definition}
Now we establish an existence and uniqueness theorem for $\bbR$-valued process, which can be extended to $\bbR^d$-valued processes. 
\begin{assumptions}
	\label{ass:BSDEexistence}
	Let $(\xi,f)$ satisfy
	\begin{enumerate}[I.]
		\item $\xi \in L^2(\Omega,\mathcal{F}_T,\mathbb{P};\mathbb{R})$
		\item $f:\Omega\times [0,T]\times\mathbb{R}\times\mathbb{R}^d\to \bbR$ such that \begin{enumerate}[a)]
			\item $f(\cdot,t,y,z)$, written $f(t,y,z)$ for simplicity, is progressively measurable for all $y,z$
			\item $f(t,0,0)\in \mathbb{H}^2[0,T]$ 
			\item $f$ is uniformly Lipschitz in $(y,z)$, i.e ,there exist a constant $C_f$ such that for all $y_1,y_2\in \bbR\times \bbR $ and $z_1,z_2\in \bbR^d\times\bbR^d$ we have
			\begin{equation}
				\label{eqn:lipschitz}
				\left|f\left(t, y_1, z_1\right)-f\left(t, y_2, z_2\right)\right| \leq C_f\left(\left|y_1-y_2\right|+\left|z_1-z_2\right|\right) \quad a.s
			\end{equation}
		\end{enumerate}
	\end{enumerate}
\end{assumptions}
\begin{theorem}[Existence and uniqueness of solutions to BSDEs \cite{pham_continuous-time_2009}]
	\label{thm:existence}
Given a pair $(\xi,f)$, called the terminal condition and the driver of the BSDE, that satisfy the assumptions \ref{ass:BSDEexistence}
, there exist a unique solution $(Y,Z)$ to the backward stochastic differential equation \eqref{eqn:BSDE}.
\end{theorem}
To give a demonstration we will need the following inequalities about SDEs, whose proofs will be omitted.
\begin{theorem}[Doob's martingale inequality \cite{mao_stochastic_2008}]
	\label{thm:Doobs}
	Let $\{M_t\}_t\geq 0$ be a $\bbR^d$-valued martingale in $L^{p}(\Omega;\bbR^d)$. Let $[0,T]$ be a bounded interval with $T>0$ and let $p>1$. Then
	\begin{equation}
		\mathbb{E}\left[ \sup_{0\leq t\leq T}|M_t|^p\right]\leq \left(\frac{p}{p-1}\right)^p \mathbb{E}[|M_T|^p],
	\end{equation}
	in particular, if $p=2$,
	\begin{equation}
		\mathbb{E}\left[ \sup_{0\leq t\leq T}|M_t|^2\right]\leq4 \mathbb{E}[|M_T|^2].
	\end{equation}
\end{theorem}
\begin{theorem}[Burkholder-Davis-Gundy inequality
 \cite{mao_stochastic_2008}]
 \label{thm:BDGineq}
	Let $g\in L^2(\bbR^+;\bbR^{d\times m})$. Define for $t\geq 0$
	\begin{equation*}
		x(t)=\int_{0}^{t}g(s)dW_s\quad \text{ and }\quad  A(t)=\int_{0}^{t}|g(s)|^2 ds
	\end{equation*}
	then, for every $p>0$ there exist universal positive constants $c_p,C_p$, depending only on $p$, such that the following inequalities hold
	\begin{equation}
		c_p\mathbb{E}[|A(t)|^{\frac{p}{2}}]\leq \mathbb{E}\left[\sup_{0\leq s\leq t}|x(s)|^p\right]\leq C_p\mathbb{E}[|A(t)|^{\frac{p}{2}}],
	\end{equation}
in particular, if $p=1$, we can take $c_p=\frac{1}{2}$ and $C_p=4\sqrt{2}$
\end{theorem}
\begin{proof}[Proof of theorem \ref{thm:existence} ]
Here we give a fixed point argument. To do it, lets consider a pair of process $(U,V)\in\Sspa\times\Hspa$ and, as in the motivation example, consider the martingale
\begin{equation}
	M_t=\mathbb{E}\left[\xi +\int_{0}^{T}f(s,U_s,V_s)ds \Bigg| \mathcal{F}_t \right],
\end{equation}
which is square-integrable under the hypothesis on $(\xi,f)$. Using to the martingale representation theorem \ref{thm:MRT}, we deduce the existence and uniqueness of a process $Z_s\in \Hspa$ such that
\begin{equation}
	\label{eqn:Mdem}
	M_t=M_0+\int_{0}^{t}Z_s \cdot dW_s.
\end{equation}
Now, define the process $Y_t$ for $0\leq t\leq T$ as
\begin{equation}
	\begin{split}
	Y_t&=\mathbb{E}\left[\xi +\int_{t}^{T}f(s,U_s,V_s)ds \Bigg| \mathcal{F}_t \right]=\mathbb{E}\left[\xi +\int_{0}^{T}f(s,U_s,V_s)ds-\int_{0}^{t}f(s,U_s,V_s)ds  \Bigg| \mathcal{F}_t \right]\\
	&=M_t-\int_{0}^{t}f(s,U_s,V_s)ds\\
	\end{split}
\end{equation}
and note that from this and using \eqref{eqn:Mdem}, $Y_t$ satisfies 
\begin{equation}
	\label{eqn:SdeY}
	\begin{split}
		Y_t&=M_0+\int_{0}^{t}Z_s \cdot dW_s-\int_{0}^{t}f(s,U_s,V_s)ds\\
		&=\xi+\int_{t}^{T}f(s,U_s,V_s)ds-\int_{t}^{T} Z_s\cdot dW_s.
	\end{split}
\end{equation}


Thus, consider the function $\Phi:\Sspa\times\Hspa \to \Sspa\times\Hspa$ that maps the pair $(U,V)$ to the pair $(Y,Z)$ constructed as above, $\Phi(U,V)=(Y,Z)$. Note that it is well-defined as the $Z$ process is unique, and by Doob's martingale inequality \ref{thm:Doobs} we have
\begin{equation}
	\mathbb{E}\left[\sup_{0\leq t\leq T}\left|\int_{t}^{T}Z_s\cdot dW_s\right|^2\right]\leq 4\mathbb{E}\left[\int_{0}^{T}|Z_s|^2ds\right]<\infty,
\end{equation}
and therefore, by assumptions $I$, $II a)$ and $II b)$, $Y_t$ lies in $\Sspa$. Also note that a solution to the BSDE \eqref{eqn:BSDE} is a fixed point of $\Phi$. We will show that such fixed point exist by showing it is a contraction if we endow the $\Sspa\times\Hspa$ space with the metric 
\begin{equation}
	\lVert(Y,Z)\rVert_\beta=\left(\expect*{\int_{0}^{T}e^{\beta s}(  |Y_s|^2+|Z_s|^2)ds}\right)^{\frac{1}{2}},
\end{equation}
where $\beta>0$ is a parameter to be chosen later.

To show that $\Phi$ is a contraction, let $(U,V),(U',V')\in \Sspa\times \Hspa$ and $(Y,Z)=\Phi(U,V)$, $(Y',Z')=\Phi(U',V')$. We denote $(\bar{U},\bar{V})=(U-U',V-V')$,  $(\bar{Y},\bar{Z})=(Y-Y',Z-Z')$ and $\bar{f_t}=f(t,U_t,V_t)-f(t,U_t',V_t')$. 

Using equation \eqref{eqn:SdeY}, we know that $\bar{Y_s}$ satisfies 
\begin{equation}
	\bar{Y_s}=-\int_{0}^{t}\bar{f_s}ds+\int_{0}^{t}\bar{Z_s}\cdot dW_s
\end{equation} 

So let's apply Ito's formula to the process $e^{\beta s}|\bar{Y_s}|^2$ between $0$ and $T$ to obtain
\begin{equation}
	\label{eqn:itoProof}
	\begin{split}
	e^{\beta T}|\bar{Y_T}|^2=|\bar{Y_0}|^2&+\int_{0}^{T}(\beta e^{\beta s}|\bar{Y_s}|^2-2e^{\beta s}\bar{Y_s}\cdot \bar{f_s}+e^{\beta s}|\bar{Z_s}|^2)ds\\
	&+\int_{0}^{T}2e^{\beta s}\bar{Y_s} \bar{Z_s}\cdot dW_s.
	\end{split}
\end{equation}
Observe that we can apply the Burkholder-Davis-Gundy inequality \ref{thm:BDGineq} with $p=1$ to the following expectation of the supremum associated with the last term
\begin{equation}
	\begin{split}
	\expect*{\sup_{0\leq t \leq T}\left|\int_{0}^{t}2e^{\beta s}\bar{Y_s} \bar{Z_s}\cdot dW_s\right|}&\leq 4\sqrt{2} \expect*{\left(\int_{0}^{T}4e^{2\beta s}|\bar{Y_s}|^2 |\bar{Z_s}|^2 ds\right)^{\frac{1}{2}}} \\
	& \leq 4\sqrt{2}e^{\beta T} \expect*{\sup_{0\leq t\leq T}|Y_t|^2+\int_{0}^{T}|\bar{Z_s}|^2 ds}\\
	&<\infty,
	\end{split}
\end{equation}
which shows that the local martingale $\int_{0}^{t}2e^{\beta s}\bar{Y_s} \bar{Z_s}\cdot dW_s$ is actually a uniformly integrable martingale and therefore its expected value remains constant zero. Also, note that $\bar{Y}_T=Y_T-Y_T'=\xi-\xi=0$.

Using these facts, take the expected value to \eqref{eqn:itoProof} and reorder terms to obtain 
\begin{equation}
	\begin{aligned}
		& \mathbb{E}\left|\bar{Y}_0\right|^2+\mathbb{E}\left[\int_0^T e^{\beta s}\left(\beta\left|\bar{Y}_s\right|^2+\left|\bar{Z}_s\right|^2\right) d s\right]=2 \mathbb{E}\left[\int_0^T e^{\beta s} \bar{Y}_s \cdot \bar{f}_s d s\right] \\
		\leq & 2 C_f \mathbb{E}\left[\int_0^T e^{\beta s}\left|\bar{Y}_s\right|\left(\left|\bar{U}_s\right|+\left|\bar{V}_s\right|\right) d s\right] \quad \text{(by condition $IIc$))}  \\
		\leq & 4 C_f^2 \mathbb{E}\left[\int_0^T e^{\beta s}\left|\bar{Y}_s\right|^2 d s\right]+\frac{1}{2} \mathbb{E}\left[\int_0^T e^{\beta s}\left(\left|\bar{U}_s\right|^2+\left|\bar{V}_s\right|^2\right) d s\right],
	\end{aligned}
\end{equation}
so if we choose $\beta=1+4C_f^2$ and ignore the $ \mathbb{E}\left|\bar{Y}_0\right|^2$ term, we obtain

\begin{equation}
	 \mathbb{E}\left[\int_0^T e^{\beta s}\left(\left|\bar{Y}_s\right|^2+\left|\bar{Z}_s\right|^2\right) d s\right] \leq \frac{1}{2}  \mathbb{E}\left[\int_0^T e^{\beta s}\left(\left|\bar{U}_s\right|^2+\left|\bar{V}_s\right|^2\right) d s\right],
\end{equation}

which is $\lVert(\Phi(U,V))\rVert_\beta \leq \frac{1}{2}\lVert(U,V)\rVert_\beta$, that means $\Phi$ is a contraction in a Banach space, as $\Sspa \times \Hspa$ is the product of Banach spaces, and therefore has a unique fixed point.
\end{proof}

As in the every differential equation, there are cases where we can provide an explicit solution. The next theorem provides one for the BSDE with linear generator
\begin{theorem}[Linear BSDEs \cite{pham_continuous-time_2009}]
	\label{thm:linearBSDE}
	Let $A_t$,$B_t$ be bounded progressively measurable processes with values in $\bbR$ and $\bbR^d$, $C$ a process in $\mathbb{H}^2(0,T)$ and $\xi \in L^2(\omega,\mathcal{F}_T,\mathbb{P},\bbR)$. Then, the linear backward stochastic differential equation
	\begin{equation}
		\begin{split}
			&dY_t=-(A_tY_t+Z_t\cdot B_t+C_t)dt+Z_t\cdot dW_t\\
			&Y_T=\xi
		\end{split}
	\end{equation}
	has a unique solution, and is given by the formula
	\begin{equation}
		\Gamma_t Y_t=E\left[\Gamma_T \xi+\int_t^T \Gamma_s C_s d s \mid \mathcal{F}_t\right],
	\end{equation}
	where $\Gamma_t$ is the solution to the adjoint process
	\begin{equation}
		\begin{split}
			&d\Gamma_t=\Gamma_t(A_tdt+B_t\cdot dW_t)\\
			&\Gamma_0=1
		\end{split}
	\end{equation}	
\end{theorem}
\begin{proof}
	First apply Ito's formula to $\Gamma_t Y_t$ to obtain
	\begin{equation}
		\begin{split}
			d(\Gamma_t Y_t)&=Y_t d\Gamma_t +\Gamma_t dY_t +d\Gamma_t dY_t\\
			&=Y_t(\Gamma_t A_t dt +\Gamma_t B_t\cdot dW_t)+\Gamma_t(-(A_tY_t+Z_t\cdot B_t+C_t)dt+Z_t\cdot dW_t)\\
			& \quad+\Gamma_t Z_t \cdot B_t dt\\
			&=-\Gamma_t C_t dt+\Gamma_t (Z_t+Y_t B_t)\cdot dW_t,
		\end{split}
	\end{equation}
that can be written in integral form as 
\begin{equation}
	\label{eqn:martAdj}
	\Gamma_t Y_t+\int_0^t \Gamma_s C_s d s=Y_0+\int_0^t \Gamma_s\left(Z_s+Y_s B_s\right) \cdot d W_s.
\end{equation}
We will show, as in the proof of theorem \ref{thm:existence}, that the stochastic integral  in the last expression, which is a local martingale, is in fact a uniformly integrable martingale. We have $\expect*{\sup_{0\leq t \leq T}|\Gamma_t|^2}<\infty$ ,since $A_t$ and $B_t$ are bounded. Also, let's denote $b_\infty$ the upper bound on $B_t$, then the following inequalities hold 
\begin{equation}
	\begin{split}
		\expect*{\sup_{0\leq t \leq T}\left|\int_0^t \Gamma_s\left(Z_s+Y_s B_s\right) \cdot d W_s\right|}&\leq 4\sqrt{2} \expect*{\left(\int_{0}^{T}|\Gamma_s|^2 |Z_s+Y_s B_s|^2 ds\right)^{\frac{1}{2}}} \\
		&\text{{\footnotesize (By BDG inequality \ref{thm:BDGineq})}}\\
		& \leq \frac{4\sqrt{2}}{2} E\left[\sup_{0\leq t \leq T}\left|\Gamma_t\right|^2+2 \int_0^T\left|Z_t\right|^2 d t+2 b_{\infty}^2 \int_0^T\left|Y_t\right|^2 d t\right]\\
		&<\infty.
	\end{split}
\end{equation}
Consequently, the right-hand side of is a uniformly integrable martingale, and so, if we take expected values to the equality \eqref{eqn:martAdj}, we have
\begin{equation}
	\begin{split}
		\Gamma_t Y_t+\int_0^t \Gamma_s C_s d s & =\expect*{\Gamma_T Y_T+\int_0^T \Gamma_s C_s d s \Bigg| \mathcal{F}_t} \\
		& =\expect*{\Gamma_T \xi+\int_0^T \Gamma_s C_s d s \Bigg| \mathcal{F}_t}
	\end{split}
\end{equation} 
and, as $\int_0^t \Gamma_s C_s d s$ is $\mathcal{F}_t$-measurable, we obtain
\begin{equation}
		\Gamma_t Y_t =\expect*{\Gamma_T \xi+\int_t^T \Gamma_s C_s d s \Bigg| \mathcal{F}_t},
\end{equation}
that is what we wanted to prove. The control solution $Z_t$ can be obtained by the martingale representation theorem \ref{thm:MRT} applied to this process.
\end{proof}


Finally, we state the next comparison principle for solution of BSDEs
\begin{theorem}[Comparison principle for BSDEs \cite{pham_continuous-time_2009}]
	Let $(\xi_1,f_1)$ and $(\xi_2,f_2)$ two pairs of terminal conditions and generators satisfying assumptions \ref{ass:BSDEexistence},and let $(Y_{1,t},Z_{1,t})$ and $(Y_{2,t},Z_{2,t})$ the solutions to their corresponding BSDE. Suppose that
	\begin{enumerate}
		\item $\xi_1 \leq \xi_2$ a.s
		\item $f_1(t,Y_{1,t},Z_{1,t})\leq f_2(t,Y_{1,t},Z_{1,t}) $ $dt\times d\mathbb{P}$-a.e 
		\item $f_2(t,Y_{1,t},Z_{1,t}) \in \mathbb{H}^2(0,T) $
	\end{enumerate} 
Then $Y_{1,t}\leq Y_{2,t}$ for all $0\leq t \leq T$, a.s.
Furthermore, if $Y_{2,0}\leq Y_{1,0}$, then $Y_{1,t}=Y_{2,t}$ for $t\in [0,T]$. In particular, if $\mathbb{P}(\xi_1<\xi_2)>0$ or $f_1(t,\cdot,\cdot)<f_2(t,\cdot,\cdot)$ on a set with strictly positive measure $dt\times d\mathbb{P}$ then $Y_{1,0}<Y_{2,0}$.
\end{theorem}
\begin{proof}
	To simplify notation, we give a proof with $d=1$.
	We denote $\bar{Y_t}=Y_{2,t}-Y_{1,t}$ and $\bar{Z_t}=Z_{2,t}-Z_{1,t}$. Then $(\bar{Y_t},\bar{Z_t})$ satisfy the BSDE
\begin{equation}
	\label{eqn:linearBSDE}
	\begin{split}
		&d \bar{Y_t}=-\left(\Delta_t^y \bar{Y_t}+\Delta_t^z \bar{Z_t}+\bar{f_t}\right) d t+\bar{Z}_t dW_t\\
		&\bar{Y_T}=\xi_2-\xi_1,
	\end{split}
\end{equation}
where 
\begin{equation}
	\begin{aligned}
		\Delta_t^y & =\frac{f_2\left(t, Y_{2,t}, Z_{2,t}\right)-f_2\left(t, Y_{1,t}, Z_{2,t}\right)}{Y_{2,t}-Y_{1,t}} 1_{Y_{2,t}-Y_{1,t} \neq 0} \\
		\Delta_t^z & =\frac{f_2\left(t, Y_{1,t}, Z_{2,t}\right)-f_2\left(t, Y_{1,t}, Z_{1,t}\right)}{Z_{2,t}-Z_{1,t}} 1_{Z_{2,t}-Z_{1,t} \neq 0} \\
		\bar{f}_t & =f_2\left(t, Y_{1,t}, Z_{1,t}\right)-f_1\left(t, Y_{1,t}, Z_{1,t}\right) .
	\end{aligned}
\end{equation}
By assumption, $f_2$ is Lipschitz in $y,z$, hence $\Delta_t^y$ and $\Delta_t^z$ are bounded. Moreover, $\bar{f_t}\in \mathbb{H}^2(0,T)$. Therefore, the solution to \eqref{eqn:linearBSDE} is given by theorem \ref{thm:linearBSDE} as
\begin{equation}
	\Gamma_t \bar{Y_t}=\expect*{\Gamma_T\left(\xi_2-\xi_1\right)+\int_t^T \Gamma_s \bar{f_s} d s \Bigg| \mathcal{F}_t},
\end{equation} 
where $\Gamma_t$ satisfies 
\begin{equation}
	\begin{split}
		&d\Gamma_t=\Gamma_{t}(\Delta_t^y dt + \Delta_t^z dW_t )\\
		&\Gamma_0=1.
	\end{split}
\end{equation}
Note that $\Gamma_t$ is strictly positive. We conclude the stated result using that $\xi_2-\xi_2\geq 0$ by assumption $1)$, and $\bar{f}_t\geq 0$ by assumption $2)$.

\end{proof}
\subsection{Forward-Backward stochastic differential equations}
Now we consider a special case of backward stochastic differential equations in which the randomness of the drift enters through a process satisfying a forward stochastic differential equation. In its more general form, the problem is stated as find three processes $(X_t,Y_t,Z_t)\in\bbR^n\times\bbR^m\times\bbR^{m\times d}$ such that
\begin{equation}
	\begin{split}
		&dX_s=\mu(t,X_s,Y_s,Z_s)ds+\sigma(s,X_s,Y_s,Z_s)dW_s\\
		&X_t=x\\
		&dY_s=-f(s,X_s,Y_s,Z_s)ds+Z_s dW_s\\
		&Y_T=g(X_T),
	\end{split}
\end{equation}  
for all $t\leq s \leq T$, where $\mu,\sigma$ and $g$ are known functions, and $x$ is the initial condition at starting time $s$. This coupled system is called a forward-backward stochastic differential equation (FBSDE).

This problem is rather difficult, as the coupling between the processes may forbid a solution to exist. There are conditions on $\mu, \sigma,g$ where we can establish the existence and uniqueness of solutions to the former system, but their detailed proof is very technical and thus is not presented here, see \cite{zhang_backward_2017}.

However, we can say something simpler about the decoupled case   
\begin{equation}
	\label{eqn:Uncoupled}
	\begin{split}
		&dX_s=\mu(s,X_s)ds+\sigma(s,X_s)dW_s\\
		&X_t=x,\\
		&dY_s=-f(s,X_s,Y_s,Z_s)ds+Z_s dW_s\\
		&Y_T=g(X_T).
	\end{split}
\end{equation}
for all $t\leq s\leq T$.  

In this case, if $\mu$ and $\sigma$ satisfy enough regularity conditions to ensure that a solution to the forward SDE in \eqref{eqn:Uncoupled} exists, for example, if they are Lipschitz and bounded, then we can solve it for the process $X_t$ and insert the solution into the backward equation in \ref{eqn:Uncoupled} and solve for the backward process. However, the main property of FBSDEs is that the solution process $(Y,Z)$ of the BSDE can be written as a deterministic function of time and the state process, in this case the solution is said to be \textit{markovian}. 

Let's establish this assertions in the following theorem. 


\begin{assumptions}
	\label{ass:FBSDEexistence}
	Let $(\mu,\sigma,f,g)$. There exist a constant $C>0$ such that for all $x,y,t$
	\begin{enumerate}[I.]
		\item $|\mu(t,x)-\mu(t,y)|+|\sigma(t,x)-\sigma(t,y)|\leq C(1+|x-y|)$
		\item $|f(t,x,y_1,z_1)-f(t,x,y_2,z_2)|\leq C(|y_1-y_2|+|z_1-z_2|)$
		\item $|\sigma(t,x)|+|\mu(t,x)|\leq C(1+|x|)$
		\item $|f(t,x,y,z)|+|g(x)|\leq C(1+|x|^p)$ para $p\geq\frac{1}{2}$
	\end{enumerate}
\end{assumptions}
\newpage
\begin{theorem}[Existence and markovianity of solutions of FBSDEs \cite{el_karoui_backward_1997}]
	Under assumptions \ref{ass:FBSDEexistence}, the uncoupled forward-backward stochastic differential equation \eqref{eqn:Uncoupled} has a unique solution $(X_{s}^{t,x},Y_{s}^{t,x},Z_{s}^{t,x})$ starting from $x$ at time $t$. Moreover, $(Y_{s}^{t,x},Z_{s}^{t,x})$ is adapted to the future $\sigma$-algebra of $W$ after $t$, i.e, it is $\mathcal{F}_{s}^{t}$-adapted where for each $s\in[t,T]$ we define $\mathcal{F}_{s}^{t}=\sigma(W_u-W_t,t\leq u\leq s)$. In particular, $Y_{t}^{t,x}$ is deterministic and for $0\leq s\leq t$ we have $Y_{s}^{t,x}=Y_{t}^{t,x}$ and $Z_{s}^{t,x}=0$.
\end{theorem}
\begin{proof}
	Im beautiful
\end{proof}
\section{The Feynman-Kac formulas}
Now we shall establish the connection between stochastic differential equations with parabolic linear partial differential equations and its non-linear generalization based on backward stochastic differential equations. 
\subsection{The linear Feynman-Kac formula}
\subsection{The non-linear Feynman-Kac formula}

 


